{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":121144,"databundleVersionId":14484960,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:00.453134Z","iopub.execute_input":"2025-11-30T07:26:00.453440Z","iopub.status.idle":"2025-11-30T07:26:00.807856Z","shell.execute_reply.started":"2025-11-30T07:26:00.453415Z","shell.execute_reply":"2025-11-30T07:26:00.806894Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/agents-intensive-capstone-project/Hackathon dataset.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":" <h1 style=\"font-size:28px;\"> üõ°Ô∏è Silent Guardian - Safety AI Agent ü§ñ </h1>\n\n**Capstone Project** - 5 - Day AI Agents Intensive Course <br>\n**Track:** Enterprise Agents <br>\n**Problem:** Organizations struggle to detect and respond to harassment across chats, emails, and collaboration tools ‚Äî causing delayed action, legal risk, and employee harm. <br>\n**Solution:** A privacy-first multi-agent system that scans communication streams, detects harassment patterns, generates safe intervention suggestions, builds evidence packets, and routes final decisions to human reviewers.\n\n<h2 style=\"font-size:24px;\"> üîë Key Features </h2>\n\nü§ñ **Multi-Agent System:** Ingestor, Extractor, Classifier, Pattern Detector, Risk Scorer, Intervention Planner, Evidence Builder, Ethics, Memory, Notifier.<br>\nüè¢ **Enterprise Integrations:** Slack/Teams/email/CSV + Google Generative AI.<br>\nüõ†Ô∏è **Custom Tools:** PII redactor, severity scoring, PDF evidence generator, moderator action stub.<br>\nüß† **Memory:** User safety profiles & incident history via Memory Bank.<br>\nüìä **Observability:** Logs, traces, confidence scores, dashboards (incidents, severity).<br>\nüîó **A2A Communication:** Agents call each other through a structured protocol.<br>\n‚öñÔ∏è **Ethics & Human-in-the-Loop Controls:** Safety checks ensure high-risk actions need human approval before execution.<br>\nüìÑ **Evidence Generation:** Automatic markdown/PDF evidence packets summarizing conversations, labels, and risk.\n","metadata":{}},{"cell_type":"markdown","source":"## üìã Table of Contents \n\n1. [Setup & Configuration](#setup) \n2. [Architecture Overview](#architecture) \n3. [Custom Tools Implementation](#tools) \n4. [Specialized Agents](#agents) \n5. [Multi-Agent Orchestration](#orchestration)\n6. [Pipeline Setup and Initialization](#initialization)\n7. [Session and Memory Management](#Session) \n8. [Observability and Logging](#observability) \n9. [Demo Run and Usage](#demo) \n10. [Evaluation of the System](#evaluation)\n11. [Conclusion & Summary](#conclusion)\n","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1 : Setup & Configuration {#setup}","metadata":{}},{"cell_type":"code","source":"\n# Install dependencies (if not already installed)\n# !pip install google-adk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:00.809581Z","iopub.execute_input":"2025-11-30T07:26:00.810003Z","iopub.status.idle":"2025-11-30T07:26:00.815121Z","shell.execute_reply.started":"2025-11-30T07:26:00.809978Z","shell.execute_reply":"2025-11-30T07:26:00.814200Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Configure API Key\nimport os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    # Fallback for local development\n    if \"GOOGLE_API_KEY\" in os.environ:\n        print(\"‚úÖ Using environment variable for API key.\")\n    else:\n        print(f\"‚ö†Ô∏è API key not found. Please set GOOGLE_API_KEY environment variable.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:00.816161Z","iopub.execute_input":"2025-11-30T07:26:00.816486Z","iopub.status.idle":"2025-11-30T07:26:01.081073Z","shell.execute_reply.started":"2025-11-30T07:26:00.816456Z","shell.execute_reply":"2025-11-30T07:26:01.080044Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Import required libraries\nimport os\nimport json\nimport re\nimport sqlite3\nimport time\nimport uuid\nfrom datetime import datetime, timedelta\nfrom typing import List, Dict, Any, Optional\nfrom dataclasses import dataclass, field\n\nprint(\"‚úÖ All imports successful! . \\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.082332Z","iopub.execute_input":"2025-11-30T07:26:01.082853Z","iopub.status.idle":"2025-11-30T07:26:01.089043Z","shell.execute_reply.started":"2025-11-30T07:26:01.082820Z","shell.execute_reply":"2025-11-30T07:26:01.088173Z"}},"outputs":[{"name":"stdout","text":"‚úÖ All imports successful! . \n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- GLOBAL UTILITY FUNCTIONS (must be defined before anything else) ---\nimport uuid\nfrom datetime import datetime\n\ndef print_header(title: str):\n    print(\"\\n\" + \"=\"*12 + f\" {title} \" + \"=\"*12)\n\ndef now_ts():\n    return datetime.utcnow().isoformat() + \"Z\"\n\ndef gen_id(prefix=\"id\"):\n    return f\"{prefix}_{uuid.uuid4().hex[:8]}\"\nprint(\"‚úÖ Utility functions loaded successfully at\", now_ts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.091567Z","iopub.execute_input":"2025-11-30T07:26:01.091851Z","iopub.status.idle":"2025-11-30T07:26:01.111399Z","shell.execute_reply.started":"2025-11-30T07:26:01.091826Z","shell.execute_reply":"2025-11-30T07:26:01.110398Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Utility functions loaded successfully at 2025-11-30T07:26:01.107748Z\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## üèóÔ∏è Section 2 : Architecture Overview {#architecture} \n\n\n### System Architecture\n\nThe Silent Guardian system is a privacy-first, multi-agent pipeline that detects, triages, and recommends interventions for harassment at scale.\n\n1) **Ingestor Agent** - Normalizes conversation streams (Slack/Teams/Chat), anonymizes PII, and creates Conversation objects.\n2) **Extractor / Context Agent** - Extracts a time window of messages around a focal message for focused analysis.\n3) **Harassment Classifier (MCP-aware)** - MCP switchable: fast rule mode or richer LLM-sim mode. Produces message-level labels + scores + explanations.\n4) **Pattern Detector (V2)** - Finds repeat targeting (mentions), builds recidivism counts using MemoryAgent history.\n5) **Risk Scorer (V2)** - Aggregates message scores, applies repeat-targeting and recidivism bumps ‚Üí maps to severity (Low / Medium / High / Immediate).\n6) **Intervention Planner** - Maps severity to recommended actions (support messages, moderator alert, HR escalation, evidence generation).\n7) **Ethics Agent** - Policy gate‚Äîdisallows destructive automated actions and requires human approval where needed.\n8) **Evidence Builder** - Assembles plain-text/markdown (or PDF) incident packet for moderators/HR (no external uploads required).\n9) **Notifier (Human-in-Loop)** - Simulated moderator notifications and supportive messages; integration point for Slack/email APIs.\n10) **Memory Agent (SQLite)** - In-notebook persistent memory for demo (incidents per user) so the system can detect recidivism across sessions.\n11) **Observability** - Structured logs for each pipeline step (ingest, classify, ethics check, incident create) to aid debugging and evaluation.\n12) **MessageBus (A2A pub/sub)** - Agent-to-Agent (A2A) pub/sub for parallel processing (e.g., post-classification pattern detection).\n13) **Tools / MCP** - Tool registry (e.g., GoogleSearchTool) and an MCP (Model Control Plane) to flip classifier modes during experiments.","metadata":{}},{"cell_type":"markdown","source":"### Data Models","metadata":{}},{"cell_type":"code","source":"# -----------------------------\n# Data models \n# -----------------------------\nprint_header(\"Data models\")\n\n@dataclass\nclass Message:\n    msg_id: str\n    sender_id: str\n    text: str\n    ts: str\n    attachments: List[str] = field(default_factory=list)\n\n@dataclass\nclass Conversation:\n    convo_id: str\n    platform: str\n    messages: List[Message]\n    metadata: Dict[str,Any] = field(default_factory=dict)   \n\n@dataclass\nclass Incident:\n    incident_id: str\n    convo_id: str\n    involved_user_ids: List[str]\n    start_ts: str\n    end_ts: str\n    labels: List[Dict[str, Any]]\n    severity: str\n    evidence: Optional[str]\n    status: str\n\nprint(\"Data models ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.112574Z","iopub.execute_input":"2025-11-30T07:26:01.112956Z","iopub.status.idle":"2025-11-30T07:26:01.140243Z","shell.execute_reply.started":"2025-11-30T07:26:01.112924Z","shell.execute_reply":"2025-11-30T07:26:01.139311Z"}},"outputs":[{"name":"stdout","text":"\n============ Data models ============\nData models ready.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Defining Helpers","metadata":{}},{"cell_type":"code","source":"# -----------------------------\n# Helpers\n# -----------------------------\n\ndef now_ts():\n    return datetime.utcnow().isoformat() + \"Z\"\n\ndef gen_id(prefix=\"id\"):\n    return f\"{prefix}_{uuid.uuid4().hex[:8]}\"\n\ndef print_header(title: str):\n    print('\\n' + '='*8 + ' ' + title + ' ' + '='*8)\n\n# Simple anonymize\nPII_EMAIL_RE = re.compile(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\")\nPII_PHONE_RE = re.compile(r\"\\b\\+?\\d[\\d \\-]{6,}\\d\\b\")\n\ndef anonymize_text(text: str) -> str:\n    t = PII_EMAIL_RE.sub(\"[EMAIL_REDACTED]\", text)\n    t = PII_PHONE_RE.sub(\"[PHONE_REDACTED]\", t)\n    return t","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.141056Z","iopub.execute_input":"2025-11-30T07:26:01.141336Z","iopub.status.idle":"2025-11-30T07:26:01.157840Z","shell.execute_reply.started":"2025-11-30T07:26:01.141315Z","shell.execute_reply":"2025-11-30T07:26:01.156702Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## üõ†Ô∏è Section 3 : Custom Tools Implementation {#tools}\n\nCreating Custom tools for MCP and Google Search tool ","metadata":{}},{"cell_type":"code","source":"# -----------------------------\n# Configuration / MCP / Tools\n# -----------------------------\nclass ModelControlPlane:\n    def __init__(self):\n        # switch between 'rule' or 'llm' (llm is a simulated rich responder)\n        self.registry = {'classifier': {'type':'llm','version':'v1'}}\n    def get(self, name):\n        return self.registry.get(name)\n    def set(self, name, cfg):\n        self.registry[name] = cfg\n\nmcp = ModelControlPlane()\n\nclass Tool:\n    def run(self, *args, **kwargs):\n        raise NotImplementedError\n\nclass GoogleSearchTool(Tool):\n    def __init__(self, api_key=None):\n        self.api_key = api_key\n    def run(self, query):\n        # demo-only: no external calls. Return placeholder structure.\n        print(f\"[GoogleSearchTool] (simulated) run: {query}\")\n        return {'query': query, 'hits': []}\n\ntool_registry = {'google_search': GoogleSearchTool(os.environ.get('GOOGLE_API_KEY'))}\n\nprint(\"\\n===== MCP / TOOL REGISTRY STATUS =====\")\nprint(\"MCP Classifier Config :\", mcp.get(\"classifier\"))\nprint(\"Registered Tools      :\", list(tool_registry.keys()))\nprint(\"Google API Key Loaded :\", bool(os.environ.get('GOOGLE_API_KEY')))\nprint(\"=======================================\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.158990Z","iopub.execute_input":"2025-11-30T07:26:01.159354Z","iopub.status.idle":"2025-11-30T07:26:01.177589Z","shell.execute_reply.started":"2025-11-30T07:26:01.159329Z","shell.execute_reply":"2025-11-30T07:26:01.176441Z"}},"outputs":[{"name":"stdout","text":"\n===== MCP / TOOL REGISTRY STATUS =====\nMCP Classifier Config : {'type': 'llm', 'version': 'v1'}\nRegistered Tools      : ['google_search']\nGoogle API Key Loaded : True\n=======================================\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### SQLite Database Setup & Schema Initialization","metadata":{}},{"cell_type":"code","source":"# -----------------------------\n# In-memory DB (no files)\n# -----------------------------\nprint_header(\"In-memory Memory DB\")\n# Use an in-memory SQLite DB so nothing is written to disk; persists for the notebook session\nconn = sqlite3.connect(':memory:')\ncur = conn.cursor()\ncur.execute('''\nCREATE TABLE IF NOT EXISTS incidents (\n    incident_id TEXT PRIMARY KEY,\n    convo_id TEXT,\n    involved_users TEXT,\n    start_ts TEXT,\n    end_ts TEXT,\n    labels TEXT,\n    severity TEXT,\n    evidence TEXT,\n    status TEXT\n)\n''')\ncur.execute('''\nCREATE TABLE IF NOT EXISTS user_profiles (\n    user_id TEXT PRIMARY KEY,\n    anon_id TEXT,\n    safety_score REAL,\n    incidents TEXT\n)\n''')\nconn.commit()\nprint(\"‚úÖ In-memory SQLite DB ready (no files created).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.178608Z","iopub.execute_input":"2025-11-30T07:26:01.179002Z","iopub.status.idle":"2025-11-30T07:26:01.204243Z","shell.execute_reply.started":"2025-11-30T07:26:01.178981Z","shell.execute_reply":"2025-11-30T07:26:01.202845Z"}},"outputs":[{"name":"stdout","text":"\n======== In-memory Memory DB ========\n‚úÖ In-memory SQLite DB ready (no files created).\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## ü§ñ Section 4 : Specialized Agents {#agents}¬∂","metadata":{}},{"cell_type":"code","source":"# -----------------------------\n# Agent 1: Memory Agent\n#Stores incident history for each user to support recidivism scoring.\n#Allows the system to get ‚Äúsmarter‚Äù with repeated interactions.\n# -----------------------------\n\nprint_header(\"Memory Agent\")\nclass MemoryAgent:\n    def __init__(self, conn):\n        self.conn = conn\n    def append_incident(self, user_id, incident_id):\n        cur = self.conn.cursor()\n        cur.execute(\"SELECT incidents FROM user_profiles WHERE user_id=?\", (user_id,))\n        r = cur.fetchone()\n        if not r:\n            cur.execute(\"INSERT INTO user_profiles (user_id, anon_id, safety_score, incidents) VALUES (?,?,?,?)\",\n                        (user_id, gen_id('anon'), 0.5, json.dumps([incident_id])))\n        else:\n            incs = json.loads(r[0] or '[]')\n            incs.append(incident_id)\n            cur.execute(\"UPDATE user_profiles SET incidents=? WHERE user_id= ?\", (json.dumps(incs), user_id))\n        self.conn.commit()\n    def get_incidents(self, user_id):\n        cur = self.conn.cursor()\n        cur.execute(\"SELECT incidents FROM user_profiles WHERE user_id=?\", (user_id,))\n        r = cur.fetchone()\n        return json.loads(r[0]) if r and r[0] else []\n\nmemory_agent = MemoryAgent(conn)\nprint(\"MemoryAgent ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.205282Z","iopub.execute_input":"2025-11-30T07:26:01.205593Z","iopub.status.idle":"2025-11-30T07:26:01.224472Z","shell.execute_reply.started":"2025-11-30T07:26:01.205567Z","shell.execute_reply":"2025-11-30T07:26:01.223275Z"}},"outputs":[{"name":"stdout","text":"\n======== Memory Agent ========\nMemoryAgent ready.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# -----------------------------\n#Agents 2 and 3 : Ingestor, Extractor\n#Ingestor - Converts raw chat messages into a clean, structured conversation format and ensures every downstream agent receives consistent and validated inputs.\n#Extractor - Selects the most relevant messages for analysis based on timestamps and prevents unnecessary processing and focuses the classifier on the correct slice of data.\n# -----------------------------\n\nprint_header(\"Ingestor & Extractor\")\nclass IngestorAgent:\n    def __init__(self):\n        print(\"[Ingestor] init\")\n    def ingest_stream(self, raw_stream: List[Dict[str,Any]], platform: str='slack') -> Conversation:\n        print(\"[Ingestor] ingest_stream called\")\n        convo_id = gen_id('convo')\n        messages = []\n        for m in raw_stream:\n            msg = Message(\n                msg_id=m.get('msg_id', gen_id('msg')),\n                sender_id=m.get('sender_id','unknown'),\n                text=anonymize_text(m.get('text','')),\n                ts=m.get('ts', now_ts()),\n                attachments=m.get('attachments', [])\n            )\n            messages.append(msg)\n        conv = Conversation(convo_id=convo_id, platform=platform, messages=messages)\n        print(f\"[Ingestor] Produced conversation {convo_id} with {len(messages)} messages\")\n        return conv\n\nclass ExtractorAgent:\n    def __init__(self):\n        print(\"[Extractor] init\")\n    def extract_window(self, conv: Conversation, center_msg_idx:int=0, window_seconds:int=300):\n        print(\"[Extractor] extract_window called\")\n        if not conv.messages:\n            return []\n        center_ts = datetime.fromisoformat(conv.messages[center_msg_idx].ts.replace('Z',''))\n        lower = (center_ts - timedelta(seconds=window_seconds)).isoformat() + 'Z'\n        upper = (center_ts + timedelta(seconds=window_seconds)).isoformat() + 'Z'\n        window_msgs = [m for m in conv.messages if lower <= m.ts <= upper]\n        print(f\"[Extractor] Window size: {len(window_msgs)} (ts range {lower} - {upper})\")\n        return window_msgs\n\ningestor = IngestorAgent()\nextractor = ExtractorAgent()\nprint(\"Ingestor and Extractor Agent ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.225770Z","iopub.execute_input":"2025-11-30T07:26:01.226091Z","iopub.status.idle":"2025-11-30T07:26:01.254560Z","shell.execute_reply.started":"2025-11-30T07:26:01.226063Z","shell.execute_reply":"2025-11-30T07:26:01.253419Z"}},"outputs":[{"name":"stdout","text":"\n======== Ingestor & Extractor ========\n[Ingestor] init\n[Extractor] init\nIngestor and Extractor Agent ready.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# -----------------------------\n# Agent 4 : Classifier: MCP-aware, scalable \"LLM-sim\" mode\n#Applies multi-category harassment detection using rule-based and simulated LLM logic.\n#Acts as the first decision point that labels message severity and meaning.\n# -----------------------------\n\nprint_header(\"Harassment Classifier (MCP-aware, LLM-sim)\")\nclass HarassmentClassifierAgent:\n    def __init__(self):\n        print(\"[HarassmentClassifier] init\")\n        # small lexicons kept for rule-mode fallback\n        self.insult_keywords = set([\"stupid\",\"idiot\",\"worthless\",\"loser\",\"dumb\",\"hate you\",\"shut up\"]) \n        self.threat_keywords = set([\"kill you\",\"hurt you\",\"i'll kill\",\"i will kill\",\"die\",\"end you\"]) \n        self.doxxing_keywords = set([\"address\",\"phone\",\"where do you live\",\"i know where you live\",\"share her number\"]) \n\n    def classify_messages(self, messages: List[Message]) -> List[Dict[str,Any]]:\n        cfg = mcp.get('classifier') or {'type':'rule'}\n        mode = cfg.get('type','rule')\n        print(f\"[HarassmentClassifier] classify_messages called (mode={mode})\")\n        outputs = []\n        for m in messages:\n            if mode == 'rule':\n                out = self._rule_classify(m)\n            else:\n                out = self._llm_sim_classify(m)\n            outputs.append(out)\n            print(f\"[HarassmentClassifier] msg:{m.msg_id[:8]} labels:{[l['label'] for l in out['labels']]}\")\n        return outputs\n\n    def _rule_classify(self, m: Message):\n        text_lower = m.text.lower() if m.text else ''\n        labels = []\n        if any(k in text_lower for k in self.insult_keywords):\n            labels.append({'label':'insult','score':0.9,'span': self._find_span(text_lower,self.insult_keywords)})\n        if any(k in text_lower for k in self.threat_keywords):\n            labels.append({'label':'threat','score':0.95,'span': self._find_span(text_lower,self.threat_keywords)})\n        if any(k in text_lower for k in self.doxxing_keywords):\n            labels.append({'label':'doxxing','score':0.7,'span': self._find_span(text_lower,self.doxxing_keywords)})\n        if not labels:\n            labels = [{'label':'none','score':0.0,'span':''}]\n        return {'msg_id': m.msg_id, 'sender_id': m.sender_id, 'labels': labels, 'text': m.text}\n\n    def _llm_sim_classify(self, m: Message):\n        # Simulated LLM response: generate a rich JSON and a natural-language explanation.\n        txt = (m.text or '').strip()\n        labels = []\n        explanation = []\n        score = 0.0\n        # heuristics but produce richer textual reasoning\n        if any(k in txt.lower() for k in self.threat_keywords):\n            labels.append({'label':'threat','score':0.98,'span': self._find_span(txt.lower(), self.threat_keywords)})\n            explanation.append('Message contains explicit threat language.')\n            score = max(score, 0.98)\n        if any(k in txt.lower() for k in self.doxxing_keywords):\n            labels.append({'label':'doxxing','score':0.8,'span': self._find_span(txt.lower(), self.doxxing_keywords)})\n            explanation.append('Possible doxxing-related phrasing detected.')\n            score = max(score, 0.8)\n        if any(k in txt.lower() for k in self.insult_keywords) or re.search(r\"\\bidiot\\b|\\bdumb\\b|\\bworthless\\b\", txt.lower()):\n            labels.append({'label':'insult','score':0.9,'span': self._find_span(txt.lower(), self.insult_keywords)})\n            explanation.append('Insulting / demeaning language present.')\n            score = max(score, 0.9)\n        # If no label found, ask a clarifying simulated question in the output for interactive queries\n        if not labels:\n            labels = [{'label':'none','score':0.0,'span':''}]\n            explanation.append('No clear harassment label detected; message appears benign or ambiguous.')\n        # Build a natural language summary as the \"assistant\" output for user queries\n        nl = f\"Classifier (LLM-sim) analysis: labels={','.join([l['label'] for l in labels])}; rationale={' | '.join(explanation)}\"\n        return {'msg_id': m.msg_id, 'sender_id': m.sender_id, 'labels': labels, 'text': m.text, 'explanation': nl}\n\n    def _find_span(self, text: str, lexicon: set):\n        for k in lexicon:\n            if k in text:\n                return k\n        return ''\n\nclassifier = HarassmentClassifierAgent()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.255798Z","iopub.execute_input":"2025-11-30T07:26:01.256633Z","iopub.status.idle":"2025-11-30T07:26:01.284961Z","shell.execute_reply.started":"2025-11-30T07:26:01.256605Z","shell.execute_reply":"2025-11-30T07:26:01.283825Z"}},"outputs":[{"name":"stdout","text":"\n======== Harassment Classifier (MCP-aware, LLM-sim) ========\n[HarassmentClassifier] init\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# -----------------------------\n# Agent 5 : Pattern Detector (uses MemoryAgent)\n#Finds repeat targeting, mentions, and historical recidivism using MemoryAgent.\n#Helps the system understand whether an offender is repeating harmful behavior.\n# -----------------------------\n\nprint_header(\"Pattern Detector\")\nclass PatternDetectorAgent:\n    def __init__(self, memory_agent: MemoryAgent):\n        print(\"[PatternDetector] init\")\n        self.memory = memory_agent\n    def detect_patterns(self, conv: Conversation, classified_msgs: List[Dict[str,Any]]) -> Dict[str,Any]:\n        print(\"[PatternDetector] detect_patterns called\")\n        patterns = {'repeat_targeting': [], 'recidivism': {}}\n        for cm in classified_msgs:\n            labels = [l['label'] for l in cm['labels'] if l['label']!='none']\n            if labels:\n                sender = cm['sender_id']\n                potential_targets = re.findall(r\"@\\w+\", cm.get('text') or '')\n                for t in potential_targets:\n                    patterns['repeat_targeting'].append({'sender': sender, 'target': t, 'msg_id': cm['msg_id']})\n                # check memory for historical incidents\n                prev = self.memory.get_incidents(sender)\n                patterns['recidivism'][sender] = len(prev)\n        print(f\"[PatternDetector] found patterns: {patterns}\")\n        return patterns\n\npattern_detector = PatternDetectorAgent(memory_agent)\nprint(\"Pattern Detector Agent ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.286472Z","iopub.execute_input":"2025-11-30T07:26:01.286826Z","iopub.status.idle":"2025-11-30T07:26:01.311395Z","shell.execute_reply.started":"2025-11-30T07:26:01.286798Z","shell.execute_reply":"2025-11-30T07:26:01.310230Z"}},"outputs":[{"name":"stdout","text":"\n======== Pattern Detector ========\n[PatternDetector] init\nPattern Detector Agent ready.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# -----------------------------\n# Agent 6 : Risk Scorer (recidivism-aware)\n#Converts labels and patterns into a numerical risk score and severity class.\n#Decides whether a situation is Low, High, or Immediate risk.\n# -----------------------------\n\nprint_header(\"Risk Scorer\")\nclass RiskScorerAgent:\n    def __init__(self):\n        print(\"[RiskScorer] init\")\n    def compute_risk(self, classified_msgs: List[Dict[str,Any]], patterns: Dict[str,Any]) -> Dict[str,Any]:\n        print(\"[RiskScorer] compute_risk called\")\n        base_scores = [max((l.get('score',0.0) for l in cm['labels'])) for cm in classified_msgs] if classified_msgs else []\n        avg_score = sum(base_scores)/len(base_scores) if base_scores else 0.0\n        repeat_count = len(patterns.get('repeat_targeting', []))\n        if repeat_count >= 3:\n            avg_score = min(1.0, avg_score + 0.2)\n        # recidivism bump\n        recidivism_bump = 0.0\n        for sender, count in patterns.get('recidivism', {}).items():\n            if count > 0:\n                recidivism_bump = max(recidivism_bump, min(0.3, 0.05 * count))\n        if recidivism_bump > 0:\n            print(f\"[RiskScorer] applying recidivism bump: {recidivism_bump}\")\n            avg_score = min(1.0, avg_score + recidivism_bump)\n        severity = 'Low'\n        if avg_score >= 0.8:\n            severity = 'Immediate'\n        elif avg_score >= 0.5:\n            severity = 'High'\n        elif avg_score >= 0.2:\n            severity = 'Medium'\n        risk = {'score': avg_score, 'severity': severity}\n        print(f\"[RiskScorer] score={avg_score:.2f} severity={severity}\")\n        return risk\n\nrisk_scorer = RiskScorerAgent()\nprint(\"Risk scorer Agent ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.315837Z","iopub.execute_input":"2025-11-30T07:26:01.316843Z","iopub.status.idle":"2025-11-30T07:26:01.338063Z","shell.execute_reply.started":"2025-11-30T07:26:01.316810Z","shell.execute_reply":"2025-11-30T07:26:01.336875Z"}},"outputs":[{"name":"stdout","text":"\n======== Risk Scorer ========\n[RiskScorer] init\nRisk scorer Agent ready.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"\n# -----------------------------\n# Agent 7, 8 and 9 :  Ethics, Planner, Notifier\n# Ethics - Blocks unsafe or inappropriate actions before they reach the moderato and ensures all interventions comply with safety, fairness, and ethical guidelines.\n# Planner - Chooses the best action to take (notify HR, generate evidence, support message) and applies decision rules based on severity, threat level, and patterns.\n# Notifier - Handles human-in-the-loop communication by alerting moderators during escalations and sends supportive or guidance messages directly to affected users when appropriate.\n# -----------------------------\n\nprint_header(\"Ethics / Planner / Notifier\")\nclass EthicsAgent:\n    def __init__(self, policy: Dict[str,Any]):\n        self.policy = policy\n    def check(self, action: Dict[str,Any]) -> Dict[str,Any]:\n        if action.get('action_type') in ['ban_user','fire_employee','legal_escalation']:\n            return {'allowed': False, 'reason':'Human approval required'}\n        if action.get('action_type')=='auto_message' and not self.policy.get('allow_auto_messages', False):\n            return {'allowed': False, 'reason':'Auto messages disabled'}\n        return {'allowed': True}\n\nethics = EthicsAgent({'allow_auto_messages': True})\n\nclass InterventionPlannerAgent:\n    def plan(self, conv, classified_msgs, risk, patterns):\n        severity = risk['severity']\n        actions = []\n        if severity=='Low':\n            actions.append({'action_type':'suggest_support_message','rationale':'Offer support','message_template':'I noticed a tense exchange ‚Äî are you okay?'})\n        elif severity=='Medium':\n            actions.append({'action_type':'notify_moderator','rationale':'Moderator review recommended','message_template':''})\n        else:\n            actions.append({'action_type':'create_incident_and_notify_hr','rationale':'Escalate to HR','message_template':''})\n            actions.append({'action_type':'generate_evidence_text','rationale':'Create evidence text','message_template':''})\n        print(f\"[InterventionPlanner] planned actions: {[a['action_type'] for a in actions]}\")\n        return actions\n\nplanner = InterventionPlannerAgent()\n\nclass NotifierAgent:\n    def notify_moderator(self, incident, actions):\n        print(f\"--- Moderator Notification: Incident {incident.incident_id} (severity={incident.severity}) ---\")\n        for i,a in enumerate(actions):\n            print(f\"[{i}] Action: {a['action_type']} - {a.get('rationale','')}\")\n    def send_supportive_message(self, user_id, msg):\n        print(f\"[Notifier] Supportive message to {user_id}: {msg}\")\n\nnotifier = NotifierAgent()\nprint(\"Ethics Planner and Notifier Agent ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.339331Z","iopub.execute_input":"2025-11-30T07:26:01.339678Z","iopub.status.idle":"2025-11-30T07:26:01.364669Z","shell.execute_reply.started":"2025-11-30T07:26:01.339651Z","shell.execute_reply":"2025-11-30T07:26:01.363692Z"}},"outputs":[{"name":"stdout","text":"\n======== Ethics / Planner / Notifier ========\nEthics Planner and Notifier Agent ready.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"\n# -----------------------------\n# Agent 10 : Evidence Builder (no files: returns/prints evidence text)\n#Creates structured text evidence for incidents needing HR escalation.\n#Includes message history, labels, severity, and reasoning.\n# -----------------------------\n\nprint_header(\"Evidence Builder\")\nclass EvidenceBuilderAgent:\n    def build_evidence_text(self, conv: Conversation, classified_msgs: List[Dict[str,Any]], risk: Dict[str,Any]) -> str:\n        lines = []\n        lines.append(f\"Evidence for conversation {conv.convo_id} (platform={conv.platform})\")\n        lines.append(f\"Generated: {now_ts()}\")\n        lines.append(f\"Risk: {risk}\")\n        lines.append('\\nMessages:')\n        for cm in classified_msgs:\n            lines.append(f\"- {cm['msg_id']} | {cm['sender_id']} | {cm.get('text','')} | labels={cm['labels']}\")\n            if 'explanation' in cm:\n                lines.append(f\"  explanation: {cm['explanation']}\")\n        txt = '\\n'.join(lines)\n        print('\\n' + txt + '\\n')\n        return txt\n\nevidence_builder = EvidenceBuilderAgent()\nprint(\"Evidence Builder Agent ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.365571Z","iopub.execute_input":"2025-11-30T07:26:01.366044Z","iopub.status.idle":"2025-11-30T07:26:01.391582Z","shell.execute_reply.started":"2025-11-30T07:26:01.365990Z","shell.execute_reply":"2025-11-30T07:26:01.390607Z"}},"outputs":[{"name":"stdout","text":"\n======== Evidence Builder ========\nEvidence Builder Agent ready.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"\n# -----------------------------\n# Agent 11 : Observability (in-memory)\n# Captures logs for every stage of the pipeline (ingestion ‚Üí ethics ‚Üí finish).\n# Provides complete transparency for debugging, evaluation, and audits.\n# -----------------------------\n\nprint_header(\"Observability\")\nclass ObservabilityAgent:\n    def __init__(self):\n        self.logs = []\n    def log(self, entry: Dict[str,Any]):\n        entry['ts'] = now_ts()\n        self.logs.append(entry)\n        print(f\"[Observability] {entry.get('event','unknown')}\")\n    def dump(self):\n        # return logs for display in notebook\n        return list(self.logs)\n\nobservability = ObservabilityAgent()\nprint(\"Observability Agent ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.392531Z","iopub.execute_input":"2025-11-30T07:26:01.392844Z","iopub.status.idle":"2025-11-30T07:26:01.413362Z","shell.execute_reply.started":"2025-11-30T07:26:01.392812Z","shell.execute_reply":"2025-11-30T07:26:01.412162Z"}},"outputs":[{"name":"stdout","text":"\n======== Observability ========\nObservability Agent ready.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## üéØ Section 5 : Multi-Agent Orchestration {#orchestration}¬∂\n\nThis system coordinates multiple specialized agents‚Äîingestion, classification, pattern detection, etc into one unified workflow and each agent performs its own task independently, and the orchestrator (pipeline) links them together so the entire harassment-detection process runs automatically, end-to-end.","metadata":{}},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# COMBINED PATCH ‚Äî Overview & developer notes\n#\n# Summary:\n# This patch upgrades the notebook with production-ready demo features:\n#  - Replaces the classifier with an MCP-aware hybrid implementation (HarassmentClassifierAgent_MCP)\n#    that can run in fast 'rule' mode or a conservative 'llm' (simulated) mode via the MCP.\n#  - Installs PatternDetectorAgentV2 which uses memory (recidivism lookup) to detect repeat targeting.\n#  - Installs RiskScorerAgentV2 which applies repeat-targeting and recidivism bumps to risk scores.\n#  - Adds a lightweight MessageBus (pub/sub) for agent-to-agent communication and safe async handlers.\n#  - Exposes a FastAPI ingest stub for integration testing.\n#  - Monkeypatches pipeline.run_once to ensure MemoryAgent is updated after incidents are created.\n#\n# Why this patch:\n#  - Enables MCP-driven experiments (flip classifier mode via mcp.set(...)).\n#  - Improves detection quality by incorporating historical incidents (recidivism).\n#  - Demonstrates agent-to-agent messaging and pluggable tool usage (google_search stub).\n#  - Keeps the notebook self-contained and safe for Kaggle (no external LLM calls).\n#\n# How to use / test:\n#  1. Flip classifier mode: mcp.set('classifier', {'type':'rule'})  (or {'type':'llm'} for demo).\n#  2. Run a single abusive stream multiple times (3+) ‚Äî observe risk bump from repeat-targeting.\n#  3. Check user memory table and incidents: SELECT * FROM user_profiles / incidents (or use cur.execute).\n# -----------------------------------------------------------------------------\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.414441Z","iopub.execute_input":"2025-11-30T07:26:01.415147Z","iopub.status.idle":"2025-11-30T07:26:01.439163Z","shell.execute_reply.started":"2025-11-30T07:26:01.415091Z","shell.execute_reply":"2025-11-30T07:26:01.438176Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# ------------------ COMBINED PATCH CELL ------------------\nprint_header(\"Applying combined patch: MCP-aware classifier, PatternDetectorV2, RiskScorerV2, MessageBus, pipeline memory update\")\n\n# 1) MCP-aware classifier (safe replacement)\nclass HarassmentClassifierAgent_MCP:\n    def __init__(self):\n        print(\"[HarassmentClassifier_MCP] init\")\n        self.insult_keywords = set([\"stupid\",\"idiot\",\"worthless\",\"loser\",\"dumb\",\"hate you\",\"shut up\"])\n        self.threat_keywords = set([\"kill you\",\"hurt you\",\"i'll kill\",\"i will kill\",\"die\",\"end you\"])\n        self.doxxing_keywords = set([\"address\",\"phone\",\"where do you live\",\"i know where you live\",\"share her number\"])\n\n    def classify_messages(self, messages: List[Message]) -> List[Dict[str, Any]]:\n        print(\"[HarassmentClassifier_MCP] classify_messages called\")\n        outputs = []\n        cfg = mcp.get('classifier') if 'mcp' in globals() else {'type':'rule'}\n        mode = cfg.get('type', 'rule')\n        for m in messages:\n            if mode == 'rule':\n                text_lower = m.text.lower()\n                labels = []\n                if any(k in text_lower for k in self.insult_keywords):\n                    labels.append({'label':'insult', 'score':0.9, 'span': self._find_span(text_lower, self.insult_keywords)})\n                if any(k in text_lower for k in self.threat_keywords):\n                    labels.append({'label':'threat', 'score':0.95, 'span': self._find_span(text_lower, self.threat_keywords)})\n                if any(k in text_lower for k in self.doxxing_keywords):\n                    labels.append({'label':'doxxing', 'score':0.7, 'span': self._find_span(text_lower, self.doxxing_keywords)})\n                if not labels:\n                    labels = [{'label':'none', 'score':0.0, 'span':''}]\n                out = {'msg_id': m.msg_id, 'sender_id': m.sender_id, 'labels': labels, 'text': m.text}\n                outputs.append(out)\n                print(f\"[HarassmentClassifier_MCP] msg:{m.msg_id[:8]} labels:{[l['label'] for l in labels]}\")\n            else:\n                # LLM mode placeholder: show prompt, optionally call a safe tool\n                prompt = f\"Classify the following message for harassment categories: {m.text}\"\n                print(f\"[HarassmentClassifier_MCP][LLM-mode] prompt: {prompt[:120]}\")\n                tool_result = None\n                if 'tool_registry' in globals() and tool_registry.get('google_search'):\n                    tool_result = tool_registry['google_search'].run(m.text)\n                # conservative fallback\n                labels = [{'label':'none', 'score':0.0, 'span':''}]\n                out = {'msg_id': m.msg_id, 'sender_id': m.sender_id, 'labels': labels, 'text': m.text, 'tool_result': tool_result}\n                outputs.append(out)\n                print(f\"[HarassmentClassifier_MCP][LLM-mode] msg:{m.msg_id[:8]} labels:{[l['label'] for l in labels]}\")\n        return outputs\n\n    def _find_span(self, text: str, lexicon: set):\n        for k in lexicon:\n            if k in text:\n                return k\n        return ''\n\n# create and attach\nclassifier = HarassmentClassifierAgent_MCP()\nprint(\"Replaced classifier with HarassmentClassifierAgent_MCP\")\nmcp.set('classifier', {'type':'rule','version':'v0'})\ntry:\n    pipeline.classifier = classifier\n    print(\"pipeline.classifier updated.\")\nexcept Exception:\n    print(\"pipeline not present or not yet instantiated; classifier object ready.\")\n\n# 2) PatternDetector V2 (uses memory_agent.get_incidents if available)\nclass PatternDetectorAgentV2:\n    def __init__(self, memory_conn):\n        print(\"[PatternDetectorV2] init\")\n        self.conn = memory_conn\n\n    def detect_patterns(self, conv: Conversation, classified_msgs: List[Dict[str, Any]]) -> Dict[str, Any]:\n        print(\"[PatternDetectorV2] detect_patterns called\")\n        patterns = {'repeat_targeting': [], 'recidivism': {}}\n        for cm in classified_msgs:\n            labels = [l['label'] for l in cm['labels'] if l['label'] != 'none']\n            if labels:\n                sender = cm['sender_id']\n                potential_targets = re.findall(r\"@\\w+\", cm.get('text','') or '')\n                for t in potential_targets:\n                    patterns['repeat_targeting'].append({'sender': sender, 'target': t, 'msg_id': cm['msg_id']})\n                # historical incidents via memory_agent\n                if 'memory_agent' in globals():\n                    try:\n                        prev_incs = memory_agent.get_incidents(sender)\n                        patterns['recidivism'][sender] = len(prev_incs)\n                    except Exception as e:\n                        print(\"[PatternDetectorV2] memory_agent.get_incidents error:\", e)\n        print(f\"[PatternDetectorV2] found patterns: {patterns}\")\n        return patterns\n\npattern_detector = PatternDetectorAgentV2(conn)\nprint(\"Instantiated PatternDetectorAgentV2 and assigned to 'pattern_detector'\")\n\n# 3) RiskScorer V2 (applies recidivism bump)\nclass RiskScorerAgentV2:\n    def __init__(self):\n        print(\"[RiskScorerV2] init\")\n\n    def compute_risk(self, classified_msgs: List[Dict[str, Any]], patterns: Dict[str, Any]) -> Dict[str, Any]:\n        print(\"[RiskScorerV2] compute_risk called\")\n        base_scores = []\n        for cm in classified_msgs:\n            max_score = max(l.get('score', 0.0) for l in cm['labels'])\n            base_scores.append(max_score)\n        avg_score = sum(base_scores) / len(base_scores) if base_scores else 0.0\n        repeat_count = len(patterns.get('repeat_targeting', []))\n        if repeat_count >= 3:\n            avg_score = min(1.0, avg_score + 0.2)\n        # recidivism bump\n        recidivism_bump = 0.0\n        if 'recidivism' in patterns:\n            for sender, count in patterns['recidivism'].items():\n                if count >= 1:\n                    recidivism_bump = max(recidivism_bump, min(0.3, 0.05 * count))\n        if recidivism_bump > 0:\n            print(f\"[RiskScorerV2] applying recidivism bump: {recidivism_bump}\")\n            avg_score = min(1.0, avg_score + recidivism_bump)\n        severity = 'Low'\n        if avg_score >= 0.8:\n            severity = 'Immediate'\n        elif avg_score >= 0.5:\n            severity = 'High'\n        elif avg_score >= 0.2:\n            severity = 'Medium'\n        risk = {'score': avg_score, 'severity': severity}\n        print(f\"[RiskScorerV2] score={avg_score:.2f} severity={severity}\")\n        return risk\n\nrisk_scorer = RiskScorerAgentV2()\nprint(\"Instantiated RiskScorerAgentV2 and assigned to 'risk_scorer'\")\n\n# Reattach components to pipeline if available\ntry:\n    pipeline.pattern_detector = pattern_detector\n    pipeline.risk_scorer = risk_scorer\n    pipeline.classifier = classifier\n    print(\"Reattached pattern_detector, risk_scorer, classifier to pipeline.\")\nexcept Exception:\n    print(\"Pipeline not present; components ready to attach when pipeline is re-created.\")\n\n# 4) MessageBus A2A pub/sub\nclass MessageBus:\n    def __init__(self):\n        self.handlers = {}\n    def register(self, topic, fn):\n        self.handlers.setdefault(topic, []).append(fn)\n    def publish(self, topic, payload):\n        print(f\"[MessageBus] publish: {topic}\")\n        for h in self.handlers.get(topic, []):\n            try:\n                h(payload)\n            except Exception as e:\n                print(f\"[MessageBus] handler error: {e}\")\n\nbus = MessageBus()\nprint(\"MessageBus initialized.\")\n\n# Example handler: on classified messages, run async pattern detection (demo)\ndef _pattern_handler(payload):\n    try:\n        conv = payload.get('conv')\n        classified = payload.get('classified')\n        pd = pattern_detector.detect_patterns(conv, classified)\n        print(\"[MessageBus pattern_handler] detected patterns:\", pd)\n    except Exception as e:\n        print(\"[MessageBus pattern_handler] error:\", e)\n\n# register handler (safe if pattern_detector exists)\nif 'pattern_detector' in globals():\n    bus.register('classified_messages', _pattern_handler)\n    print(\"Registered pattern_handler on topic 'classified_messages'\")\n\n# 5) FastAPI stub\ntry:\n    from fastapi import FastAPI\n    from pydantic import BaseModel\n    app = FastAPI()\n    class IngestPayload(BaseModel):\n        messages: list\n    @app.post('/ingest')\n    def ingest_endpoint(payload: IngestPayload):\n        stream = payload.messages\n        incident = pipeline.run_once(stream)\n        return {'incident_id': incident.incident_id, 'severity': incident.severity}\n    print(\"FastAPI stub defined. (Not running server in notebook.)\")\nexcept Exception:\n    print(\"FastAPI not available in this environment (optional).\")\n\n# 6) Monkeypatch pipeline.run_once to update MemoryAgent after incident creation\ntry:\n    if 'pipeline' in globals():\n        old_run = pipeline.run_once\n        def _run_and_update_memory(raw_stream):\n            # call existing pipeline logic (which returns an Incident)\n            incident = old_run(raw_stream)\n            # update memory agent for involved users if available\n            try:\n                if 'memory_agent' in globals():\n                    for u in incident.involved_user_ids:\n                        try:\n                            memory_agent.append_incident(u, incident.incident_id)\n                        except Exception as e:\n                            print(\"[pipeline memory update] append_incident error:\", e)\n                    print(\"[pipeline memory update] updated memory_agent for involved users.\")\n            except Exception as e:\n                print(\"[pipeline memory update] unexpected error:\", e)\n            return incident\n        pipeline.run_once = _run_and_update_memory\n        print(\"Pipeline.run_once monkeypatched: will now update memory_agent after creating incidents.\")\n    else:\n        print(\"No pipeline object found; cannot monkeypatch run_once. Create pipeline then re-run this cell.\")\nexcept Exception as e:\n    print(\"Error patching pipeline.run_once:\", e)\n\nprint_header(\"COMBINED PATCH APPLIED - Test suggestion\")\nprint(\"Suggested test: run one abusive stream multiple times (3+) to see recidivism bump in RiskScorerV2.\")\nprint(\"To flip classifier to LLM-mode (demo), run: mcp.set('classifier', {'type':'llm','version':'v1'})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:01.440585Z","iopub.execute_input":"2025-11-30T07:26:01.440906Z","iopub.status.idle":"2025-11-30T07:26:02.410059Z","shell.execute_reply.started":"2025-11-30T07:26:01.440877Z","shell.execute_reply":"2025-11-30T07:26:02.408483Z"}},"outputs":[{"name":"stdout","text":"\n======== Applying combined patch: MCP-aware classifier, PatternDetectorV2, RiskScorerV2, MessageBus, pipeline memory update ========\n[HarassmentClassifier_MCP] init\nReplaced classifier with HarassmentClassifierAgent_MCP\npipeline not present or not yet instantiated; classifier object ready.\n[PatternDetectorV2] init\nInstantiated PatternDetectorAgentV2 and assigned to 'pattern_detector'\n[RiskScorerV2] init\nInstantiated RiskScorerAgentV2 and assigned to 'risk_scorer'\nPipeline not present; components ready to attach when pipeline is re-created.\nMessageBus initialized.\nRegistered pattern_handler on topic 'classified_messages'\nFastAPI stub defined. (Not running server in notebook.)\nNo pipeline object found; cannot monkeypatch run_once. Create pipeline then re-run this cell.\n\n======== COMBINED PATCH APPLIED - Test suggestion ========\nSuggested test: run one abusive stream multiple times (3+) to see recidivism bump in RiskScorerV2.\nTo flip classifier to LLM-mode (demo), run: mcp.set('classifier', {'type':'llm','version':'v1'})\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## üß© Section 6 : Pipeline Setup and Initialization (#initialization)\n This section ensures pipeline components (planner, classifier, pattern detector, etc.)\nare created and attached in a safe order, provide repair hooks, and avoid NameError/TypeError","metadata":{}},{"cell_type":"code","source":"# --- FIX: Ensure planner exists before pipeline creation ---\n# Purpose: guard against NameError when pipeline is instantiated before certain agents.\n# Behavior:\n#  - Check if 'planner', 'ethics', 'notifier', etc. are in globals()\n#  - If missing, create minimal safe stub objects (no-op or logging-only)\n#  - This lets pipeline be instantiated reliably while dev iterates on agents\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.411310Z","iopub.execute_input":"2025-11-30T07:26:02.411832Z","iopub.status.idle":"2025-11-30T07:26:02.418049Z","shell.execute_reply.started":"2025-11-30T07:26:02.411759Z","shell.execute_reply":"2025-11-30T07:26:02.415853Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# --- FIX: Ensure planner exists before pipeline creation ---\nif 'planner' not in globals():\n    print(\"planner not found ‚Äî creating a default InterventionPlannerAgent()\")\n\n    class InterventionPlannerAgent:\n        def __init__(self):\n            print(\"[InterventionPlanner] init\")\n\n        def plan(self, conv, classified_msgs, risk, patterns):\n            severity = risk['severity']\n            actions = []\n            if severity == 'Low':\n                actions.append({\n                    'action_type':'suggest_support_message',\n                    'rationale':'Low severity; offer support to target'\n                })\n            elif severity == 'Medium':\n                actions.append({\n                    'action_type':'notify_moderator',\n                    'rationale':'Medium severity; moderator review recommended'\n                })\n            else:\n                actions.append({\n                    'action_type':'create_incident_and_notify_hr',\n                    'rationale':'High/Immediate severity; escalate to HR'\n                })\n            return actions\n\n    planner = InterventionPlannerAgent()\n\nprint(\"planner is ready:\", planner)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.419332Z","iopub.execute_input":"2025-11-30T07:26:02.419718Z","iopub.status.idle":"2025-11-30T07:26:02.444152Z","shell.execute_reply.started":"2025-11-30T07:26:02.419690Z","shell.execute_reply":"2025-11-30T07:26:02.442405Z"}},"outputs":[{"name":"stdout","text":"planner is ready: <__main__.InterventionPlannerAgent object at 0x7f9dbd9b9b90>\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# --- Safe Bootstrap Cell ---\n# Purpose: create deterministic minimal runtime baseline.\n# Behavior:\n#  - sets up ModelControlPlane (mcp) and tool_registry\n#  - creates or connects to memory DB/connection placeholder\n#  - defines lightweight MemoryAgent stub if not defined.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.445233Z","iopub.execute_input":"2025-11-30T07:26:02.445758Z","iopub.status.idle":"2025-11-30T07:26:02.464852Z","shell.execute_reply.started":"2025-11-30T07:26:02.445724Z","shell.execute_reply":"2025-11-30T07:26:02.463477Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# -----------------------------\n# SAFE BOOTSTRAP CELL ‚Äî create missing agents & instantiate pipeline\n# -----------------------------\nimport types, inspect\n\nprint(\"\\n==== SAFE BOOTSTRAP: ensuring required agents & pipeline ====\")\n\n# Helper: create a minimal default implementation only if missing\ndef ensure(name, creator_fn):\n    if name in globals() and globals()[name] is not None:\n        print(f\"‚úî {name} already present\")\n        return globals()[name]\n    else:\n        obj = creator_fn()\n        globals()[name] = obj\n        print(f\"‚úî Created default {name}\")\n        return obj\n\n# Default simple classes (only created if the user hasn't defined them)\ndef make_ethics():\n    class EthicsAgent:\n        def __init__(self, policy=None):\n            self.policy = policy or {'allow_auto_messages': True}\n            print(\"[Ethics] default created\")\n        def check(self, action):\n            if action.get('action_type') in ['ban_user','fire_employee','legal_escalation']:\n                return {'allowed': False, 'reason': 'Human approval required'}\n            if action.get('action_type') == 'auto_message' and not self.policy.get('allow_auto_messages', False):\n                return {'allowed': False, 'reason': 'Auto messages disabled'}\n            return {'allowed': True}\n    return EthicsAgent({'allow_auto_messages': True})\n\ndef make_notifier():\n    class NotifierAgent:\n        def notify_moderator(self, incident, actions):\n            try:\n                iid = incident.incident_id\n            except Exception:\n                # incident may be a tuple ‚Äî be resilient\n                try:\n                    iid = incident[0].incident_id\n                except Exception:\n                    iid = getattr(incident, 'incident_id', '<unknown>')\n            print(f\"[Notifier] Incident {iid} notify (simulated). Actions: {[a['action_type'] for a in actions]}\")\n        def send_supportive_message(self, user_id, msg):\n            print(f\"[Notifier] Supportive message to {user_id}: {msg}\")\n    return NotifierAgent()\n\ndef make_observability():\n    class ObservabilityAgent:\n        def __init__(self):\n            self.logs = []\n            print(\"[Observability] default created\")\n        def log(self, entry):\n            entry = dict(entry)\n            entry['ts'] = datetime.utcnow().isoformat() + \"Z\"\n            self.logs.append(entry)\n            print(f\"[Observability] {entry.get('event','unknown')}\")\n        def dump(self):\n            return list(self.logs)\n    return ObservabilityAgent()\n\ndef make_planner():\n    class InterventionPlannerAgent:\n        def __init__(self):\n            print(\"[InterventionPlanner] default created\")\n        def plan(self, conv, classified_msgs, risk, patterns):\n            severity = risk.get('severity') if isinstance(risk, dict) else 'Low'\n            actions = []\n            if severity == 'Low':\n                actions.append({'action_type':'suggest_support_message','rationale':'Offer support'})\n            elif severity == 'Medium':\n                actions.append({'action_type':'notify_moderator','rationale':'Moderator review recommended'})\n            else:\n                actions.append({'action_type':'create_incident_and_notify_hr','rationale':'Escalate to HR'})\n                actions.append({'action_type':'generate_evidence_text','rationale':'Create evidence text'})\n            return actions\n    return InterventionPlannerAgent()\n\ndef make_pattern_detector():\n    class PatternDetectorAgent:\n        def __init__(self, memory_agent=None):\n            self.memory = memory_agent\n            print(\"[PatternDetector] default created\")\n        def detect_patterns(self, conv, classified_msgs):\n            patterns = {'repeat_targeting': [], 'recidivism': {}}\n            for cm in classified_msgs:\n                labels = [l['label'] for l in cm.get('labels',[]) if l.get('label')!='none']\n                if labels:\n                    sender = cm.get('sender_id')\n                    text = cm.get('text','') or ''\n                    for t in re.findall(r\"@\\w+\", text):\n                        patterns['repeat_targeting'].append({'sender': sender, 'target': t, 'msg_id': cm.get('msg_id')})\n                    if self.memory:\n                        try:\n                            prev = self.memory.get_incidents(sender)\n                            patterns['recidivism'][sender] = len(prev)\n                        except Exception:\n                            patterns['recidivism'][sender] = 0\n            return patterns\n    return PatternDetectorAgent(memory_agent if 'memory_agent' in globals() else None)\n\ndef make_risk_scorer():\n    class RiskScorerAgent:\n        def __init__(self):\n            print(\"[RiskScorer] default created\")\n        def compute_risk(self, classified_msgs, patterns):\n            base_scores = []\n            for cm in classified_msgs:\n                s = max((l.get('score',0.0) for l in cm.get('labels',[])), default=0.0)\n                base_scores.append(s)\n            avg = sum(base_scores)/len(base_scores) if base_scores else 0.0\n            repeat_count = len(patterns.get('repeat_targeting',[])) if isinstance(patterns, dict) else 0\n            if repeat_count >= 3:\n                avg = min(1.0, avg + 0.2)\n            # recidivism bump (safe)\n            bump = 0.0\n            for cnt in (patterns.get('recidivism',{}).values() if isinstance(patterns, dict) else []):\n                if cnt>0:\n                    bump = max(bump, min(0.3, 0.05*cnt))\n            avg = min(1.0, avg + bump)\n            severity = 'Low'\n            if avg >= 0.8: severity='Immediate'\n            elif avg >= 0.5: severity='High'\n            elif avg >= 0.2: severity='Medium'\n            return {'score': avg, 'severity': severity}\n    return RiskScorerAgent()\n\ndef make_classifier():\n    class HarassmentClassifierAgent:\n        def __init__(self):\n            self.insult_keywords = set([\"stupid\",\"idiot\",\"worthless\",\"loser\",\"dumb\",\"hate you\",\"shut up\"])\n            self.threat_keywords = set([\"kill you\",\"hurt you\",\"i'll kill\",\"i will kill\",\"die\",\"end you\"])\n            self.doxxing_keywords = set([\"address\",\"phone\",\"where do you live\",\"i know where you live\",\"share her number\"])\n            print(\"[Classifier] default created\")\n        def _find_span(self, text, lex):\n            for k in lex:\n                if k in text: return k\n            return ''\n        def classify_messages(self, messages):\n            outputs=[]\n            mode = (mcp.get('classifier') or {}).get('type','rule') if 'mcp' in globals() else 'rule'\n            for m in messages:\n                t = (m.get('text') if isinstance(m, dict) else getattr(m,'text', '')) if isinstance(m, dict) or hasattr(m,'text') else ''\n                text_lower = (t or '').lower()\n                labels=[]\n                if any(k in text_lower for k in self.threat_keywords):\n                    labels.append({'label':'threat','score':0.98,'span':self._find_span(text_lower,self.threat_keywords)})\n                if any(k in text_lower for k in self.doxxing_keywords):\n                    labels.append({'label':'doxxing','score':0.8,'span':self._find_span(text_lower,self.doxxing_keywords)})\n                if any(k in text_lower for k in self.insult_keywords) or re.search(r\"\\bidiot\\b|\\bdumb\\b|\\bworthless\\b\", text_lower):\n                    labels.append({'label':'insult','score':0.9,'span':self._find_span(text_lower,self.insult_keywords)})\n                if not labels:\n                    labels=[{'label':'none','score':0.0,'span':''}]\n                # support both Message objects and dict-like items\n                msg_id = (m.get('msg_id') if isinstance(m, dict) else getattr(m, 'msg_id', gen_id('msg')))\n                sender_id = (m.get('sender_id') if isinstance(m, dict) else getattr(m, 'sender_id', 'unknown'))\n                outputs.append({'msg_id': msg_id, 'sender_id': sender_id, 'labels': labels, 'text': t})\n            return outputs\n    return HarassmentClassifierAgent()\n\ndef make_ingestor():\n    class IngestorAgent:\n        def ingest_stream(self, raw_stream, platform='slack'):\n            convo_id = gen_id('convo')\n            messages=[]\n            for m in raw_stream:\n                mid = m.get('msg_id') if isinstance(m, dict) else getattr(m,'msg_id', gen_id('msg'))\n                sender = m.get('sender_id') if isinstance(m, dict) else getattr(m,'sender_id','unknown')\n                txt = anonymize_text(m.get('text','') if isinstance(m, dict) else getattr(m,'text',''))\n                ts = m.get('ts') if isinstance(m, dict) else getattr(m,'ts', now_ts())\n                messages.append({'msg_id': mid, 'sender_id': sender, 'text': txt, 'ts': ts})\n            # Return a minimal convo-like object with attributes used downstream\n            return types.SimpleNamespace(convo_id=convo_id, platform=platform, messages=[types.SimpleNamespace(**mm) for mm in messages])\n    return IngestorAgent()\n\ndef make_extractor():\n    class ExtractorAgent:\n        def extract_window(self, conv, center_msg_idx=0, window_seconds=300):\n            if not getattr(conv,'messages',[]): return []\n            center_ts = datetime.fromisoformat(conv.messages[center_msg_idx].ts.replace('Z',''))\n            lower=(center_ts - timedelta(seconds=window_seconds)).isoformat()+'Z'\n            upper=(center_ts + timedelta(seconds=window_seconds)).isoformat()+'Z'\n            window_msgs = [m for m in conv.messages if lower <= getattr(m,'ts',now_ts()) <= upper]\n            return window_msgs\n    return ExtractorAgent()\n\ndef make_evidence_builder():\n    class EvidenceBuilderAgent:\n        def build_evidence_text(self, conv, classified_msgs, risk):\n            lines=[f\"Evidence for convo {getattr(conv,'convo_id','<conv>')}\",\"Generated: \"+now_ts(), f\"Risk: {risk}\", \"Messages:\"]\n            for cm in classified_msgs:\n                lines.append(f\"- {cm.get('msg_id')} | {cm.get('sender_id')} | {cm.get('text')} | labels={cm.get('labels')}\")\n            txt = \"\\n\".join(lines)\n            print(txt)\n            return txt\n    return EvidenceBuilderAgent()\n\n# Ensure memory_agent exists (in-memory SQLite expected by user's notebook)\nif 'memory_agent' not in globals():\n    # create a tiny MemoryAgent that stores in a dict (non-persistent)\n    class MemoryAgentSimple:\n        def __init__(self):\n            self.mem = {}\n            print(\"[MemoryAgentSimple] created (in-memory dict)\")\n        def append_incident(self,user_id, incident_id):\n            self.mem.setdefault(user_id, []).append(incident_id)\n        def get_incidents(self, user_id):\n            return list(self.mem.get(user_id, []))\n    memory_agent = MemoryAgentSimple()\n    globals()['memory_agent'] = memory_agent\nelse:\n    print(\"‚úî memory_agent present\")\n\n# Create/ensure other agents (will not overwrite user-defined ones)\nensure('ethics', lambda: make_ethics())\nensure('notifier', lambda: make_notifier())\nensure('observability', lambda: make_observability())\nensure('planner', lambda: make_planner())\nensure('pattern_detector', lambda: make_pattern_detector())\nensure('risk_scorer', lambda: make_risk_scorer())\nensure('classifier', lambda: make_classifier())\nensure('ingestor', lambda: make_ingestor())\nensure('extractor', lambda: make_extractor())\nensure('evidence_builder', lambda: make_evidence_builder())\n\n# Now define a robust pipeline that tolerates missing/tuple returns\nprint(\"\\nConstructing SilentGuardianPipeline (robust)...\")\nclass SilentGuardianPipelineRobust:\n    def __init__(self):\n        self.ingestor = globals().get('ingestor')\n        self.extractor = globals().get('extractor')\n        self.classifier = globals().get('classifier')\n        self.pattern_detector = globals().get('pattern_detector')\n        self.risk_scorer = globals().get('risk_scorer')\n        self.planner = globals().get('planner')\n        self.evidence_builder = globals().get('evidence_builder')\n        self.ethics = globals().get('ethics')\n        self.notifier = globals().get('notifier')\n        self.observability = globals().get('observability')\n        self.memory = globals().get('memory_agent')\n        print(\"[PipelineRobust] created with components:\",\n              \"ingestor\", bool(self.ingestor),\n              \"classifier\", bool(self.classifier),\n              \"pattern_detector\", bool(self.pattern_detector))\n\n    def run_once(self, raw_stream):\n        print(\"[PipelineRobust] run_once called\")\n        conv = self.ingestor.ingest_stream(raw_stream)\n        # Logging safe\n        try:\n            self.observability.log({'event':'ingested_conversation','convo_id': conv.convo_id, 'n_messages': len(conv.messages)})\n        except Exception:\n            pass\n        # Extract window (safe)\n        try:\n            window_msgs = self.extractor.extract_window(conv, center_msg_idx=max(0, len(conv.messages)-1))\n        except Exception:\n            window_msgs = getattr(conv, 'messages', [])\n        # Classify (supports both objects and dicts)\n        classified = self.classifier.classify_messages(window_msgs)\n        # Detect patterns\n        patterns = {}\n        try:\n            patterns = self.pattern_detector.detect_patterns(conv, classified)\n        except Exception as e:\n            print(\"[PipelineRobust] pattern_detector error:\", e); patterns = {}\n        # Score risk\n        risk = self.risk_scorer.compute_risk(classified, patterns)\n        # Plan actions\n        actions = self.planner.plan(conv, classified, risk, patterns)\n        # Ethics filter\n        filtered_actions = []\n        for a in actions:\n            try:\n                check = self.ethics.check(a)\n            except Exception:\n                check = {'allowed': True}\n            try:\n                self.observability.log({'event':'ethics_check','action': a.get('action_type'), 'result': check})\n            except Exception:\n                pass\n            if check.get('allowed'):\n                filtered_actions.append(a)\n        # Evidence text if requested\n        evidence_text = None\n        if any(a.get('action_type')=='generate_evidence_text' for a in filtered_actions):\n            try:\n                evidence_text = self.evidence_builder.build_evidence_text(conv, classified, risk)\n            except Exception as e:\n                print(\"[PipelineRobust] evidence builder error:\", e)\n                evidence_text = None\n        # Build incident object (SimpleNamespace) to keep consistent shape\n        incident = types.SimpleNamespace(\n            incident_id = gen_id('incident'),\n            convo_id = getattr(conv,'convo_id', gen_id('convo')),\n            involved_user_ids = list({getattr(m,'sender_id', None) for m in getattr(conv,'messages',[]) if getattr(m,'sender_id',None)}),\n            start_ts = getattr(conv.messages[0],'ts', now_ts()) if getattr(conv,'messages',None) else now_ts(),\n            end_ts = getattr(conv.messages[-1],'ts', now_ts()) if getattr(conv,'messages',None) else now_ts(),\n            labels = [l for cm in classified for l in cm.get('labels',[])],\n            severity = risk.get('severity') if isinstance(risk, dict) else 'Low',\n            evidence = evidence_text,\n            status = 'new'\n        )\n        # store minimal incident in memory_agent if possible\n        try:\n            for u in incident.involved_user_ids:\n                if self.memory:\n                    self.memory.append_incident(u, incident.incident_id)\n        except Exception as e:\n            print(\"[PipelineRobust] memory append error:\", e)\n        # Notify moderator (resilient)\n        try:\n            self.notifier.notify_moderator(incident, filtered_actions)\n        except Exception as e:\n            print(\"[PipelineRobust] notifier error:\", e)\n        try:\n            self.observability.log({'event':'pipeline_complete', 'incident_id': incident.incident_id, 'severity': incident.severity})\n        except Exception:\n            pass\n        # Return standardized tuple: (incident, conv, classified, patterns, risk)\n        return incident, conv, classified, patterns, risk\n\n# Instantiate robust pipeline and place into globals under the expected name\npipeline = SilentGuardianPipelineRobust()\nglobals()['pipeline'] = pipeline\nprint(\"\\n‚úî pipeline (robust) is ready and assigned to variable 'pipeline'\")\nprint(\"You can now call: incident, conv, classified, patterns, risk = pipeline.run_once(stream)\")\nprint(\"==== SAFE BOOTSTRAP complete ====\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.466221Z","iopub.execute_input":"2025-11-30T07:26:02.466609Z","iopub.status.idle":"2025-11-30T07:26:02.525406Z","shell.execute_reply.started":"2025-11-30T07:26:02.466579Z","shell.execute_reply":"2025-11-30T07:26:02.524326Z"}},"outputs":[{"name":"stdout","text":"\n==== SAFE BOOTSTRAP: ensuring required agents & pipeline ====\n‚úî memory_agent present\n‚úî ethics already present\n‚úî notifier already present\n‚úî observability already present\n‚úî planner already present\n‚úî pattern_detector already present\n‚úî risk_scorer already present\n‚úî classifier already present\n‚úî ingestor already present\n‚úî extractor already present\n‚úî evidence_builder already present\n\nConstructing SilentGuardianPipeline (robust)...\n[PipelineRobust] created with components: ingestor True classifier True pattern_detector True\n\n‚úî pipeline (robust) is ready and assigned to variable 'pipeline'\nYou can now call: incident, conv, classified, patterns, risk = pipeline.run_once(stream)\n==== SAFE BOOTSTRAP complete ====\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Restore print_header safely\ndef print_header(title: str):\n    print(\"\\n\" + \"=\"*8 + f\" {title} \" + \"=\"*8 + \"\\n\")\n\nprint(\"‚úî print_header restored.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.526425Z","iopub.execute_input":"2025-11-30T07:26:02.526797Z","iopub.status.idle":"2025-11-30T07:26:02.551274Z","shell.execute_reply.started":"2025-11-30T07:26:02.526768Z","shell.execute_reply":"2025-11-30T07:26:02.550118Z"}},"outputs":[{"name":"stdout","text":"‚úî print_header restored.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# --- Repair Cell (hotfixes / monkeypatches) ---\n# Purpose: patch broken or partially-applied state after manual edits.\n# Examples:\n#  - ensure observability.logs exists (fix AttributeError)\n#  - replace pipeline.classifier/pipeline.pattern_detector when updated classes are defined\n#  - make pipeline.run_once wrapper tuple-safe (handles both dataclass and tuple returns)\n# Use: run when you see NameError/AttributeError after re-editing components.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.552780Z","iopub.execute_input":"2025-11-30T07:26:02.553194Z","iopub.status.idle":"2025-11-30T07:26:02.574860Z","shell.execute_reply.started":"2025-11-30T07:26:02.553157Z","shell.execute_reply":"2025-11-30T07:26:02.573771Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# --- REPAIR CELL: Ensure all agents exist before Pipeline ---\n\n# 1. Pattern Detector\ntry:\n    pattern_detector\n    print(\"[Repair] pattern_detector already exists.\")\nexcept NameError:\n    print(\"[Repair] Creating pattern_detector...\")\n    class PatternDetector_Fix:\n        def detect_patterns(self, conv, classified):\n            return {'repeat_targeting': [], 'recidivism': {}}\n    pattern_detector = PatternDetector_Fix()\n\n# 2. Risk Scorer\ntry:\n    risk_scorer\nexcept NameError:\n    class RiskScorer_Fix:\n        def compute_risk(self, classified, patterns):\n            return {'score':0.0, 'severity':'Low'}\n    risk_scorer = RiskScorer_Fix()\n\n# 3. Planner\ntry:\n    planner\nexcept NameError:\n    class Planner_Fix:\n        def plan(self, conv, classified, risk, patterns):\n            return [{'action_type':'suggest_support_message'}]\n    planner = Planner_Fix()\n\n# 4. Ethics Agent\ntry:\n    ethics\nexcept NameError:\n    class Ethics_Fix:\n        def check(self, action):\n            return {'allowed': True}\n    ethics = Ethics_Fix()\n\n# 5. Notifier\ntry:\n    notifier\nexcept NameError:\n    class Notifier_Fix:\n        def notify_moderator(self, incident, actions):\n            print(\"[Notifier_Fix] moderator notified\")\n    notifier = Notifier_Fix()\n\n# 6. Observability\ntry:\n    observability\nexcept NameError:\n    class Obs_Fix:\n        def __init__(self): self.logs=[]\n        def log(self, entry): self.logs.append(entry)\n    observability = Obs_Fix()\n\n# 7. Memory Agent\ntry:\n    memory_agent\nexcept NameError:\n    class Memory_Fix:\n        def append_incident(self,u,i): pass\n    memory_agent = Memory_Fix()\n\nprint(\"‚úî All required components exist now.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.576176Z","iopub.execute_input":"2025-11-30T07:26:02.576558Z","iopub.status.idle":"2025-11-30T07:26:02.594839Z","shell.execute_reply.started":"2025-11-30T07:26:02.576460Z","shell.execute_reply":"2025-11-30T07:26:02.593645Z"}},"outputs":[{"name":"stdout","text":"[Repair] pattern_detector already exists.\n‚úî All required components exist now.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# --- Safe Pipeline Builder Cell ---\n# Purpose: instantiate the pipeline in a defensive manner.\n# Behavior:\n#  - verify required agent globals exist (ingestor, extractor, classifier, pattern_detector, risk_scorer, planner, ethics, notifier, evidence_builder, observability, memory_agent)\n#  - if any missing, attach a small safe stub that logs calls (no destructive behavior)\n#  - print a short summary of attached components (so you can confirm)\n# Use: run this cell to (re)create a stable pipeline object after edits.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.595944Z","iopub.execute_input":"2025-11-30T07:26:02.596279Z","iopub.status.idle":"2025-11-30T07:26:02.617045Z","shell.execute_reply.started":"2025-11-30T07:26:02.596252Z","shell.execute_reply":"2025-11-30T07:26:02.615875Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# -----------------------------\n# Safe pipeline builder cell (paste this into your notebook)\n# -----------------------------\nfrom typing import List, Dict, Any\n\nprint_header(\"Safe Pipeline Builder (auto-fallbacks)\")\n\n# Helper: create a minimal stub implementation for an agent type if it's missing\ndef make_stub(name):\n    class Stub:\n        def __init__(self):\n            print(f\"[Stub:{name}] created\")\n        # common minimal methods used by pipeline\n        def ingest_stream(self, raw_stream, platform='slack'):\n            return None\n        def extract_window(self, conv, center_msg_idx=0, window_seconds=300):\n            return []\n        def classify_messages(self, messages):\n            return []\n        def detect_patterns(self, conv, classified_msgs):\n            return {'repeat_targeting': [], 'recidivism': {}}\n        def compute_risk(self, classified_msgs, patterns):\n            return {'score': 0.0, 'severity': 'Low'}\n        def plan(self, conv, classified_msgs, risk, patterns):\n            return []\n        def build_evidence_text(self, conv, classified_msgs, risk):\n            return \"NO EVIDENCE (stub)\"\n        def check(self, action):\n            return {'allowed': True}\n        def notify_moderator(self, incident, actions):\n            print(f\"[Stub-notifier] Incident {getattr(incident,'incident_id', '<no-id>')} actions: {actions}\")\n        def log(self, entry):\n            print(f\"[Stub-observability] {entry}\")\n        def append_incident(self, user_id, incident_id):\n            pass\n        def get_incidents(self, user_id):\n            return []\n    Stub.__name__ = f\"Stub_{name}\"\n    return Stub()\n\n# List of expected component names and the attribute to attach in pipeline\nexpected_components = {\n    'ingestor': ('ingestor', 'IngestorAgent'),\n    'extractor': ('extractor', 'ExtractorAgent'),\n    'classifier': ('classifier', 'HarassmentClassifierAgent'),\n    'pattern_detector': ('pattern_detector', 'PatternDetectorAgent'),\n    'risk_scorer': ('risk_scorer', 'RiskScorerAgent'),\n    'planner': ('planner', 'InterventionPlannerAgent'),\n    'evidence_builder': ('evidence_builder', 'EvidenceBuilderAgent'),\n    'ethics': ('ethics', 'EthicsAgent'),\n    'notifier': ('notifier', 'NotifierAgent'),\n    'observability': ('observability', 'ObservabilityAgent'),\n    'memory': ('memory_agent', 'MemoryAgent'),\n}\n\n# Prepare attachments: use existing globals() objects if present; otherwise create stubs\nattached = {}\nfor attr, (global_name, cls_name) in expected_components.items():\n    if global_name in globals() and globals()[global_name] is not None:\n        attached[attr] = globals()[global_name]\n        print(f\"Using existing {global_name} -> {type(attached[attr]).__name__}\")\n    else:\n        # create a stub and attach\n        stub = make_stub(attr)\n        attached[attr] = stub\n        globals()[global_name] = stub  # create a global reference so later cells find it\n        print(f\"Created stub for missing {global_name} -> {type(stub).__name__}\")\n\n# Minimal Incident dataclass fallback (if missing)\ntry:\n    Incident  # noqa: F821\nexcept NameError:\n    from dataclasses import dataclass, field\n    @dataclass\n    class Incident:\n        incident_id: str\n        convo_id: str\n        involved_user_ids: List[str]\n        start_ts: str\n        end_ts: str\n        labels: List[Dict[str,Any]]\n        severity: str\n        evidence: Any = None\n        status: str = 'new'\n    globals()['Incident'] = Incident\n    print(\"Defined fallback Incident dataclass\")\n\n# Now define a safe pipeline class that uses the attached components\nclass SilentGuardianPipelineSafe:\n    def __init__(self, components: Dict[str, Any]):\n        print(\"[PipelineSafe] init\")\n        # attach everything (either real or stub)\n        self.ingestor = components['ingestor']\n        self.extractor = components['extractor']\n        self.classifier = components['classifier']\n        self.pattern_detector = components['pattern_detector']\n        self.risk_scorer = components['risk_scorer']\n        self.planner = components['planner']\n        self.evidence_builder = components['evidence_builder']\n        self.ethics = components['ethics']\n        self.notifier = components['notifier']\n        self.observability = components['observability']\n        self.memory = components['memory']\n\n    def run_once(self, raw_stream: List[Dict[str,Any]]):\n        print(\"[PipelineSafe] run_once called\")\n        # Ingest\n        conv = None\n        try:\n            conv = self.ingestor.ingest_stream(raw_stream)\n        except Exception as e:\n            print(\"[PipelineSafe] ingest_stream error:\", e)\n            # create a minimal conversation object if necessary\n            conv = type(\"Conv\", (), {\"convo_id\": gen_id(\"convo\"), \"platform\": \"unknown\", \"messages\": []})()\n\n        # observability\n        try:\n            self.observability.log({'event':'ingested_conversation','convo_id': getattr(conv,'convo_id', None), 'n_messages': len(getattr(conv,'messages',[]))})\n        except Exception as e:\n            print(\"[PipelineSafe] observability.log error:\", e)\n\n        # Extract window\n        try:\n            window_msgs = self.extractor.extract_window(conv, center_msg_idx=max(0, len(getattr(conv,'messages',[]))-1))\n        except Exception as e:\n            print(\"[PipelineSafe] extract_window error:\", e)\n            window_msgs = getattr(conv,'messages',[])\n\n        # Classify\n        try:\n            classified = self.classifier.classify_messages(window_msgs)\n        except Exception as e:\n            print(\"[PipelineSafe] classify_messages error:\", e)\n            classified = []\n\n        # Pattern detection\n        try:\n            patterns = self.pattern_detector.detect_patterns(conv, classified)\n        except Exception as e:\n            print(\"[PipelineSafe] detect_patterns error:\", e)\n            patterns = {'repeat_targeting': [], 'recidivism': {}}\n\n        # Risk scoring\n        try:\n            risk = self.risk_scorer.compute_risk(classified, patterns)\n        except Exception as e:\n            print(\"[PipelineSafe] compute_risk error:\", e)\n            risk = {'score':0.0, 'severity':'Low'}\n\n        # Plan interventions\n        try:\n            actions = self.planner.plan(conv, classified, risk, patterns)\n        except Exception as e:\n            print(\"[PipelineSafe] planner.plan error:\", e)\n            actions = []\n\n        # Ethics vetting\n        filtered_actions = []\n        for a in actions:\n            try:\n                check = self.ethics.check(a)\n            except Exception as e:\n                print(\"[PipelineSafe] ethics.check error:\", e)\n                check = {'allowed': True}\n            try:\n                self.observability.log({'event':'ethics_check','action': a.get('action_type','unknown'), 'result': check})\n            except Exception:\n                pass\n            if check.get('allowed'):\n                filtered_actions.append(a)\n\n        # Evidence (text) generation if requested\n        evidence_text = None\n        if any(a.get('action_type') in ('generate_evidence_text','generate_evidence_packet') for a in filtered_actions):\n            try:\n                evidence_text = self.evidence_builder.build_evidence_text(conv, classified, risk)\n            except Exception as e:\n                print(\"[PipelineSafe] evidence_builder error:\", e)\n                evidence_text = \"EVIDENCE ERROR\"\n\n        # Build Incident (robust)\n        incident_id = gen_id('incident')\n        involved = list({m.sender_id for m in getattr(conv,'messages',[])}) if getattr(conv,'messages',None) else []\n        incident = Incident(\n            incident_id=incident_id,\n            convo_id=getattr(conv,'convo_id', gen_id('convo')),\n            involved_user_ids=involved,\n            start_ts=getattr(conv,'messages',[{'ts': now_ts()}])[0]['ts'] if getattr(conv,'messages',None) else now_ts(),\n            end_ts=getattr(conv,'messages',[-1])['ts'] if getattr(conv,'messages',None) else now_ts(),\n            labels=[l for cm in classified for l in cm.get('labels',[])],\n            severity=risk.get('severity','Low'),\n            evidence=evidence_text,\n            status='new'\n        )\n\n        # store incident if DB cursor exists (safe)\n        try:\n            if 'cur' in globals() and 'conn' in globals():\n                cur.execute('INSERT INTO incidents (incident_id, convo_id, involved_users, start_ts, end_ts, labels, severity, evidence, status) VALUES (?,?,?,?,?,?,?,?,?)',\n                            (incident.incident_id, incident.convo_id, json.dumps(incident.involved_user_ids), incident.start_ts, incident.end_ts, json.dumps(incident.labels), incident.severity, json.dumps(incident.evidence) if incident.evidence else None, incident.status))\n                conn.commit()\n        except Exception as e:\n            print(\"[PipelineSafe] DB insert error:\", e)\n\n        # Update memory for involved users\n        try:\n            for u in incident.involved_user_ids:\n                try:\n                    self.memory.append_incident(u, incident.incident_id)\n                except Exception:\n                    pass\n        except Exception:\n            pass\n\n        # Notify moderator (prints with fallback)\n        try:\n            self.notifier.notify_moderator(incident, filtered_actions)\n        except Exception as e:\n            print(\"[PipelineSafe] notifier.notify_moderator error:\", e)\n\n        try:\n            self.observability.log({'event':'pipeline_complete','incident_id': incident.incident_id, 'severity': incident.severity})\n        except Exception:\n            pass\n\n        # Return the robust tuple\n        return incident, conv, classified, patterns, risk\n\n# instantiate pipeline with attached components\npipeline = SilentGuardianPipelineSafe(attached)\nprint(\"\\nPipeline created. Attached components summary:\")\nfor k, v in attached.items():\n    print(f\" - {k}: {type(v).__name__}\")\n\nprint(\"\\n‚úÖ Safe pipeline ready. Run pipeline.run_once(stream) to test.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.618415Z","iopub.execute_input":"2025-11-30T07:26:02.618813Z","iopub.status.idle":"2025-11-30T07:26:02.653141Z","shell.execute_reply.started":"2025-11-30T07:26:02.618783Z","shell.execute_reply":"2025-11-30T07:26:02.652166Z"}},"outputs":[{"name":"stdout","text":"\n======== Safe Pipeline Builder (auto-fallbacks) ========\n\nUsing existing ingestor -> IngestorAgent\nUsing existing extractor -> ExtractorAgent\nUsing existing classifier -> HarassmentClassifierAgent_MCP\nUsing existing pattern_detector -> PatternDetectorAgentV2\nUsing existing risk_scorer -> RiskScorerAgentV2\nUsing existing planner -> InterventionPlannerAgent\nUsing existing evidence_builder -> EvidenceBuilderAgent\nUsing existing ethics -> EthicsAgent\nUsing existing notifier -> NotifierAgent\nUsing existing observability -> ObservabilityAgent\nUsing existing memory_agent -> MemoryAgent\n[PipelineSafe] init\n\nPipeline created. Attached components summary:\n - ingestor: IngestorAgent\n - extractor: ExtractorAgent\n - classifier: HarassmentClassifierAgent_MCP\n - pattern_detector: PatternDetectorAgentV2\n - risk_scorer: RiskScorerAgentV2\n - planner: InterventionPlannerAgent\n - evidence_builder: EvidenceBuilderAgent\n - ethics: EthicsAgent\n - notifier: NotifierAgent\n - observability: ObservabilityAgent\n - memory: MemoryAgent\n\n‚úÖ Safe pipeline ready. Run pipeline.run_once(stream) to test.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# --- Pipeline Cell ---\n# Purpose: define SilentGuardianPipeline and its run_once() method (main processing flow).\n# Behavior:\n#  - ingest -> extract -> classify -> pattern detect -> score -> plan -> ethics -> evidence -> incident save -> notify\n#  - uses the objects attached in the Safe Pipeline Builder cell\n# Safety:\n#  - should not directly perform destructive actions (ban/fire); those are flagged for human approval by EthicsAgent\n#  - returns a consistent Incident dataclass (or guarded tuple) so downstream code can handle both shapes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.654795Z","iopub.execute_input":"2025-11-30T07:26:02.655055Z","iopub.status.idle":"2025-11-30T07:26:02.673715Z","shell.execute_reply.started":"2025-11-30T07:26:02.655034Z","shell.execute_reply":"2025-11-30T07:26:02.672695Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# -----------------------------\n# Pipeline\n# -----------------------------\nfrom typing import List, Dict, Any  \nprint_header(\"Pipeline\")\nclass SilentGuardianPipeline:\n    def __init__(self):\n        print(\"[Pipeline] init\")\n        self.ingestor = ingestor\n        self.extractor = extractor\n        self.classifier = classifier\n        self.pattern_detector = pattern_detector\n        self.risk_scorer = risk_scorer\n        self.planner = planner\n        self.evidence_builder = evidence_builder\n        self.ethics = ethics\n        self.notifier = notifier\n        self.observability = observability\n        self.memory = memory_agent\n\n    def run_once(self, raw_stream: List[Dict[str,Any]]):\n        print(\"[Pipeline] run_once called\")\n        conv = self.ingestor.ingest_stream(raw_stream)\n        self.observability.log({'event':'ingested_conversation','convo_id': conv.convo_id, 'n_messages': len(conv.messages)})\n        window_msgs = self.extractor.extract_window(conv, center_msg_idx=max(0, len(conv.messages)-1))\n        classified = self.classifier.classify_messages(window_msgs)\n        # publish: here we just call pattern detector\n        patterns = self.pattern_detector.detect_patterns(conv, classified)\n        risk = self.risk_scorer.compute_risk(classified, patterns)\n        actions = self.planner.plan(conv, classified, risk, patterns)\n        filtered_actions = []\n        for a in actions:\n            check = self.ethics.check(a)\n            self.observability.log({'event':'ethics_check','action': a['action_type'], 'result': check})\n            if check.get('allowed'):\n                filtered_actions.append(a)\n            else:\n                print(f\"[Pipeline] Action {a['action_type']} blocked by ethics: {check.get('reason')}\")\n        evidence_text = None\n        if any(a['action_type']=='generate_evidence_text' for a in filtered_actions):\n            evidence_text = self.evidence_builder.build_evidence_text(conv, classified, risk)\n        # Create incident object and store in-memory DB\n        incident_id = gen_id('incident')\n        incident = Incident(incident_id=incident_id, convo_id=conv.convo_id,\n                            involved_user_ids=list({m.sender_id for m in conv.messages}),\n                            start_ts=conv.messages[0].ts if conv.messages else now_ts(),\n                            end_ts=conv.messages[-1].ts if conv.messages else now_ts(),\n                            labels=[l for cm in classified for l in cm['labels']],\n                            severity=risk['severity'], evidence=evidence_text, status='new')\n        cur.execute('INSERT INTO incidents (incident_id, convo_id, involved_users, start_ts, end_ts, labels, severity, evidence, status) VALUES (?,?,?,?,?,?,?,?,?)',\n                    (incident.incident_id, incident.convo_id, json.dumps(incident.involved_user_ids), incident.start_ts, incident.end_ts, json.dumps(incident.labels), incident.severity, json.dumps(incident.evidence) if incident.evidence else None, incident.status))\n        conn.commit()\n        print(f\"[Pipeline] Created incident {incident.incident_id} severity={incident.severity}\")\n        # update memory for involved users\n        for u in incident.involved_user_ids:\n            self.memory.append_incident(u, incident.incident_id)\n        # Notify moderator (prints)\n        self.notifier.notify_moderator(incident, filtered_actions)\n        self.observability.log({'event':'pipeline_complete','incident_id': incident.incident_id, 'severity': incident.severity})\n        return incident, conv, classified, patterns, risk\n\npipeline = SilentGuardianPipeline()\nprint(\"Pipeline ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.676134Z","iopub.execute_input":"2025-11-30T07:26:02.676550Z","iopub.status.idle":"2025-11-30T07:26:02.700434Z","shell.execute_reply.started":"2025-11-30T07:26:02.676525Z","shell.execute_reply":"2025-11-30T07:26:02.699367Z"}},"outputs":[{"name":"stdout","text":"\n======== Pipeline ========\n\n[Pipeline] init\nPipeline ready.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## üß† Section 7 : Session and Memory Management (#session)\nMaintains per-user memory across sessions by logging past incidents in SQLite.\nEnables recidivism detection and history-aware risk scoring for repeated offenders.","metadata":{}},{"cell_type":"code","source":"print_header(\"Memory Agent\")\nclass MemoryAgent:\n    def __init__(self, conn):\n        self.conn = conn\n    def append_incident(self, user_id, incident_id):\n        cur = self.conn.cursor()\n        cur.execute(\"SELECT incidents FROM user_profiles WHERE user_id=?\", (user_id,))\n        r = cur.fetchone()\n        if not r:\n            cur.execute(\"INSERT INTO user_profiles (user_id, anon_id, safety_score, incidents) VALUES (?,?,?,?)\",\n                        (user_id, gen_id('anon'), 0.5, json.dumps([incident_id])))\n        else:\n            incs = json.loads(r[0] or '[]')\n            incs.append(incident_id)\n            cur.execute(\"UPDATE user_profiles SET incidents=? WHERE user_id= ?\", (json.dumps(incs), user_id))\n        self.conn.commit()\n    def get_incidents(self, user_id):\n        cur = self.conn.cursor()\n        cur.execute(\"SELECT incidents FROM user_profiles WHERE user_id=?\", (user_id,))\n        r = cur.fetchone()\n        return json.loads(r[0]) if r and r[0] else []\n\nmemory_agent = MemoryAgent(conn)\nprint(\"MemoryAgent ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.701651Z","iopub.execute_input":"2025-11-30T07:26:02.701971Z","iopub.status.idle":"2025-11-30T07:26:02.727626Z","shell.execute_reply.started":"2025-11-30T07:26:02.701944Z","shell.execute_reply":"2025-11-30T07:26:02.726426Z"}},"outputs":[{"name":"stdout","text":"\n======== Memory Agent ========\n\nMemoryAgent ready.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## üìä Section 8 : Observability and Logging (#observability)\nCaptures every pipeline event with timestamps for full traceability and debugging.\nProvides transparent logs that support evaluation, auditing, and agent introspection.\n\n","metadata":{}},{"cell_type":"code","source":"print_header(\"Observability\")\nclass ObservabilityAgent:\n    def __init__(self):\n        self.logs = []\n    def log(self, entry: Dict[str,Any]):\n        entry['ts'] = now_ts()\n        self.logs.append(entry)\n        print(f\"[Observability] {entry.get('event','unknown')}\")\n    def dump(self):\n        # return logs for display in notebook\n        return list(self.logs)\n\nobservability = ObservabilityAgent()\nprint(\"Observability and Logging done successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.728819Z","iopub.execute_input":"2025-11-30T07:26:02.729327Z","iopub.status.idle":"2025-11-30T07:26:02.755677Z","shell.execute_reply.started":"2025-11-30T07:26:02.729292Z","shell.execute_reply":"2025-11-30T07:26:02.754353Z"}},"outputs":[{"name":"stdout","text":"\n======== Observability ========\n\nObservability and Logging done successfully.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"## üé¨ Section 9 : Demo Run and Usage (#demo)\nIn this section we can now run the demo streams, check safety pipeline and observability validation, fix the missing logs and also execute the main actual runner streams of the System ","metadata":{}},{"cell_type":"code","source":"# -----------------------------\n# Demo streams (runtime)\n# Generates realistic chat conversations dynamically for live testing of the pipeline.\n# Includes benign, low-risk, and repeated high-risk harassment scenarios.\n# -----------------------------\nprint_header(\"Demo streams\")\nSIM_STREAMS = []\nSIM_STREAMS.append([\n    {'sender_id':'@alice','text':'Hey team, please review my PR','ts': now_ts()},\n    {'sender_id':'@bob','text':'Looks good to me, thanks!','ts': now_ts()}\n])\nSIM_STREAMS.append([\n    {'sender_id':'@alex','text':'You are so dumb','ts': now_ts()},\n    {'sender_id':'@mira','text':'Please do not talk to me like that','ts': now_ts()}\n])\nfor i in range(4):\n    SIM_STREAMS.append([\n        {'sender_id':'@alex','text': f\"@mira you are worthless and a loser {i}\", 'ts': now_ts()}\n    ])\nprint(f\"Prepared {len(SIM_STREAMS)} demo streams (runtime-generated).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.757589Z","iopub.execute_input":"2025-11-30T07:26:02.757993Z","iopub.status.idle":"2025-11-30T07:26:02.777515Z","shell.execute_reply.started":"2025-11-30T07:26:02.757964Z","shell.execute_reply":"2025-11-30T07:26:02.776138Z"}},"outputs":[{"name":"stdout","text":"\n======== Demo streams ========\n\nPrepared 6 demo streams (runtime-generated).\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Verifies that the pipeline and observability system are properly initialized before execution.\n# Prevents runtime crashes by stopping execution if critical components are missing.\n\nif 'pipeline' not in globals():\n    print(\"‚ùå pipeline does NOT exist yet. Run the pipeline creation cell first.\")\nelse:\n    if not hasattr(pipeline, 'observability'):\n        print(\"‚ùå pipeline.observability missing ‚Äî create Observability before pipeline.\")\n    else:\n        if not hasattr(pipeline.observability, 'logs'):\n            pipeline.observability.logs = []\n            print(\"‚úÖ Fixed: created pipeline.observability.logs = []\")\n        else:\n            print(f\"‚úî pipeline.observability.logs already exists (len = {len(pipeline.observability.logs)})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.778460Z","iopub.execute_input":"2025-11-30T07:26:02.778789Z","iopub.status.idle":"2025-11-30T07:26:02.803288Z","shell.execute_reply.started":"2025-11-30T07:26:02.778761Z","shell.execute_reply":"2025-11-30T07:26:02.802201Z"}},"outputs":[{"name":"stdout","text":"‚úî pipeline.observability.logs already exists (len = 0)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# Automatically repairs missing observability log storage if it was not initialized correctly.\n# Ensures uninterrupted logging without restarting the full notebook.\n\ntry:\n    if hasattr(pipeline, 'observability'):\n        if not hasattr(pipeline.observability, 'logs'):\n            pipeline.observability.logs = []\n            print(\"Created pipeline.observability.logs = [] (quick fix)\")\n        else:\n            print(\"pipeline.observability.logs already exists (len = {})\".format(len(pipeline.observability.logs)))\n    else:\n        print(\"pipeline or pipeline.observability not found in globals()\")\nexcept Exception as e:\n    print(\"Error applying quick fix:\", e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.804583Z","iopub.execute_input":"2025-11-30T07:26:02.805026Z","iopub.status.idle":"2025-11-30T07:26:02.823376Z","shell.execute_reply.started":"2025-11-30T07:26:02.804993Z","shell.execute_reply":"2025-11-30T07:26:02.822325Z"}},"outputs":[{"name":"stdout","text":"pipeline.observability.logs already exists (len = 0)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# ============================================================================\n# MAIN EXECUTION PIPELINE ‚Äî END-TO-END DEMO RUNNER\n# ============================================================================\n# This is the primary execution cell of the Silent Guardian system.\n# It runs the complete multi-agent pipeline on all demo chat streams,\n# generates structured incident summaries, and prints human-readable outputs.\n#\n# HOW TO USE THIS SECTION:\n# 1. Ensure all agents (Ingestor, Classifier, Pattern Detector, Risk Scorer,\n#    Planner, MemoryAgent, Observability, and Pipeline) are already created.\n# 2. Ensure SIM_STREAMS (demo chat conversations) are defined.\n# 3. Run this cell once to execute the full detection ‚Üí analysis ‚Üí risk scoring\n#    ‚Üí intervention ‚Üí memory update ‚Üí reporting workflow.\n#\n# WHAT THIS SECTION DOES:\n# ‚Ä¢ Executes each chat stream through the unified multi-agent pipeline.\n# ‚Ä¢ Automatically normalizes different pipeline return formats (safe handling).\n# ‚Ä¢ Identifies offender and target using analytical heuristics.\n# ‚Ä¢ Prints a standardized Incident Summary Dashboard for every conversation.\n# ‚Ä¢ Displays full conversation, classifier outputs, detected patterns, and risk.\n# ‚Ä¢ Collects all results into the `results` list for evaluation or export.\n#\n# This section demonstrates the complete real-time behavior of the system\n# exactly as it would operate in a production moderation environment.\n# ============================================================================\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.824508Z","iopub.execute_input":"2025-11-30T07:26:02.824918Z","iopub.status.idle":"2025-11-30T07:26:02.849056Z","shell.execute_reply.started":"2025-11-30T07:26:02.824890Z","shell.execute_reply":"2025-11-30T07:26:02.847810Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# ----------------------------\n# Executes the full Silent Guardian multi-agent pipeline on all runtime demo streams and prints standardized incident reports.\n# -----------------------------\nfrom collections import Counter\nfrom typing import List, Dict, Any\n\ndef summarize_offender_target(classified: List[Dict[str,Any]], patterns: Dict[str,Any]):\n    \"\"\"\n    Pick an offender (sender with highest total label score) and a target (most frequent @-mention).\n    Returns tuple (offender, target).\n    Defensive: works with labelled messages where each cm has 'sender_id' and 'labels'.\n    \"\"\"\n    # Sum label scores per sender\n    scores_by_sender = {}\n    for cm in classified:\n        s = cm.get('sender_id', '(unknown)')\n        total = sum(l.get('score', 0.0) for l in cm.get('labels', []))\n        scores_by_sender[s] = scores_by_sender.get(s, 0.0) + total\n    if scores_by_sender:\n        sorted_items = sorted(scores_by_sender.items(), key=lambda kv: (-kv[1], kv[0]))\n        offender = sorted_items[0][0]\n    else:\n        offender = '(none)'\n\n    # Collect targets from pattern detector and direct message mentions\n    targets = [t.get('target') for t in patterns.get('repeat_targeting', []) if t.get('target')]\n    # Also scan classified messages for mentions if patterns empty\n    if not targets:\n        for cm in classified:\n            text = cm.get('text') or ''\n            # safe string check\n            if isinstance(text, str):\n                targets.extend(re.findall(r\"@\\w+\", text))\n    if targets:\n        counts = Counter(targets)\n        # pick most frequent, break ties lexicographically\n        sorted_targets = sorted(counts.items(), key=lambda kv: (-kv[1], kv[0]))\n        target = sorted_targets[0][0]\n    else:\n        target = '(none detected)'\n\n    return offender, target\n\n\ndef print_incident_dashboard(incident_obj, conv, classified: List[Dict[str,Any]],\n                             patterns: Dict[str,Any], risk: Dict[str,Any],\n                             planner_obj=None, ethics_obj=None):\n    \"\"\"\n    Robust incident dashboard printer.\n    Supports:\n     - incident_obj as dataclass-like with .incident_id/.severity\n     - incident_obj as tuple (returns from older pipeline) -- tries reasonable positions\n    \"\"\"\n    planner_obj = planner_obj or globals().get('planner')\n    ethics_obj = ethics_obj or globals().get('ethics')\n\n    offender, target = summarize_offender_target(classified, patterns)\n\n    # Resolve incident id + severity safely\n    if hasattr(incident_obj, 'incident_id'):\n        incident_id = getattr(incident_obj, 'incident_id', '(unknown)')\n    elif isinstance(incident_obj, tuple):\n        # try common tuple shapes: (incident, conv, classified, patterns, risk)\n        # if incident_obj actually is the \"incident\" element in older wrapper, handle both.\n        try:\n            # if the user passed a 5-tuple from old pipeline, second element may be conv etc.\n            # Search tuple for an object with attribute 'incident_id'\n            incident_id = next((x.incident_id for x in incident_obj if hasattr(x, 'incident_id')), None)\n            if not incident_id:\n                incident_id = incident_obj[0] if len(incident_obj) > 0 else '(unknown)'\n        except Exception:\n            incident_id = str(incident_obj)\n    else:\n        incident_id = str(incident_obj)\n\n    if hasattr(incident_obj, 'severity'):\n        severity = getattr(incident_obj, 'severity', '(unknown)')\n    elif isinstance(incident_obj, tuple):\n        # try to find risk-like element in tuple (a dict with 'severity') or fallback\n        sev = None\n        for x in incident_obj:\n            if isinstance(x, dict) and 'severity' in x:\n                sev = x.get('severity')\n                break\n        severity = sev or (incident_obj[0].severity if hasattr(incident_obj[0], 'severity') else '(unknown)')\n    else:\n        severity = risk.get('severity') if isinstance(risk, dict) else '(unknown)'\n\n    # Build recommended actions using planner if available and if it accepts inputs\n    actions = []\n    if planner_obj:\n        try:\n            # planner.plan may expect conv, classified, risk, patterns\n            # ensure risk is a dict with severity\n            r = risk if isinstance(risk, dict) else {'severity': severity}\n            actions = planner_obj.plan(conv, classified, r, patterns) or []\n        except Exception as e:\n            # fallback: leave actions empty but do not raise\n            # print debug line to help developer\n            print(f\"[print_incident_dashboard] planner.plan call failed: {e}\")\n            actions = []\n\n    # Print dashboard\n    print(\"\\n=== Incident Summary Dashboard ===\")\n    print(f\"Incident ID: {incident_id}\")\n    print(f\"Severity: {severity}\")\n    print(f\"Offender: {offender}\")\n    print(f\"Target: {target}\")\n    print(\"Recommended Actions:\")\n    if actions:\n        for a in actions:\n            print(f\" - {a.get('action_type', '(unknown)')}\" + (f\": {a.get('rationale')}\" if a.get('rationale') else \"\"))\n    else:\n        print(\" - (none)\")\n    print(\"=\"*40 + \"\\n\")\n\n\n# -----------------------------\n# Re-run demo loop using new dashboard function\n# (This replaces the old ad-hoc printing block; paste this cell and run)\n# -----------------------------\nprint_header(\"Run demo\")\nresults = []\n\n# Defensive checks for required globals\nif 'SIM_STREAMS' not in globals():\n    raise RuntimeError(\"SIM_STREAMS not found in globals. Ensure you defined demo streams before running this cell.\")\nif 'pipeline' not in globals():\n    raise RuntimeError(\"pipeline not found in globals. Define pipeline (SilentGuardianPipeline) before running this cell.\")\n\nfor i, s in enumerate(SIM_STREAMS):\n    print(f\"\\n--- Running stream #{i} ---\")\n    # pipeline.run_once may return either: Incident (dataclass) or tuple (incident, conv, classified, patterns, risk)\n    out = pipeline.run_once(s)\n    # Normalize return shapes:\n    if isinstance(out, tuple) and len(out) == 5:\n        incident, conv, classified, patterns, risk = out\n    elif hasattr(out, 'incident_id') or isinstance(out, dict):\n        # older pipeline variant returned incident only; try to reconstruct other outputs where possible\n        incident = out\n        # attempt to reconstruct conv/classified/patterns/risk via a second classification pass (safe)\n        try:\n            # we have the raw stream s -> ingest to get conv\n            conv = ingestor.ingest_stream(s)\n            window_msgs = extractor.extract_window(conv, center_msg_idx=max(0, len(conv.messages)-1))\n            classified = classifier.classify_messages(window_msgs)\n            patterns = pattern_detector.detect_patterns(conv, classified) if 'pattern_detector' in globals() else {}\n            risk = risk_scorer.compute_risk(classified, patterns) if 'risk_scorer' in globals() else {'severity': getattr(incident, 'severity', 'Unknown')}\n        except Exception as e:\n            # last resort: set placeholders\n            conv = None\n            classified = []\n            patterns = {}\n            risk = {'severity': getattr(incident, 'severity', 'Unknown')}\n    else:\n        # Unexpected shape ‚Äî try to treat it as incident-like\n        incident = out\n        conv = None\n        classified = []\n        patterns = {}\n        risk = {'severity': getattr(incident, 'severity', 'Unknown')}\n\n    # Print standardized dashboard\n    try:\n        print_incident_dashboard(incident, conv, classified, patterns, risk, planner_obj=globals().get('planner'))\n    except Exception as e:\n        print(\"[demo loop] print_incident_dashboard failed:\", e)\n\n    # The rest of the structured output (messages, classifier results, etc.)\n    if conv:\n        print(f\"Session: {getattr(conv, 'convo_id', '(unknown)')}\")\n        try:\n            n_messages = len(conv.messages)\n        except Exception:\n            n_messages = 0\n        print(f\"User messages ({n_messages}):\")\n        for m in getattr(conv, 'messages', []):\n            # m may be Message object or dict\n            if hasattr(m, 'sender_id'):\n                sid = m.sender_id\n                txt = m.text\n                ts = m.ts\n            else:\n                sid = m.get('sender_id','(unknown)')\n                txt = m.get('text','')\n                ts = m.get('ts', now_ts())\n            print(f\" - {sid} @ {ts}: {txt}\")\n    else:\n        print(\"Session: (conversation object not available)\")\n\n    # Classifier results\n    print('\\nClassifier results:')\n    for cm in classified:\n        expl = cm.get('explanation') or ''\n        print(f\" - {cm.get('msg_id','(no-id)')} by {cm.get('sender_id','(unknown)')}: labels={[l['label'] for l in cm.get('labels',[])]} {expl}\")\n\n    # Patterns, risk, recommended actions (repeat)\n    print('\\nPatterns detected:')\n    print(patterns)\n    print('\\nRisk: ', risk)\n    print('\\nRecommended actions:')\n    try:\n        rec_actions = globals().get('planner').plan(conv, classified, risk, patterns)\n    except Exception as e:\n        rec_actions = []\n    for a in rec_actions:\n        print(' -', a.get('action_type'), ':', a.get('rationale',''))\n    results.append({'incident':incident, 'conv':conv, 'classified':classified, 'patterns':patterns, 'risk':risk})\n\nprint_header(\"Run demo complete (patched)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.850436Z","iopub.execute_input":"2025-11-30T07:26:02.850862Z","iopub.status.idle":"2025-11-30T07:26:02.887906Z","shell.execute_reply.started":"2025-11-30T07:26:02.850828Z","shell.execute_reply":"2025-11-30T07:26:02.886667Z"}},"outputs":[{"name":"stdout","text":"\n======== Run demo ========\n\n\n--- Running stream #0 ---\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_2fb21d97 with 2 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 2 (ts range 2025-11-30T07:21:02.773496Z - 2025-11-30T07:31:02.773496Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_1c93 labels:['none']\n[HarassmentClassifier_MCP] msg:msg_8dc7 labels:['none']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] score=0.00 severity=Low\n[InterventionPlanner] planned actions: ['suggest_support_message']\n[Observability] ethics_check\n[Pipeline] Created incident incident_92ca683d severity=Low\n--- Moderator Notification: Incident incident_92ca683d (severity=Low) ---\n[0] Action: suggest_support_message - Offer support\n[Observability] pipeline_complete\n[InterventionPlanner] planned actions: ['suggest_support_message']\n\n=== Incident Summary Dashboard ===\nIncident ID: incident_92ca683d\nSeverity: Low\nOffender: @alice\nTarget: (none detected)\nRecommended Actions:\n - suggest_support_message: Offer support\n========================================\n\nSession: convo_2fb21d97\nUser messages (2):\n - @alice @ 2025-11-30T07:26:02.773484Z: Hey team, please review my PR\n - @bob @ 2025-11-30T07:26:02.773496Z: Looks good to me, thanks!\n\nClassifier results:\n - msg_1c93bba5 by @alice: labels=['none'] \n - msg_8dc7f0f4 by @bob: labels=['none'] \n\nPatterns detected:\n{'repeat_targeting': [], 'recidivism': {}}\n\nRisk:  {'score': 0.0, 'severity': 'Low'}\n\nRecommended actions:\n[InterventionPlanner] planned actions: ['suggest_support_message']\n - suggest_support_message : Offer support\n\n--- Running stream #1 ---\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_01583389 with 2 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 2 (ts range 2025-11-30T07:21:02.773560Z - 2025-11-30T07:31:02.773560Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_08e7 labels:['insult']\n[HarassmentClassifier_MCP] msg:msg_a815 labels:['none']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {'@alex': 0}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] score=0.45 severity=Medium\n[InterventionPlanner] planned actions: ['notify_moderator']\n[Observability] ethics_check\n[Pipeline] Created incident incident_0b0a197c severity=Medium\n--- Moderator Notification: Incident incident_0b0a197c (severity=Medium) ---\n[0] Action: notify_moderator - Moderator review recommended\n[Observability] pipeline_complete\n[InterventionPlanner] planned actions: ['notify_moderator']\n\n=== Incident Summary Dashboard ===\nIncident ID: incident_0b0a197c\nSeverity: Medium\nOffender: @alex\nTarget: (none detected)\nRecommended Actions:\n - notify_moderator: Moderator review recommended\n========================================\n\nSession: convo_01583389\nUser messages (2):\n - @alex @ 2025-11-30T07:26:02.773558Z: You are so dumb\n - @mira @ 2025-11-30T07:26:02.773560Z: Please do not talk to me like that\n\nClassifier results:\n - msg_08e7208c by @alex: labels=['insult'] \n - msg_a8153e5b by @mira: labels=['none'] \n\nPatterns detected:\n{'repeat_targeting': [], 'recidivism': {'@alex': 0}}\n\nRisk:  {'score': 0.45, 'severity': 'Medium'}\n\nRecommended actions:\n[InterventionPlanner] planned actions: ['notify_moderator']\n - notify_moderator : Moderator review recommended\n\n--- Running stream #2 ---\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_69d77704 with 1 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 1 (ts range 2025-11-30T07:21:02.773642Z - 2025-11-30T07:31:02.773642Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_54fe labels:['insult']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_54fe39fe'}], 'recidivism': {'@alex': 1}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] applying recidivism bump: 0.05\n[RiskScorerV2] score=0.95 severity=Immediate\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n[Observability] ethics_check\n[Observability] ethics_check\n\nEvidence for conversation convo_69d77704 (platform=slack)\nGenerated: 2025-11-30T07:26:02.881592Z\nRisk: {'score': 0.9500000000000001, 'severity': 'Immediate'}\n\nMessages:\n- msg_54fe39fe | @alex | @mira you are worthless and a loser 0 | labels=[{'label': 'insult', 'score': 0.9, 'span': 'loser'}]\n\n[Pipeline] Created incident incident_4f88c913 severity=Immediate\n--- Moderator Notification: Incident incident_4f88c913 (severity=Immediate) ---\n[0] Action: create_incident_and_notify_hr - Escalate to HR\n[1] Action: generate_evidence_text - Create evidence text\n[Observability] pipeline_complete\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n\n=== Incident Summary Dashboard ===\nIncident ID: incident_4f88c913\nSeverity: Immediate\nOffender: @alex\nTarget: @mira\nRecommended Actions:\n - create_incident_and_notify_hr: Escalate to HR\n - generate_evidence_text: Create evidence text\n========================================\n\nSession: convo_69d77704\nUser messages (1):\n - @alex @ 2025-11-30T07:26:02.773642Z: @mira you are worthless and a loser 0\n\nClassifier results:\n - msg_54fe39fe by @alex: labels=['insult'] \n\nPatterns detected:\n{'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_54fe39fe'}], 'recidivism': {'@alex': 1}}\n\nRisk:  {'score': 0.9500000000000001, 'severity': 'Immediate'}\n\nRecommended actions:\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n - create_incident_and_notify_hr : Escalate to HR\n - generate_evidence_text : Create evidence text\n\n--- Running stream #3 ---\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_9a25bbf1 with 1 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 1 (ts range 2025-11-30T07:21:02.773646Z - 2025-11-30T07:31:02.773646Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_40cf labels:['insult']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_40cf578e'}], 'recidivism': {'@alex': 2}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] applying recidivism bump: 0.1\n[RiskScorerV2] score=1.00 severity=Immediate\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n[Observability] ethics_check\n[Observability] ethics_check\n\nEvidence for conversation convo_9a25bbf1 (platform=slack)\nGenerated: 2025-11-30T07:26:02.882510Z\nRisk: {'score': 1.0, 'severity': 'Immediate'}\n\nMessages:\n- msg_40cf578e | @alex | @mira you are worthless and a loser 1 | labels=[{'label': 'insult', 'score': 0.9, 'span': 'loser'}]\n\n[Pipeline] Created incident incident_3b5f5b77 severity=Immediate\n--- Moderator Notification: Incident incident_3b5f5b77 (severity=Immediate) ---\n[0] Action: create_incident_and_notify_hr - Escalate to HR\n[1] Action: generate_evidence_text - Create evidence text\n[Observability] pipeline_complete\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n\n=== Incident Summary Dashboard ===\nIncident ID: incident_3b5f5b77\nSeverity: Immediate\nOffender: @alex\nTarget: @mira\nRecommended Actions:\n - create_incident_and_notify_hr: Escalate to HR\n - generate_evidence_text: Create evidence text\n========================================\n\nSession: convo_9a25bbf1\nUser messages (1):\n - @alex @ 2025-11-30T07:26:02.773646Z: @mira you are worthless and a loser 1\n\nClassifier results:\n - msg_40cf578e by @alex: labels=['insult'] \n\nPatterns detected:\n{'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_40cf578e'}], 'recidivism': {'@alex': 2}}\n\nRisk:  {'score': 1.0, 'severity': 'Immediate'}\n\nRecommended actions:\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n - create_incident_and_notify_hr : Escalate to HR\n - generate_evidence_text : Create evidence text\n\n--- Running stream #4 ---\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_158b2671 with 1 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 1 (ts range 2025-11-30T07:21:02.773648Z - 2025-11-30T07:31:02.773648Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_8683 labels:['insult']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_8683c7b2'}], 'recidivism': {'@alex': 3}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] applying recidivism bump: 0.15000000000000002\n[RiskScorerV2] score=1.00 severity=Immediate\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n[Observability] ethics_check\n[Observability] ethics_check\n\nEvidence for conversation convo_158b2671 (platform=slack)\nGenerated: 2025-11-30T07:26:02.883045Z\nRisk: {'score': 1.0, 'severity': 'Immediate'}\n\nMessages:\n- msg_8683c7b2 | @alex | @mira you are worthless and a loser 2 | labels=[{'label': 'insult', 'score': 0.9, 'span': 'loser'}]\n\n[Pipeline] Created incident incident_f64c79f0 severity=Immediate\n--- Moderator Notification: Incident incident_f64c79f0 (severity=Immediate) ---\n[0] Action: create_incident_and_notify_hr - Escalate to HR\n[1] Action: generate_evidence_text - Create evidence text\n[Observability] pipeline_complete\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n\n=== Incident Summary Dashboard ===\nIncident ID: incident_f64c79f0\nSeverity: Immediate\nOffender: @alex\nTarget: @mira\nRecommended Actions:\n - create_incident_and_notify_hr: Escalate to HR\n - generate_evidence_text: Create evidence text\n========================================\n\nSession: convo_158b2671\nUser messages (1):\n - @alex @ 2025-11-30T07:26:02.773648Z: @mira you are worthless and a loser 2\n\nClassifier results:\n - msg_8683c7b2 by @alex: labels=['insult'] \n\nPatterns detected:\n{'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_8683c7b2'}], 'recidivism': {'@alex': 3}}\n\nRisk:  {'score': 1.0, 'severity': 'Immediate'}\n\nRecommended actions:\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n - create_incident_and_notify_hr : Escalate to HR\n - generate_evidence_text : Create evidence text\n\n--- Running stream #5 ---\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_d3a06776 with 1 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 1 (ts range 2025-11-30T07:21:02.773652Z - 2025-11-30T07:31:02.773652Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_dc38 labels:['insult']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_dc38c739'}], 'recidivism': {'@alex': 4}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] applying recidivism bump: 0.2\n[RiskScorerV2] score=1.00 severity=Immediate\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n[Observability] ethics_check\n[Observability] ethics_check\n\nEvidence for conversation convo_d3a06776 (platform=slack)\nGenerated: 2025-11-30T07:26:02.883661Z\nRisk: {'score': 1.0, 'severity': 'Immediate'}\n\nMessages:\n- msg_dc38c739 | @alex | @mira you are worthless and a loser 3 | labels=[{'label': 'insult', 'score': 0.9, 'span': 'loser'}]\n\n[Pipeline] Created incident incident_a456431d severity=Immediate\n--- Moderator Notification: Incident incident_a456431d (severity=Immediate) ---\n[0] Action: create_incident_and_notify_hr - Escalate to HR\n[1] Action: generate_evidence_text - Create evidence text\n[Observability] pipeline_complete\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n\n=== Incident Summary Dashboard ===\nIncident ID: incident_a456431d\nSeverity: Immediate\nOffender: @alex\nTarget: @mira\nRecommended Actions:\n - create_incident_and_notify_hr: Escalate to HR\n - generate_evidence_text: Create evidence text\n========================================\n\nSession: convo_d3a06776\nUser messages (1):\n - @alex @ 2025-11-30T07:26:02.773652Z: @mira you are worthless and a loser 3\n\nClassifier results:\n - msg_dc38c739 by @alex: labels=['insult'] \n\nPatterns detected:\n{'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_dc38c739'}], 'recidivism': {'@alex': 4}}\n\nRisk:  {'score': 1.0, 'severity': 'Immediate'}\n\nRecommended actions:\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n - create_incident_and_notify_hr : Escalate to HR\n - generate_evidence_text : Create evidence text\n\n======== Run demo complete (patched) ========\n\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# -----------------------------\n# Inspect MemoryAgent persistent user incident history\n# -----------------------------\ncur.execute(\"SELECT user_id, incidents FROM user_profiles WHERE incidents IS NOT NULL\")\nprint(cur.fetchall()[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.888888Z","iopub.execute_input":"2025-11-30T07:26:02.889629Z","iopub.status.idle":"2025-11-30T07:26:02.908418Z","shell.execute_reply.started":"2025-11-30T07:26:02.889596Z","shell.execute_reply":"2025-11-30T07:26:02.907390Z"}},"outputs":[{"name":"stdout","text":"[('@alice', '[\"incident_92ca683d\"]'), ('@bob', '[\"incident_92ca683d\"]'), ('@mira', '[\"incident_0b0a197c\"]'), ('@alex', '[\"incident_0b0a197c\", \"incident_4f88c913\", \"incident_3b5f5b77\", \"incident_f64c79f0\", \"incident_a456431d\"]')]\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# ---------------------------------------------\n# Observability & Execution Trace Viewer\n# ---------------------------------------------\n# Displays the last 10 internal pipeline events captured during the demo run.\n# This provides full transparency into system behavior for debugging, auditing,\n# and validating multi-agent decision flow.\n     \nprint_header('Observability logs (last 10)')\nlogs = observability.dump()\nfor e in logs[-10:]:\n    print(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.909967Z","iopub.execute_input":"2025-11-30T07:26:02.910384Z","iopub.status.idle":"2025-11-30T07:26:02.930739Z","shell.execute_reply.started":"2025-11-30T07:26:02.910359Z","shell.execute_reply":"2025-11-30T07:26:02.929775Z"}},"outputs":[{"name":"stdout","text":"\n======== Observability logs (last 10) ========\n\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"## üîç Section 10 :  Evaluation of the System (#evaluation)\nThis section validates the end-to-end Silent Guardian pipeline using a small, controlled test set.  \nEach test case contains a short message stream with a known ground-truth severity label** (Gold) and compares it with the system-predicted severity.\n\nThe evaluation is executed in three stages:\n1. Initial baseline evaluation\n2. Robust output normalization for safe metric extraction\n3. Final stabilized evaluation with guaranteed tuple unpacking\n\nThis design ensures the system behaves correctly even when internal pipeline return formats change during experimentation.\n","metadata":{}},{"cell_type":"code","source":"# ---------------------------------------------\n# Evaluation Cell 1: Baseline Functional Check\n# ---------------------------------------------\n# Runs a labeled test set through the pipeline and prints\n# Gold (expected) vs Pred (predicted) severity levels.\n# This verifies that the end-to-end detection and scoring logic is working.\n\nprint_header('Evaluation')\nEVAL_SET = [\n    ([{'sender_id':'@u1','text':'Hi all, hello','ts': now_ts()}], 'Low'),\n    ([{'sender_id':'@u2','text':'You are worthless','ts': now_ts()}], 'High'),\n    ([{'sender_id':'@u3','text':'I will kill you','ts': now_ts()}], 'Immediate'),\n]\nprint('Running eval set (prints Gold vs Pred)')\nfor stream, gold in EVAL_SET:\n    inc, conv, classified, patterns, risk = pipeline.run_once(stream)\n    print(f\"Gold={gold} Pred={risk['severity']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.931675Z","iopub.execute_input":"2025-11-30T07:26:02.931964Z","iopub.status.idle":"2025-11-30T07:26:02.958705Z","shell.execute_reply.started":"2025-11-30T07:26:02.931941Z","shell.execute_reply":"2025-11-30T07:26:02.957613Z"}},"outputs":[{"name":"stdout","text":"\n======== Evaluation ========\n\nRunning eval set (prints Gold vs Pred)\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_3c8ef861 with 1 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 1 (ts range 2025-11-30T07:21:02.952338Z - 2025-11-30T07:31:02.952338Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_f937 labels:['none']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] score=0.00 severity=Low\n[InterventionPlanner] planned actions: ['suggest_support_message']\n[Observability] ethics_check\n[Pipeline] Created incident incident_67d2d39c severity=Low\n--- Moderator Notification: Incident incident_67d2d39c (severity=Low) ---\n[0] Action: suggest_support_message - Offer support\n[Observability] pipeline_complete\nGold=Low Pred=Low\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_f163c4b2 with 1 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 1 (ts range 2025-11-30T07:21:02.952348Z - 2025-11-30T07:31:02.952348Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_fca7 labels:['insult']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {'@u2': 0}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] score=0.90 severity=Immediate\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n[Observability] ethics_check\n[Observability] ethics_check\n\nEvidence for conversation convo_f163c4b2 (platform=slack)\nGenerated: 2025-11-30T07:26:02.954829Z\nRisk: {'score': 0.9, 'severity': 'Immediate'}\n\nMessages:\n- msg_fca7df56 | @u2 | You are worthless | labels=[{'label': 'insult', 'score': 0.9, 'span': 'worthless'}]\n\n[Pipeline] Created incident incident_80b12c72 severity=Immediate\n--- Moderator Notification: Incident incident_80b12c72 (severity=Immediate) ---\n[0] Action: create_incident_and_notify_hr - Escalate to HR\n[1] Action: generate_evidence_text - Create evidence text\n[Observability] pipeline_complete\nGold=High Pred=Immediate\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_593b67ab with 1 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 1 (ts range 2025-11-30T07:21:02.952350Z - 2025-11-30T07:31:02.952350Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_4e49 labels:['threat']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {'@u3': 0}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] score=0.95 severity=Immediate\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n[Observability] ethics_check\n[Observability] ethics_check\n\nEvidence for conversation convo_593b67ab (platform=slack)\nGenerated: 2025-11-30T07:26:02.955512Z\nRisk: {'score': 0.95, 'severity': 'Immediate'}\n\nMessages:\n- msg_4e49e055 | @u3 | I will kill you | labels=[{'label': 'threat', 'score': 0.95, 'span': 'i will kill'}]\n\n[Pipeline] Created incident incident_4ffc6a05 severity=Immediate\n--- Moderator Notification: Incident incident_4ffc6a05 (severity=Immediate) ---\n[0] Action: create_incident_and_notify_hr - Escalate to HR\n[1] Action: generate_evidence_text - Create evidence text\n[Observability] pipeline_complete\nGold=Immediate Pred=Immediate\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# ---------------------------------------------\n# Evaluation Cell 2: Pipeline Output Normalizer\n# ---------------------------------------------\n# Wraps pipeline.run_once with a robust normalizer to guarantee\n# a consistent return format: (incident, conv, classified, patterns, risk).\n# Also performs safe MemoryAgent updates without risking runtime crashes.\n# This ensures all evaluation logic works reliably across pipeline versions.\n\nfrom types import MethodType\nprint(\"Applying robust pipeline.run_once normalizer...\")\n\n# get the current 'raw' run function if saved previously (avoid losing the original)\noriginal = getattr(pipeline, '__orig_run__', None)\nif original is None:\n    # if not saved, assume current pipeline.run_once is the original\n    original = pipeline.run_once\n\ndef _normalized_run(raw_stream):\n    # call original\n    res = original(raw_stream)\n    # normalize to tuple (incident, conv, classified, patterns, risk)\n    if isinstance(res, tuple):\n        # assume the original already returns desired tuple\n        normalized = res\n    else:\n        # single incident returned -> try to reconstruct minimal tuple\n        incident = res\n        conv = None\n        classified = None\n        patterns = None\n        risk = None\n        # try to extract some fields if incident-like\n        if hasattr(incident, 'convo_id'):\n            conv = Conversation(convo_id=getattr(incident, 'convo_id'), platform='unknown', messages=[])\n        if hasattr(incident, 'severity'):\n            risk = {'severity': getattr(incident, 'severity')}\n        normalized = (incident, conv, classified, patterns, risk)\n\n    # Update memory safely (no attribute errors)\n    try:\n        incident_obj = normalized[0]\n        involved = getattr(incident_obj, 'involved_user_ids', None) or getattr(incident_obj, 'involved_users', None)\n        if involved and 'memory_agent' in globals():\n            for u in involved:\n                try:\n                    memory_agent.append_incident(u, getattr(incident_obj, 'incident_id', None))\n                except Exception as e:\n                    print(\"[pipeline memory update] append_incident error:\", e)\n            # informational\n            print(\"[pipeline memory update] updated memory_agent for involved users.\")\n    except Exception as e:\n        print(\"[pipeline memory update] unexpected error while updating memory:\", e)\n\n    return normalized\n\n# attach wrapper and remember original\npipeline.__orig_run__ = original\npipeline.run_once = MethodType(lambda self, raw_stream: _normalized_run(raw_stream), pipeline)\nprint(\"pipeline.run_once normalized: callers will receive a tuple (incident, conv, classified, patterns, risk).\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.964489Z","iopub.execute_input":"2025-11-30T07:26:02.964786Z","iopub.status.idle":"2025-11-30T07:26:02.986788Z","shell.execute_reply.started":"2025-11-30T07:26:02.964764Z","shell.execute_reply":"2025-11-30T07:26:02.985895Z"}},"outputs":[{"name":"stdout","text":"Applying robust pipeline.run_once normalizer...\npipeline.run_once normalized: callers will receive a tuple (incident, conv, classified, patterns, risk).\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# ---------------------------------------------\n# Evaluation Cell 3: Final Stabilized Validation\n# ---------------------------------------------\n# Executes the evaluation using the normalized pipeline output.\n# Safely extracts predicted severity and compares it with gold labels.\n# This cell represents the final verification step for detection accuracy\n# and can be extended for formal ML metrics in future versions.\n\nprint_header('Evaluation  - fixed unpacking')\nEVAL_SET = [\n    ([{'sender_id':'@u1','text':'Hi all, hello','ts': now_ts()}], 'Low'),\n    ([{'sender_id':'@u2','text':'You are worthless','ts': now_ts()}], 'High'),\n    ([{'sender_id':'@u3','text':'I will kill you','ts': now_ts()}], 'Immediate'),\n]\nprint('Running small eval set (prints Gold vs Pred)')\n\nfor stream, gold in EVAL_SET:\n    # call pipeline.run_once - accept either tuple return or single Incident\n    result = pipeline.run_once(stream)\n    if isinstance(result, tuple):\n        # expected tuple shape: (incident, conv, classified, patterns, risk)\n        incident = result[0] if len(result) > 0 else None\n        conv = result[1] if len(result) > 1 else None\n        classified = result[2] if len(result) > 2 else None\n        patterns = result[3] if len(result) > 3 else None\n        risk = result[4] if len(result) > 4 else (None if not incident else {'severity': incident.severity if hasattr(incident, 'severity') else None})\n    else:\n        # single object returned (incident-like)\n        incident = result\n        conv = classified = patterns = None\n        # try to derive risk if available on incident; else fallback\n        risk = {'severity': getattr(incident, 'severity', None)} if incident is not None else {'severity': None}\n\n    pred = risk.get('severity') if isinstance(risk, dict) else getattr(risk, 'severity', None)\n    print(f\"Gold={gold} Pred={pred}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:02.987821Z","iopub.execute_input":"2025-11-30T07:26:02.988218Z","iopub.status.idle":"2025-11-30T07:26:03.017226Z","shell.execute_reply.started":"2025-11-30T07:26:02.988184Z","shell.execute_reply":"2025-11-30T07:26:03.015836Z"}},"outputs":[{"name":"stdout","text":"\n======== Evaluation  - fixed unpacking ========\n\nRunning small eval set (prints Gold vs Pred)\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_44a6d7dc with 1 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 1 (ts range 2025-11-30T07:21:03.010931Z - 2025-11-30T07:31:03.010931Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_46ed labels:['none']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] score=0.00 severity=Low\n[InterventionPlanner] planned actions: ['suggest_support_message']\n[Observability] ethics_check\n[Pipeline] Created incident incident_437aca8b severity=Low\n--- Moderator Notification: Incident incident_437aca8b (severity=Low) ---\n[0] Action: suggest_support_message - Offer support\n[Observability] pipeline_complete\n[pipeline memory update] updated memory_agent for involved users.\nGold=Low Pred=Low\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_b69d6f6b with 1 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 1 (ts range 2025-11-30T07:21:03.010943Z - 2025-11-30T07:31:03.010943Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_69be labels:['insult']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {'@u2': 1}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] applying recidivism bump: 0.05\n[RiskScorerV2] score=0.95 severity=Immediate\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n[Observability] ethics_check\n[Observability] ethics_check\n\nEvidence for conversation convo_b69d6f6b (platform=slack)\nGenerated: 2025-11-30T07:26:03.012692Z\nRisk: {'score': 0.9500000000000001, 'severity': 'Immediate'}\n\nMessages:\n- msg_69bebe67 | @u2 | You are worthless | labels=[{'label': 'insult', 'score': 0.9, 'span': 'worthless'}]\n\n[Pipeline] Created incident incident_f81a140f severity=Immediate\n--- Moderator Notification: Incident incident_f81a140f (severity=Immediate) ---\n[0] Action: create_incident_and_notify_hr - Escalate to HR\n[1] Action: generate_evidence_text - Create evidence text\n[Observability] pipeline_complete\n[pipeline memory update] updated memory_agent for involved users.\nGold=High Pred=Immediate\n[Pipeline] run_once called\n[Ingestor] ingest_stream called\n[Ingestor] Produced conversation convo_77700296 with 1 messages\n[Observability] ingested_conversation\n[Extractor] extract_window called\n[Extractor] Window size: 1 (ts range 2025-11-30T07:21:03.010945Z - 2025-11-30T07:31:03.010945Z)\n[HarassmentClassifier_MCP] classify_messages called\n[HarassmentClassifier_MCP] msg:msg_c3ac labels:['threat']\n[PatternDetectorV2] detect_patterns called\n[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {'@u3': 1}}\n[RiskScorerV2] compute_risk called\n[RiskScorerV2] applying recidivism bump: 0.05\n[RiskScorerV2] score=1.00 severity=Immediate\n[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n[Observability] ethics_check\n[Observability] ethics_check\n\nEvidence for conversation convo_77700296 (platform=slack)\nGenerated: 2025-11-30T07:26:03.013147Z\nRisk: {'score': 1.0, 'severity': 'Immediate'}\n\nMessages:\n- msg_c3ac7d52 | @u3 | I will kill you | labels=[{'label': 'threat', 'score': 0.95, 'span': 'i will kill'}]\n\n[Pipeline] Created incident incident_e1b565bb severity=Immediate\n--- Moderator Notification: Incident incident_e1b565bb (severity=Immediate) ---\n[0] Action: create_incident_and_notify_hr - Escalate to HR\n[1] Action: generate_evidence_text - Create evidence text\n[Observability] pipeline_complete\n[pipeline memory update] updated memory_agent for involved users.\nGold=Immediate Pred=Immediate\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"\n# -----------------------------\n# Inspect in-memory DB (print summary)\n# -----------------------------\nprint_header('In-memory incidents summary')\ncur.execute('SELECT incident_id, convo_id, severity FROM incidents')\nfor r in cur.fetchall():\n    print(r)\n\nprint('\\n‚úÖ Demo complete ‚Äî all outputs are printed above (no files).')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:26:03.018223Z","iopub.execute_input":"2025-11-30T07:26:03.018496Z","iopub.status.idle":"2025-11-30T07:26:03.043268Z","shell.execute_reply.started":"2025-11-30T07:26:03.018469Z","shell.execute_reply":"2025-11-30T07:26:03.042246Z"}},"outputs":[{"name":"stdout","text":"\n======== In-memory incidents summary ========\n\n('incident_92ca683d', 'convo_2fb21d97', 'Low')\n('incident_0b0a197c', 'convo_01583389', 'Medium')\n('incident_4f88c913', 'convo_69d77704', 'Immediate')\n('incident_3b5f5b77', 'convo_9a25bbf1', 'Immediate')\n('incident_f64c79f0', 'convo_158b2671', 'Immediate')\n('incident_a456431d', 'convo_d3a06776', 'Immediate')\n('incident_67d2d39c', 'convo_3c8ef861', 'Low')\n('incident_80b12c72', 'convo_f163c4b2', 'Immediate')\n('incident_4ffc6a05', 'convo_593b67ab', 'Immediate')\n('incident_437aca8b', 'convo_44a6d7dc', 'Low')\n('incident_f81a140f', 'convo_b69d6f6b', 'Immediate')\n('incident_e1b565bb', 'convo_77700296', 'Immediate')\n\n‚úÖ Demo complete ‚Äî all outputs are printed above (no files).\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"## üìù Section 11 : Conclusion & Summary {#conclusion}\n","metadata":{}},{"cell_type":"markdown","source":"### Key Concepts Demonstrated\n\nThis capstone project successfully demonstrates the following advanced AI system concepts :\n\n1. ‚úÖ **Multi-Agent System**\n\n    - Multiple specialized agents such as Ingestor, Classifier, Pattern Detector, Risk    Scorer, Planner, Ethics, Evidence Builder, Notifier, Memory, and Observability\n\n    - A centralized pipeline orchestrator coordinating all agents\n\n     - Sequential and event-driven agent execution\n\n    - Agent collaboration for real-time detection and response\n\n2. ‚úÖ **Custom Tools & MCP (Model Control Plane)**\n\n    - Google Search Tool (simulated) integrated as a safe external tool\n\n    - MCP-based classifier switching between rule-based and LLM-sim modes\n\n    - Tool registry enabling safe experimentation and modular upgrades\n\n3. ‚úÖ **Sessions & Memory**\n\n    - Persistent user behavior tracking using SQLite / in-memory database\n\n    - Incident history (recidivism tracking) for repeat offenders\n\n    - Stateful context preserved across multiple interactions\n\n4. ‚úÖ **Observability**\n\n    - End-to-end event logging for every pipeline stage\n\n    - Tracks ingestion, classification, ethics checks, escalations, and completion\n\n    - Enables debugging, auditing, and system transparency\n\n5. ‚úÖ **Agent-to-Agent Communication**\n\n    - Agents communicate via the pipeline and Message Bus (A2A Pub/Sub)\n\n    - Real-time sharing between Classifier ‚Üí Pattern Detector ‚Üí Risk Scorer ‚Üí Planner\n\n    - Modular design allows agents to act as tools for other agents\n\n6. ‚úÖ **Agent Evaluation**\n\n    - Built evaluation framework for checking predictions\n\n    - Gold vs Predicted severity comparison\n\n    - Functional validation of full pipeline behavior\n\n## üèóÔ∏è Architecture Highlights\n\n - Modular Design: Each agent is independently replaceable\n\n - Scalable: New tools, models, or agents can be added easily\n\n - Observable: Complete visibility into system behavior\n\n - Stateful: Uses memory and session context for intelligent decisions\n\n - Ethics-Aware: All automated actions pass through policy checks\n\n - Human-in-the-Loop Ready: HR/moderator escalation is built-in\n\n## üéØ Value Proposition\n\n- This system helps organizations:\n\n- ‚úÖ Detect harassment automatically in real time\n\n- ‚úÖ Prevent repeated abuse using behavior history (recidivism tracking)\n\n- ‚úÖ Reduce manual moderation workload through automation\n\n- ‚úÖ Ensure ethical compliance before any enforcement\n\n- ‚úÖ Preserve legal evidence for HR and compliance teams\n\n- ‚úÖ Improve workplace safety and trust\n\n## üöÄ Future Enhancements\n\n- Integration with real chat platforms (Slack, MS Teams, Emails)\n\n- Automated sentiment trend analysis\n\n- Admin dashboard for live monitoring\n\n- Role-based access control (RBAC)\n\n- Multilingual harassment detection\n\n- Mobile and web UI for moderators\n\n## ‚úÖ Final Summary Statement\n\nThe Silent Guardian AI Safety Agent demonstrates how a multi-agent, memory-aware, observable, and ethics-driven AI system can be designed to automatically detect, assess, and intervene in harassment incidents at scale. This project showcases enterprise-","metadata":{}}]}