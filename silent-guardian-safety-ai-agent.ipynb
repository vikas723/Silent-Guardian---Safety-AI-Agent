{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b13a623",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:45.292173Z",
     "iopub.status.busy": "2025-11-30T07:31:45.291594Z",
     "iopub.status.idle": "2025-11-30T07:31:47.086508Z",
     "shell.execute_reply": "2025-11-30T07:31:47.085478Z"
    },
    "papermill": {
     "duration": 1.811395,
     "end_time": "2025-11-30T07:31:47.088306",
     "exception": false,
     "start_time": "2025-11-30T07:31:45.276911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/agents-intensive-capstone-project/Hackathon dataset.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78361b3e",
   "metadata": {
    "papermill": {
     "duration": 0.010234,
     "end_time": "2025-11-30T07:31:47.109394",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.099160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " <h1 style=\"font-size:28px;\"> üõ°Ô∏è Silent Guardian - Safety AI Agent ü§ñ </h1>\n",
    "\n",
    "**Capstone Project** - 5 - Day AI Agents Intensive Course <br>\n",
    "**Track:** Enterprise Agents <br>\n",
    "**Problem:** Organizations struggle to detect and respond to harassment across chats, emails, and collaboration tools ‚Äî causing delayed action, legal risk, and employee harm. <br>\n",
    "**Solution:** A privacy-first multi-agent system that scans communication streams, detects harassment patterns, generates safe intervention suggestions, builds evidence packets, and routes final decisions to human reviewers.\n",
    "\n",
    "<h2 style=\"font-size:24px;\"> üîë Key Features </h2>\n",
    "\n",
    "ü§ñ **Multi-Agent System:** Ingestor, Extractor, Classifier, Pattern Detector, Risk Scorer, Intervention Planner, Evidence Builder, Ethics, Memory, Notifier.<br>\n",
    "üè¢ **Enterprise Integrations:** Slack/Teams/email/CSV + Google Generative AI.<br>\n",
    "üõ†Ô∏è **Custom Tools:** PII redactor, severity scoring, PDF evidence generator, moderator action stub.<br>\n",
    "üß† **Memory:** User safety profiles & incident history via Memory Bank.<br>\n",
    "üìä **Observability:** Logs, traces, confidence scores, dashboards (incidents, severity).<br>\n",
    "üîó **A2A Communication:** Agents call each other through a structured protocol.<br>\n",
    "‚öñÔ∏è **Ethics & Human-in-the-Loop Controls:** Safety checks ensure high-risk actions need human approval before execution.<br>\n",
    "üìÑ **Evidence Generation:** Automatic markdown/PDF evidence packets summarizing conversations, labels, and risk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18717b3a",
   "metadata": {
    "papermill": {
     "duration": 0.010166,
     "end_time": "2025-11-30T07:31:47.129912",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.119746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìã Table of Contents \n",
    "\n",
    "1. [Setup & Configuration](#setup) \n",
    "2. [Architecture Overview](#architecture) \n",
    "3. [Custom Tools Implementation](#tools) \n",
    "4. [Specialized Agents](#agents) \n",
    "5. [Multi-Agent Orchestration](#orchestration)\n",
    "6. [Pipeline Setup and Initialization](#initialization)\n",
    "7. [Session and Memory Management](#Session) \n",
    "8. [Observability and Logging](#observability) \n",
    "9. [Demo Run and Usage](#demo) \n",
    "10. [Evaluation of the System](#evaluation)\n",
    "11. [Conclusion & Summary](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1da6076",
   "metadata": {
    "papermill": {
     "duration": 0.01072,
     "end_time": "2025-11-30T07:31:47.150848",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.140128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ‚öôÔ∏è Section 1 : Setup & Configuration {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897661ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.172662Z",
     "iopub.status.busy": "2025-11-30T07:31:47.172246Z",
     "iopub.status.idle": "2025-11-30T07:31:47.176297Z",
     "shell.execute_reply": "2025-11-30T07:31:47.175473Z"
    },
    "papermill": {
     "duration": 0.016685,
     "end_time": "2025-11-30T07:31:47.177632",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.160947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Install dependencies (if not already installed)\n",
    "# !pip install google-adk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d26c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.199614Z",
     "iopub.status.busy": "2025-11-30T07:31:47.199347Z",
     "iopub.status.idle": "2025-11-30T07:31:47.270395Z",
     "shell.execute_reply": "2025-11-30T07:31:47.269432Z"
    },
    "papermill": {
     "duration": 0.083832,
     "end_time": "2025-11-30T07:31:47.271896",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.188064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Configure API Key\n",
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "try:\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "    print(\"‚úÖ Gemini API key setup complete.\")\n",
    "except Exception as e:\n",
    "    # Fallback for local development\n",
    "    if \"GOOGLE_API_KEY\" in os.environ:\n",
    "        print(\"‚úÖ Using environment variable for API key.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è API key not found. Please set GOOGLE_API_KEY environment variable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b150e1e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.296524Z",
     "iopub.status.busy": "2025-11-30T07:31:47.295773Z",
     "iopub.status.idle": "2025-11-30T07:31:47.301288Z",
     "shell.execute_reply": "2025-11-30T07:31:47.300490Z"
    },
    "papermill": {
     "duration": 0.018634,
     "end_time": "2025-11-30T07:31:47.302744",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.284110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful! . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import sqlite3\n",
    "import time\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "print(\"‚úÖ All imports successful! . \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11180f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.325467Z",
     "iopub.status.busy": "2025-11-30T07:31:47.325167Z",
     "iopub.status.idle": "2025-11-30T07:31:47.331043Z",
     "shell.execute_reply": "2025-11-30T07:31:47.330112Z"
    },
    "papermill": {
     "duration": 0.018925,
     "end_time": "2025-11-30T07:31:47.332366",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.313441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Utility functions loaded successfully at 2025-11-30T07:31:47.327627Z\n"
     ]
    }
   ],
   "source": [
    "# --- GLOBAL UTILITY FUNCTIONS (must be defined before anything else) ---\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "def print_header(title: str):\n",
    "    print(\"\\n\" + \"=\"*12 + f\" {title} \" + \"=\"*12)\n",
    "\n",
    "def now_ts():\n",
    "    return datetime.utcnow().isoformat() + \"Z\"\n",
    "\n",
    "def gen_id(prefix=\"id\"):\n",
    "    return f\"{prefix}_{uuid.uuid4().hex[:8]}\"\n",
    "print(\"‚úÖ Utility functions loaded successfully at\", now_ts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77a871",
   "metadata": {
    "papermill": {
     "duration": 0.010788,
     "end_time": "2025-11-30T07:31:47.353826",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.343038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üèóÔ∏è Section 2 : Architecture Overview {#architecture} \n",
    "\n",
    "\n",
    "### System Architecture\n",
    "\n",
    "The Silent Guardian system is a privacy-first, multi-agent pipeline that detects, triages, and recommends interventions for harassment at scale.\n",
    "\n",
    "1) **Ingestor Agent** - Normalizes conversation streams (Slack/Teams/Chat), anonymizes PII, and creates Conversation objects.\n",
    "2) **Extractor / Context Agent** - Extracts a time window of messages around a focal message for focused analysis.\n",
    "3) **Harassment Classifier (MCP-aware)** - MCP switchable: fast rule mode or richer LLM-sim mode. Produces message-level labels + scores + explanations.\n",
    "4) **Pattern Detector (V2)** - Finds repeat targeting (mentions), builds recidivism counts using MemoryAgent history.\n",
    "5) **Risk Scorer (V2)** - Aggregates message scores, applies repeat-targeting and recidivism bumps ‚Üí maps to severity (Low / Medium / High / Immediate).\n",
    "6) **Intervention Planner** - Maps severity to recommended actions (support messages, moderator alert, HR escalation, evidence generation).\n",
    "7) **Ethics Agent** - Policy gate‚Äîdisallows destructive automated actions and requires human approval where needed.\n",
    "8) **Evidence Builder** - Assembles plain-text/markdown (or PDF) incident packet for moderators/HR (no external uploads required).\n",
    "9) **Notifier (Human-in-Loop)** - Simulated moderator notifications and supportive messages; integration point for Slack/email APIs.\n",
    "10) **Memory Agent (SQLite)** - In-notebook persistent memory for demo (incidents per user) so the system can detect recidivism across sessions.\n",
    "11) **Observability** - Structured logs for each pipeline step (ingest, classify, ethics check, incident create) to aid debugging and evaluation.\n",
    "12) **MessageBus (A2A pub/sub)** - Agent-to-Agent (A2A) pub/sub for parallel processing (e.g., post-classification pattern detection).\n",
    "13) **Tools / MCP** - Tool registry (e.g., GoogleSearchTool) and an MCP (Model Control Plane) to flip classifier modes during experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddcdbfa",
   "metadata": {
    "papermill": {
     "duration": 0.010437,
     "end_time": "2025-11-30T07:31:47.374741",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.364304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34cecf97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.396919Z",
     "iopub.status.busy": "2025-11-30T07:31:47.396602Z",
     "iopub.status.idle": "2025-11-30T07:31:47.404798Z",
     "shell.execute_reply": "2025-11-30T07:31:47.403931Z"
    },
    "papermill": {
     "duration": 0.020906,
     "end_time": "2025-11-30T07:31:47.406077",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.385171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ Data models ============\n",
      "Data models ready.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Data models \n",
    "# -----------------------------\n",
    "print_header(\"Data models\")\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    msg_id: str\n",
    "    sender_id: str\n",
    "    text: str\n",
    "    ts: str\n",
    "    attachments: List[str] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class Conversation:\n",
    "    convo_id: str\n",
    "    platform: str\n",
    "    messages: List[Message]\n",
    "    metadata: Dict[str,Any] = field(default_factory=dict)   \n",
    "\n",
    "@dataclass\n",
    "class Incident:\n",
    "    incident_id: str\n",
    "    convo_id: str\n",
    "    involved_user_ids: List[str]\n",
    "    start_ts: str\n",
    "    end_ts: str\n",
    "    labels: List[Dict[str, Any]]\n",
    "    severity: str\n",
    "    evidence: Optional[str]\n",
    "    status: str\n",
    "\n",
    "print(\"Data models ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab861cc",
   "metadata": {
    "papermill": {
     "duration": 0.01039,
     "end_time": "2025-11-30T07:31:47.427134",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.416744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Defining Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80dec33b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.449622Z",
     "iopub.status.busy": "2025-11-30T07:31:47.448957Z",
     "iopub.status.idle": "2025-11-30T07:31:47.455443Z",
     "shell.execute_reply": "2025-11-30T07:31:47.454620Z"
    },
    "papermill": {
     "duration": 0.01911,
     "end_time": "2025-11-30T07:31:47.456682",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.437572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "\n",
    "def now_ts():\n",
    "    return datetime.utcnow().isoformat() + \"Z\"\n",
    "\n",
    "def gen_id(prefix=\"id\"):\n",
    "    return f\"{prefix}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "def print_header(title: str):\n",
    "    print('\\n' + '='*8 + ' ' + title + ' ' + '='*8)\n",
    "\n",
    "# Simple anonymize\n",
    "PII_EMAIL_RE = re.compile(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\")\n",
    "PII_PHONE_RE = re.compile(r\"\\b\\+?\\d[\\d \\-]{6,}\\d\\b\")\n",
    "\n",
    "def anonymize_text(text: str) -> str:\n",
    "    t = PII_EMAIL_RE.sub(\"[EMAIL_REDACTED]\", text)\n",
    "    t = PII_PHONE_RE.sub(\"[PHONE_REDACTED]\", t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7185429",
   "metadata": {
    "papermill": {
     "duration": 0.010402,
     "end_time": "2025-11-30T07:31:47.477608",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.467206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üõ†Ô∏è Section 3 : Custom Tools Implementation {#tools}\n",
    "\n",
    "Creating Custom tools for MCP and Google Search tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780d69d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.499614Z",
     "iopub.status.busy": "2025-11-30T07:31:47.499338Z",
     "iopub.status.idle": "2025-11-30T07:31:47.507361Z",
     "shell.execute_reply": "2025-11-30T07:31:47.506375Z"
    },
    "papermill": {
     "duration": 0.020726,
     "end_time": "2025-11-30T07:31:47.508642",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.487916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== MCP / TOOL REGISTRY STATUS =====\n",
      "MCP Classifier Config : {'type': 'llm', 'version': 'v1'}\n",
      "Registered Tools      : ['google_search']\n",
      "Google API Key Loaded : True\n",
      "=======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Configuration / MCP / Tools\n",
    "# -----------------------------\n",
    "class ModelControlPlane:\n",
    "    def __init__(self):\n",
    "        # switch between 'rule' or 'llm' (llm is a simulated rich responder)\n",
    "        self.registry = {'classifier': {'type':'llm','version':'v1'}}\n",
    "    def get(self, name):\n",
    "        return self.registry.get(name)\n",
    "    def set(self, name, cfg):\n",
    "        self.registry[name] = cfg\n",
    "\n",
    "mcp = ModelControlPlane()\n",
    "\n",
    "class Tool:\n",
    "    def run(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GoogleSearchTool(Tool):\n",
    "    def __init__(self, api_key=None):\n",
    "        self.api_key = api_key\n",
    "    def run(self, query):\n",
    "        # demo-only: no external calls. Return placeholder structure.\n",
    "        print(f\"[GoogleSearchTool] (simulated) run: {query}\")\n",
    "        return {'query': query, 'hits': []}\n",
    "\n",
    "tool_registry = {'google_search': GoogleSearchTool(os.environ.get('GOOGLE_API_KEY'))}\n",
    "\n",
    "print(\"\\n===== MCP / TOOL REGISTRY STATUS =====\")\n",
    "print(\"MCP Classifier Config :\", mcp.get(\"classifier\"))\n",
    "print(\"Registered Tools      :\", list(tool_registry.keys()))\n",
    "print(\"Google API Key Loaded :\", bool(os.environ.get('GOOGLE_API_KEY')))\n",
    "print(\"=======================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932175d",
   "metadata": {
    "papermill": {
     "duration": 0.010305,
     "end_time": "2025-11-30T07:31:47.529611",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.519306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### SQLite Database Setup & Schema Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed070b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.552136Z",
     "iopub.status.busy": "2025-11-30T07:31:47.551322Z",
     "iopub.status.idle": "2025-11-30T07:31:47.557594Z",
     "shell.execute_reply": "2025-11-30T07:31:47.556828Z"
    },
    "papermill": {
     "duration": 0.01901,
     "end_time": "2025-11-30T07:31:47.558981",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.539971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== In-memory Memory DB ========\n",
      "‚úÖ In-memory SQLite DB ready (no files created).\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# In-memory DB (no files)\n",
    "# -----------------------------\n",
    "print_header(\"In-memory Memory DB\")\n",
    "# Use an in-memory SQLite DB so nothing is written to disk; persists for the notebook session\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cur = conn.cursor()\n",
    "cur.execute('''\n",
    "CREATE TABLE IF NOT EXISTS incidents (\n",
    "    incident_id TEXT PRIMARY KEY,\n",
    "    convo_id TEXT,\n",
    "    involved_users TEXT,\n",
    "    start_ts TEXT,\n",
    "    end_ts TEXT,\n",
    "    labels TEXT,\n",
    "    severity TEXT,\n",
    "    evidence TEXT,\n",
    "    status TEXT\n",
    ")\n",
    "''')\n",
    "cur.execute('''\n",
    "CREATE TABLE IF NOT EXISTS user_profiles (\n",
    "    user_id TEXT PRIMARY KEY,\n",
    "    anon_id TEXT,\n",
    "    safety_score REAL,\n",
    "    incidents TEXT\n",
    ")\n",
    "''')\n",
    "conn.commit()\n",
    "print(\"‚úÖ In-memory SQLite DB ready (no files created).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd0a65",
   "metadata": {
    "papermill": {
     "duration": 0.010653,
     "end_time": "2025-11-30T07:31:47.580282",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.569629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ü§ñ Section 4 : Specialized Agents {#agents}¬∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af875e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.602842Z",
     "iopub.status.busy": "2025-11-30T07:31:47.602509Z",
     "iopub.status.idle": "2025-11-30T07:31:47.610737Z",
     "shell.execute_reply": "2025-11-30T07:31:47.609564Z"
    },
    "papermill": {
     "duration": 0.021395,
     "end_time": "2025-11-30T07:31:47.612244",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.590849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Memory Agent ========\n",
      "MemoryAgent ready.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Agent 1: Memory Agent\n",
    "#Stores incident history for each user to support recidivism scoring.\n",
    "#Allows the system to get ‚Äúsmarter‚Äù with repeated interactions.\n",
    "# -----------------------------\n",
    "\n",
    "print_header(\"Memory Agent\")\n",
    "class MemoryAgent:\n",
    "    def __init__(self, conn):\n",
    "        self.conn = conn\n",
    "    def append_incident(self, user_id, incident_id):\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(\"SELECT incidents FROM user_profiles WHERE user_id=?\", (user_id,))\n",
    "        r = cur.fetchone()\n",
    "        if not r:\n",
    "            cur.execute(\"INSERT INTO user_profiles (user_id, anon_id, safety_score, incidents) VALUES (?,?,?,?)\",\n",
    "                        (user_id, gen_id('anon'), 0.5, json.dumps([incident_id])))\n",
    "        else:\n",
    "            incs = json.loads(r[0] or '[]')\n",
    "            incs.append(incident_id)\n",
    "            cur.execute(\"UPDATE user_profiles SET incidents=? WHERE user_id= ?\", (json.dumps(incs), user_id))\n",
    "        self.conn.commit()\n",
    "    def get_incidents(self, user_id):\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(\"SELECT incidents FROM user_profiles WHERE user_id=?\", (user_id,))\n",
    "        r = cur.fetchone()\n",
    "        return json.loads(r[0]) if r and r[0] else []\n",
    "\n",
    "memory_agent = MemoryAgent(conn)\n",
    "print(\"MemoryAgent ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c96d6856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.635651Z",
     "iopub.status.busy": "2025-11-30T07:31:47.635379Z",
     "iopub.status.idle": "2025-11-30T07:31:47.645745Z",
     "shell.execute_reply": "2025-11-30T07:31:47.644737Z"
    },
    "papermill": {
     "duration": 0.023752,
     "end_time": "2025-11-30T07:31:47.647040",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.623288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Ingestor & Extractor ========\n",
      "[Ingestor] init\n",
      "[Extractor] init\n",
      "Ingestor and Extractor Agent ready.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "#Agents 2 and 3 : Ingestor, Extractor\n",
    "#Ingestor - Converts raw chat messages into a clean, structured conversation format and ensures every downstream agent receives consistent and validated inputs.\n",
    "#Extractor - Selects the most relevant messages for analysis based on timestamps and prevents unnecessary processing and focuses the classifier on the correct slice of data.\n",
    "# -----------------------------\n",
    "\n",
    "print_header(\"Ingestor & Extractor\")\n",
    "class IngestorAgent:\n",
    "    def __init__(self):\n",
    "        print(\"[Ingestor] init\")\n",
    "    def ingest_stream(self, raw_stream: List[Dict[str,Any]], platform: str='slack') -> Conversation:\n",
    "        print(\"[Ingestor] ingest_stream called\")\n",
    "        convo_id = gen_id('convo')\n",
    "        messages = []\n",
    "        for m in raw_stream:\n",
    "            msg = Message(\n",
    "                msg_id=m.get('msg_id', gen_id('msg')),\n",
    "                sender_id=m.get('sender_id','unknown'),\n",
    "                text=anonymize_text(m.get('text','')),\n",
    "                ts=m.get('ts', now_ts()),\n",
    "                attachments=m.get('attachments', [])\n",
    "            )\n",
    "            messages.append(msg)\n",
    "        conv = Conversation(convo_id=convo_id, platform=platform, messages=messages)\n",
    "        print(f\"[Ingestor] Produced conversation {convo_id} with {len(messages)} messages\")\n",
    "        return conv\n",
    "\n",
    "class ExtractorAgent:\n",
    "    def __init__(self):\n",
    "        print(\"[Extractor] init\")\n",
    "    def extract_window(self, conv: Conversation, center_msg_idx:int=0, window_seconds:int=300):\n",
    "        print(\"[Extractor] extract_window called\")\n",
    "        if not conv.messages:\n",
    "            return []\n",
    "        center_ts = datetime.fromisoformat(conv.messages[center_msg_idx].ts.replace('Z',''))\n",
    "        lower = (center_ts - timedelta(seconds=window_seconds)).isoformat() + 'Z'\n",
    "        upper = (center_ts + timedelta(seconds=window_seconds)).isoformat() + 'Z'\n",
    "        window_msgs = [m for m in conv.messages if lower <= m.ts <= upper]\n",
    "        print(f\"[Extractor] Window size: {len(window_msgs)} (ts range {lower} - {upper})\")\n",
    "        return window_msgs\n",
    "\n",
    "ingestor = IngestorAgent()\n",
    "extractor = ExtractorAgent()\n",
    "print(\"Ingestor and Extractor Agent ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb1f209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.670366Z",
     "iopub.status.busy": "2025-11-30T07:31:47.669893Z",
     "iopub.status.idle": "2025-11-30T07:31:47.684922Z",
     "shell.execute_reply": "2025-11-30T07:31:47.684089Z"
    },
    "papermill": {
     "duration": 0.028256,
     "end_time": "2025-11-30T07:31:47.686181",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.657925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Harassment Classifier (MCP-aware, LLM-sim) ========\n",
      "[HarassmentClassifier] init\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Agent 4 : Classifier: MCP-aware, scalable \"LLM-sim\" mode\n",
    "#Applies multi-category harassment detection using rule-based and simulated LLM logic.\n",
    "#Acts as the first decision point that labels message severity and meaning.\n",
    "# -----------------------------\n",
    "\n",
    "print_header(\"Harassment Classifier (MCP-aware, LLM-sim)\")\n",
    "class HarassmentClassifierAgent:\n",
    "    def __init__(self):\n",
    "        print(\"[HarassmentClassifier] init\")\n",
    "        # small lexicons kept for rule-mode fallback\n",
    "        self.insult_keywords = set([\"stupid\",\"idiot\",\"worthless\",\"loser\",\"dumb\",\"hate you\",\"shut up\"]) \n",
    "        self.threat_keywords = set([\"kill you\",\"hurt you\",\"i'll kill\",\"i will kill\",\"die\",\"end you\"]) \n",
    "        self.doxxing_keywords = set([\"address\",\"phone\",\"where do you live\",\"i know where you live\",\"share her number\"]) \n",
    "\n",
    "    def classify_messages(self, messages: List[Message]) -> List[Dict[str,Any]]:\n",
    "        cfg = mcp.get('classifier') or {'type':'rule'}\n",
    "        mode = cfg.get('type','rule')\n",
    "        print(f\"[HarassmentClassifier] classify_messages called (mode={mode})\")\n",
    "        outputs = []\n",
    "        for m in messages:\n",
    "            if mode == 'rule':\n",
    "                out = self._rule_classify(m)\n",
    "            else:\n",
    "                out = self._llm_sim_classify(m)\n",
    "            outputs.append(out)\n",
    "            print(f\"[HarassmentClassifier] msg:{m.msg_id[:8]} labels:{[l['label'] for l in out['labels']]}\")\n",
    "        return outputs\n",
    "\n",
    "    def _rule_classify(self, m: Message):\n",
    "        text_lower = m.text.lower() if m.text else ''\n",
    "        labels = []\n",
    "        if any(k in text_lower for k in self.insult_keywords):\n",
    "            labels.append({'label':'insult','score':0.9,'span': self._find_span(text_lower,self.insult_keywords)})\n",
    "        if any(k in text_lower for k in self.threat_keywords):\n",
    "            labels.append({'label':'threat','score':0.95,'span': self._find_span(text_lower,self.threat_keywords)})\n",
    "        if any(k in text_lower for k in self.doxxing_keywords):\n",
    "            labels.append({'label':'doxxing','score':0.7,'span': self._find_span(text_lower,self.doxxing_keywords)})\n",
    "        if not labels:\n",
    "            labels = [{'label':'none','score':0.0,'span':''}]\n",
    "        return {'msg_id': m.msg_id, 'sender_id': m.sender_id, 'labels': labels, 'text': m.text}\n",
    "\n",
    "    def _llm_sim_classify(self, m: Message):\n",
    "        # Simulated LLM response: generate a rich JSON and a natural-language explanation.\n",
    "        txt = (m.text or '').strip()\n",
    "        labels = []\n",
    "        explanation = []\n",
    "        score = 0.0\n",
    "        # heuristics but produce richer textual reasoning\n",
    "        if any(k in txt.lower() for k in self.threat_keywords):\n",
    "            labels.append({'label':'threat','score':0.98,'span': self._find_span(txt.lower(), self.threat_keywords)})\n",
    "            explanation.append('Message contains explicit threat language.')\n",
    "            score = max(score, 0.98)\n",
    "        if any(k in txt.lower() for k in self.doxxing_keywords):\n",
    "            labels.append({'label':'doxxing','score':0.8,'span': self._find_span(txt.lower(), self.doxxing_keywords)})\n",
    "            explanation.append('Possible doxxing-related phrasing detected.')\n",
    "            score = max(score, 0.8)\n",
    "        if any(k in txt.lower() for k in self.insult_keywords) or re.search(r\"\\bidiot\\b|\\bdumb\\b|\\bworthless\\b\", txt.lower()):\n",
    "            labels.append({'label':'insult','score':0.9,'span': self._find_span(txt.lower(), self.insult_keywords)})\n",
    "            explanation.append('Insulting / demeaning language present.')\n",
    "            score = max(score, 0.9)\n",
    "        # If no label found, ask a clarifying simulated question in the output for interactive queries\n",
    "        if not labels:\n",
    "            labels = [{'label':'none','score':0.0,'span':''}]\n",
    "            explanation.append('No clear harassment label detected; message appears benign or ambiguous.')\n",
    "        # Build a natural language summary as the \"assistant\" output for user queries\n",
    "        nl = f\"Classifier (LLM-sim) analysis: labels={','.join([l['label'] for l in labels])}; rationale={' | '.join(explanation)}\"\n",
    "        return {'msg_id': m.msg_id, 'sender_id': m.sender_id, 'labels': labels, 'text': m.text, 'explanation': nl}\n",
    "\n",
    "    def _find_span(self, text: str, lexicon: set):\n",
    "        for k in lexicon:\n",
    "            if k in text:\n",
    "                return k\n",
    "        return ''\n",
    "\n",
    "classifier = HarassmentClassifierAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4557cf40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.709430Z",
     "iopub.status.busy": "2025-11-30T07:31:47.709107Z",
     "iopub.status.idle": "2025-11-30T07:31:47.716978Z",
     "shell.execute_reply": "2025-11-30T07:31:47.715759Z"
    },
    "papermill": {
     "duration": 0.020965,
     "end_time": "2025-11-30T07:31:47.718256",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.697291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Pattern Detector ========\n",
      "[PatternDetector] init\n",
      "Pattern Detector Agent ready.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Agent 5 : Pattern Detector (uses MemoryAgent)\n",
    "#Finds repeat targeting, mentions, and historical recidivism using MemoryAgent.\n",
    "#Helps the system understand whether an offender is repeating harmful behavior.\n",
    "# -----------------------------\n",
    "\n",
    "print_header(\"Pattern Detector\")\n",
    "class PatternDetectorAgent:\n",
    "    def __init__(self, memory_agent: MemoryAgent):\n",
    "        print(\"[PatternDetector] init\")\n",
    "        self.memory = memory_agent\n",
    "    def detect_patterns(self, conv: Conversation, classified_msgs: List[Dict[str,Any]]) -> Dict[str,Any]:\n",
    "        print(\"[PatternDetector] detect_patterns called\")\n",
    "        patterns = {'repeat_targeting': [], 'recidivism': {}}\n",
    "        for cm in classified_msgs:\n",
    "            labels = [l['label'] for l in cm['labels'] if l['label']!='none']\n",
    "            if labels:\n",
    "                sender = cm['sender_id']\n",
    "                potential_targets = re.findall(r\"@\\w+\", cm.get('text') or '')\n",
    "                for t in potential_targets:\n",
    "                    patterns['repeat_targeting'].append({'sender': sender, 'target': t, 'msg_id': cm['msg_id']})\n",
    "                # check memory for historical incidents\n",
    "                prev = self.memory.get_incidents(sender)\n",
    "                patterns['recidivism'][sender] = len(prev)\n",
    "        print(f\"[PatternDetector] found patterns: {patterns}\")\n",
    "        return patterns\n",
    "\n",
    "pattern_detector = PatternDetectorAgent(memory_agent)\n",
    "print(\"Pattern Detector Agent ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c616216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.741442Z",
     "iopub.status.busy": "2025-11-30T07:31:47.741127Z",
     "iopub.status.idle": "2025-11-30T07:31:47.750069Z",
     "shell.execute_reply": "2025-11-30T07:31:47.748907Z"
    },
    "papermill": {
     "duration": 0.022013,
     "end_time": "2025-11-30T07:31:47.751298",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.729285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Risk Scorer ========\n",
      "[RiskScorer] init\n",
      "Risk scorer Agent ready.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Agent 6 : Risk Scorer (recidivism-aware)\n",
    "#Converts labels and patterns into a numerical risk score and severity class.\n",
    "#Decides whether a situation is Low, High, or Immediate risk.\n",
    "# -----------------------------\n",
    "\n",
    "print_header(\"Risk Scorer\")\n",
    "class RiskScorerAgent:\n",
    "    def __init__(self):\n",
    "        print(\"[RiskScorer] init\")\n",
    "    def compute_risk(self, classified_msgs: List[Dict[str,Any]], patterns: Dict[str,Any]) -> Dict[str,Any]:\n",
    "        print(\"[RiskScorer] compute_risk called\")\n",
    "        base_scores = [max((l.get('score',0.0) for l in cm['labels'])) for cm in classified_msgs] if classified_msgs else []\n",
    "        avg_score = sum(base_scores)/len(base_scores) if base_scores else 0.0\n",
    "        repeat_count = len(patterns.get('repeat_targeting', []))\n",
    "        if repeat_count >= 3:\n",
    "            avg_score = min(1.0, avg_score + 0.2)\n",
    "        # recidivism bump\n",
    "        recidivism_bump = 0.0\n",
    "        for sender, count in patterns.get('recidivism', {}).items():\n",
    "            if count > 0:\n",
    "                recidivism_bump = max(recidivism_bump, min(0.3, 0.05 * count))\n",
    "        if recidivism_bump > 0:\n",
    "            print(f\"[RiskScorer] applying recidivism bump: {recidivism_bump}\")\n",
    "            avg_score = min(1.0, avg_score + recidivism_bump)\n",
    "        severity = 'Low'\n",
    "        if avg_score >= 0.8:\n",
    "            severity = 'Immediate'\n",
    "        elif avg_score >= 0.5:\n",
    "            severity = 'High'\n",
    "        elif avg_score >= 0.2:\n",
    "            severity = 'Medium'\n",
    "        risk = {'score': avg_score, 'severity': severity}\n",
    "        print(f\"[RiskScorer] score={avg_score:.2f} severity={severity}\")\n",
    "        return risk\n",
    "\n",
    "risk_scorer = RiskScorerAgent()\n",
    "print(\"Risk scorer Agent ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73234cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.774897Z",
     "iopub.status.busy": "2025-11-30T07:31:47.774492Z",
     "iopub.status.idle": "2025-11-30T07:31:47.785296Z",
     "shell.execute_reply": "2025-11-30T07:31:47.784448Z"
    },
    "papermill": {
     "duration": 0.024199,
     "end_time": "2025-11-30T07:31:47.786528",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.762329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Ethics / Planner / Notifier ========\n",
      "Ethics Planner and Notifier Agent ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Agent 7, 8 and 9 :  Ethics, Planner, Notifier\n",
    "# Ethics - Blocks unsafe or inappropriate actions before they reach the moderato and ensures all interventions comply with safety, fairness, and ethical guidelines.\n",
    "# Planner - Chooses the best action to take (notify HR, generate evidence, support message) and applies decision rules based on severity, threat level, and patterns.\n",
    "# Notifier - Handles human-in-the-loop communication by alerting moderators during escalations and sends supportive or guidance messages directly to affected users when appropriate.\n",
    "# -----------------------------\n",
    "\n",
    "print_header(\"Ethics / Planner / Notifier\")\n",
    "class EthicsAgent:\n",
    "    def __init__(self, policy: Dict[str,Any]):\n",
    "        self.policy = policy\n",
    "    def check(self, action: Dict[str,Any]) -> Dict[str,Any]:\n",
    "        if action.get('action_type') in ['ban_user','fire_employee','legal_escalation']:\n",
    "            return {'allowed': False, 'reason':'Human approval required'}\n",
    "        if action.get('action_type')=='auto_message' and not self.policy.get('allow_auto_messages', False):\n",
    "            return {'allowed': False, 'reason':'Auto messages disabled'}\n",
    "        return {'allowed': True}\n",
    "\n",
    "ethics = EthicsAgent({'allow_auto_messages': True})\n",
    "\n",
    "class InterventionPlannerAgent:\n",
    "    def plan(self, conv, classified_msgs, risk, patterns):\n",
    "        severity = risk['severity']\n",
    "        actions = []\n",
    "        if severity=='Low':\n",
    "            actions.append({'action_type':'suggest_support_message','rationale':'Offer support','message_template':'I noticed a tense exchange ‚Äî are you okay?'})\n",
    "        elif severity=='Medium':\n",
    "            actions.append({'action_type':'notify_moderator','rationale':'Moderator review recommended','message_template':''})\n",
    "        else:\n",
    "            actions.append({'action_type':'create_incident_and_notify_hr','rationale':'Escalate to HR','message_template':''})\n",
    "            actions.append({'action_type':'generate_evidence_text','rationale':'Create evidence text','message_template':''})\n",
    "        print(f\"[InterventionPlanner] planned actions: {[a['action_type'] for a in actions]}\")\n",
    "        return actions\n",
    "\n",
    "planner = InterventionPlannerAgent()\n",
    "\n",
    "class NotifierAgent:\n",
    "    def notify_moderator(self, incident, actions):\n",
    "        print(f\"--- Moderator Notification: Incident {incident.incident_id} (severity={incident.severity}) ---\")\n",
    "        for i,a in enumerate(actions):\n",
    "            print(f\"[{i}] Action: {a['action_type']} - {a.get('rationale','')}\")\n",
    "    def send_supportive_message(self, user_id, msg):\n",
    "        print(f\"[Notifier] Supportive message to {user_id}: {msg}\")\n",
    "\n",
    "notifier = NotifierAgent()\n",
    "print(\"Ethics Planner and Notifier Agent ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "005bdf36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.810147Z",
     "iopub.status.busy": "2025-11-30T07:31:47.809842Z",
     "iopub.status.idle": "2025-11-30T07:31:47.817376Z",
     "shell.execute_reply": "2025-11-30T07:31:47.816501Z"
    },
    "papermill": {
     "duration": 0.020869,
     "end_time": "2025-11-30T07:31:47.818589",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.797720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Evidence Builder ========\n",
      "Evidence Builder Agent ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Agent 10 : Evidence Builder (no files: returns/prints evidence text)\n",
    "#Creates structured text evidence for incidents needing HR escalation.\n",
    "#Includes message history, labels, severity, and reasoning.\n",
    "# -----------------------------\n",
    "\n",
    "print_header(\"Evidence Builder\")\n",
    "class EvidenceBuilderAgent:\n",
    "    def build_evidence_text(self, conv: Conversation, classified_msgs: List[Dict[str,Any]], risk: Dict[str,Any]) -> str:\n",
    "        lines = []\n",
    "        lines.append(f\"Evidence for conversation {conv.convo_id} (platform={conv.platform})\")\n",
    "        lines.append(f\"Generated: {now_ts()}\")\n",
    "        lines.append(f\"Risk: {risk}\")\n",
    "        lines.append('\\nMessages:')\n",
    "        for cm in classified_msgs:\n",
    "            lines.append(f\"- {cm['msg_id']} | {cm['sender_id']} | {cm.get('text','')} | labels={cm['labels']}\")\n",
    "            if 'explanation' in cm:\n",
    "                lines.append(f\"  explanation: {cm['explanation']}\")\n",
    "        txt = '\\n'.join(lines)\n",
    "        print('\\n' + txt + '\\n')\n",
    "        return txt\n",
    "\n",
    "evidence_builder = EvidenceBuilderAgent()\n",
    "print(\"Evidence Builder Agent ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fc792db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.842092Z",
     "iopub.status.busy": "2025-11-30T07:31:47.841793Z",
     "iopub.status.idle": "2025-11-30T07:31:47.848115Z",
     "shell.execute_reply": "2025-11-30T07:31:47.847200Z"
    },
    "papermill": {
     "duration": 0.019757,
     "end_time": "2025-11-30T07:31:47.849395",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.829638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Observability ========\n",
      "Observability Agent ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Agent 11 : Observability (in-memory)\n",
    "# Captures logs for every stage of the pipeline (ingestion ‚Üí ethics ‚Üí finish).\n",
    "# Provides complete transparency for debugging, evaluation, and audits.\n",
    "# -----------------------------\n",
    "\n",
    "print_header(\"Observability\")\n",
    "class ObservabilityAgent:\n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "    def log(self, entry: Dict[str,Any]):\n",
    "        entry['ts'] = now_ts()\n",
    "        self.logs.append(entry)\n",
    "        print(f\"[Observability] {entry.get('event','unknown')}\")\n",
    "    def dump(self):\n",
    "        # return logs for display in notebook\n",
    "        return list(self.logs)\n",
    "\n",
    "observability = ObservabilityAgent()\n",
    "print(\"Observability Agent ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2971373",
   "metadata": {
    "papermill": {
     "duration": 0.010935,
     "end_time": "2025-11-30T07:31:47.871566",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.860631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üéØ Section 5 : Multi-Agent Orchestration {#orchestration}¬∂\n",
    "\n",
    "This system coordinates multiple specialized agents‚Äîingestion, classification, pattern detection, etc into one unified workflow and each agent performs its own task independently, and the orchestrator (pipeline) links them together so the entire harassment-detection process runs automatically, end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e07a060a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.895620Z",
     "iopub.status.busy": "2025-11-30T07:31:47.894888Z",
     "iopub.status.idle": "2025-11-30T07:31:47.899559Z",
     "shell.execute_reply": "2025-11-30T07:31:47.898731Z"
    },
    "papermill": {
     "duration": 0.018425,
     "end_time": "2025-11-30T07:31:47.901017",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.882592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# COMBINED PATCH ‚Äî Overview & developer notes\n",
    "#\n",
    "# Summary:\n",
    "# This patch upgrades the notebook with production-ready demo features:\n",
    "#  - Replaces the classifier with an MCP-aware hybrid implementation (HarassmentClassifierAgent_MCP)\n",
    "#    that can run in fast 'rule' mode or a conservative 'llm' (simulated) mode via the MCP.\n",
    "#  - Installs PatternDetectorAgentV2 which uses memory (recidivism lookup) to detect repeat targeting.\n",
    "#  - Installs RiskScorerAgentV2 which applies repeat-targeting and recidivism bumps to risk scores.\n",
    "#  - Adds a lightweight MessageBus (pub/sub) for agent-to-agent communication and safe async handlers.\n",
    "#  - Exposes a FastAPI ingest stub for integration testing.\n",
    "#  - Monkeypatches pipeline.run_once to ensure MemoryAgent is updated after incidents are created.\n",
    "#\n",
    "# Why this patch:\n",
    "#  - Enables MCP-driven experiments (flip classifier mode via mcp.set(...)).\n",
    "#  - Improves detection quality by incorporating historical incidents (recidivism).\n",
    "#  - Demonstrates agent-to-agent messaging and pluggable tool usage (google_search stub).\n",
    "#  - Keeps the notebook self-contained and safe for Kaggle (no external LLM calls).\n",
    "#\n",
    "# How to use / test:\n",
    "#  1. Flip classifier mode: mcp.set('classifier', {'type':'rule'})  (or {'type':'llm'} for demo).\n",
    "#  2. Run a single abusive stream multiple times (3+) ‚Äî observe risk bump from repeat-targeting.\n",
    "#  3. Check user memory table and incidents: SELECT * FROM user_profiles / incidents (or use cur.execute).\n",
    "# -----------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ab3713e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:47.924931Z",
     "iopub.status.busy": "2025-11-30T07:31:47.924612Z",
     "iopub.status.idle": "2025-11-30T07:31:48.806973Z",
     "shell.execute_reply": "2025-11-30T07:31:48.806006Z"
    },
    "papermill": {
     "duration": 0.896079,
     "end_time": "2025-11-30T07:31:48.808216",
     "exception": false,
     "start_time": "2025-11-30T07:31:47.912137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Applying combined patch: MCP-aware classifier, PatternDetectorV2, RiskScorerV2, MessageBus, pipeline memory update ========\n",
      "[HarassmentClassifier_MCP] init\n",
      "Replaced classifier with HarassmentClassifierAgent_MCP\n",
      "pipeline not present or not yet instantiated; classifier object ready.\n",
      "[PatternDetectorV2] init\n",
      "Instantiated PatternDetectorAgentV2 and assigned to 'pattern_detector'\n",
      "[RiskScorerV2] init\n",
      "Instantiated RiskScorerAgentV2 and assigned to 'risk_scorer'\n",
      "Pipeline not present; components ready to attach when pipeline is re-created.\n",
      "MessageBus initialized.\n",
      "Registered pattern_handler on topic 'classified_messages'\n",
      "FastAPI stub defined. (Not running server in notebook.)\n",
      "No pipeline object found; cannot monkeypatch run_once. Create pipeline then re-run this cell.\n",
      "\n",
      "======== COMBINED PATCH APPLIED - Test suggestion ========\n",
      "Suggested test: run one abusive stream multiple times (3+) to see recidivism bump in RiskScorerV2.\n",
      "To flip classifier to LLM-mode (demo), run: mcp.set('classifier', {'type':'llm','version':'v1'})\n"
     ]
    }
   ],
   "source": [
    "# ------------------ COMBINED PATCH CELL ------------------\n",
    "print_header(\"Applying combined patch: MCP-aware classifier, PatternDetectorV2, RiskScorerV2, MessageBus, pipeline memory update\")\n",
    "\n",
    "# 1) MCP-aware classifier (safe replacement)\n",
    "class HarassmentClassifierAgent_MCP:\n",
    "    def __init__(self):\n",
    "        print(\"[HarassmentClassifier_MCP] init\")\n",
    "        self.insult_keywords = set([\"stupid\",\"idiot\",\"worthless\",\"loser\",\"dumb\",\"hate you\",\"shut up\"])\n",
    "        self.threat_keywords = set([\"kill you\",\"hurt you\",\"i'll kill\",\"i will kill\",\"die\",\"end you\"])\n",
    "        self.doxxing_keywords = set([\"address\",\"phone\",\"where do you live\",\"i know where you live\",\"share her number\"])\n",
    "\n",
    "    def classify_messages(self, messages: List[Message]) -> List[Dict[str, Any]]:\n",
    "        print(\"[HarassmentClassifier_MCP] classify_messages called\")\n",
    "        outputs = []\n",
    "        cfg = mcp.get('classifier') if 'mcp' in globals() else {'type':'rule'}\n",
    "        mode = cfg.get('type', 'rule')\n",
    "        for m in messages:\n",
    "            if mode == 'rule':\n",
    "                text_lower = m.text.lower()\n",
    "                labels = []\n",
    "                if any(k in text_lower for k in self.insult_keywords):\n",
    "                    labels.append({'label':'insult', 'score':0.9, 'span': self._find_span(text_lower, self.insult_keywords)})\n",
    "                if any(k in text_lower for k in self.threat_keywords):\n",
    "                    labels.append({'label':'threat', 'score':0.95, 'span': self._find_span(text_lower, self.threat_keywords)})\n",
    "                if any(k in text_lower for k in self.doxxing_keywords):\n",
    "                    labels.append({'label':'doxxing', 'score':0.7, 'span': self._find_span(text_lower, self.doxxing_keywords)})\n",
    "                if not labels:\n",
    "                    labels = [{'label':'none', 'score':0.0, 'span':''}]\n",
    "                out = {'msg_id': m.msg_id, 'sender_id': m.sender_id, 'labels': labels, 'text': m.text}\n",
    "                outputs.append(out)\n",
    "                print(f\"[HarassmentClassifier_MCP] msg:{m.msg_id[:8]} labels:{[l['label'] for l in labels]}\")\n",
    "            else:\n",
    "                # LLM mode placeholder: show prompt, optionally call a safe tool\n",
    "                prompt = f\"Classify the following message for harassment categories: {m.text}\"\n",
    "                print(f\"[HarassmentClassifier_MCP][LLM-mode] prompt: {prompt[:120]}\")\n",
    "                tool_result = None\n",
    "                if 'tool_registry' in globals() and tool_registry.get('google_search'):\n",
    "                    tool_result = tool_registry['google_search'].run(m.text)\n",
    "                # conservative fallback\n",
    "                labels = [{'label':'none', 'score':0.0, 'span':''}]\n",
    "                out = {'msg_id': m.msg_id, 'sender_id': m.sender_id, 'labels': labels, 'text': m.text, 'tool_result': tool_result}\n",
    "                outputs.append(out)\n",
    "                print(f\"[HarassmentClassifier_MCP][LLM-mode] msg:{m.msg_id[:8]} labels:{[l['label'] for l in labels]}\")\n",
    "        return outputs\n",
    "\n",
    "    def _find_span(self, text: str, lexicon: set):\n",
    "        for k in lexicon:\n",
    "            if k in text:\n",
    "                return k\n",
    "        return ''\n",
    "\n",
    "# create and attach\n",
    "classifier = HarassmentClassifierAgent_MCP()\n",
    "print(\"Replaced classifier with HarassmentClassifierAgent_MCP\")\n",
    "mcp.set('classifier', {'type':'rule','version':'v0'})\n",
    "try:\n",
    "    pipeline.classifier = classifier\n",
    "    print(\"pipeline.classifier updated.\")\n",
    "except Exception:\n",
    "    print(\"pipeline not present or not yet instantiated; classifier object ready.\")\n",
    "\n",
    "# 2) PatternDetector V2 (uses memory_agent.get_incidents if available)\n",
    "class PatternDetectorAgentV2:\n",
    "    def __init__(self, memory_conn):\n",
    "        print(\"[PatternDetectorV2] init\")\n",
    "        self.conn = memory_conn\n",
    "\n",
    "    def detect_patterns(self, conv: Conversation, classified_msgs: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        print(\"[PatternDetectorV2] detect_patterns called\")\n",
    "        patterns = {'repeat_targeting': [], 'recidivism': {}}\n",
    "        for cm in classified_msgs:\n",
    "            labels = [l['label'] for l in cm['labels'] if l['label'] != 'none']\n",
    "            if labels:\n",
    "                sender = cm['sender_id']\n",
    "                potential_targets = re.findall(r\"@\\w+\", cm.get('text','') or '')\n",
    "                for t in potential_targets:\n",
    "                    patterns['repeat_targeting'].append({'sender': sender, 'target': t, 'msg_id': cm['msg_id']})\n",
    "                # historical incidents via memory_agent\n",
    "                if 'memory_agent' in globals():\n",
    "                    try:\n",
    "                        prev_incs = memory_agent.get_incidents(sender)\n",
    "                        patterns['recidivism'][sender] = len(prev_incs)\n",
    "                    except Exception as e:\n",
    "                        print(\"[PatternDetectorV2] memory_agent.get_incidents error:\", e)\n",
    "        print(f\"[PatternDetectorV2] found patterns: {patterns}\")\n",
    "        return patterns\n",
    "\n",
    "pattern_detector = PatternDetectorAgentV2(conn)\n",
    "print(\"Instantiated PatternDetectorAgentV2 and assigned to 'pattern_detector'\")\n",
    "\n",
    "# 3) RiskScorer V2 (applies recidivism bump)\n",
    "class RiskScorerAgentV2:\n",
    "    def __init__(self):\n",
    "        print(\"[RiskScorerV2] init\")\n",
    "\n",
    "    def compute_risk(self, classified_msgs: List[Dict[str, Any]], patterns: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        print(\"[RiskScorerV2] compute_risk called\")\n",
    "        base_scores = []\n",
    "        for cm in classified_msgs:\n",
    "            max_score = max(l.get('score', 0.0) for l in cm['labels'])\n",
    "            base_scores.append(max_score)\n",
    "        avg_score = sum(base_scores) / len(base_scores) if base_scores else 0.0\n",
    "        repeat_count = len(patterns.get('repeat_targeting', []))\n",
    "        if repeat_count >= 3:\n",
    "            avg_score = min(1.0, avg_score + 0.2)\n",
    "        # recidivism bump\n",
    "        recidivism_bump = 0.0\n",
    "        if 'recidivism' in patterns:\n",
    "            for sender, count in patterns['recidivism'].items():\n",
    "                if count >= 1:\n",
    "                    recidivism_bump = max(recidivism_bump, min(0.3, 0.05 * count))\n",
    "        if recidivism_bump > 0:\n",
    "            print(f\"[RiskScorerV2] applying recidivism bump: {recidivism_bump}\")\n",
    "            avg_score = min(1.0, avg_score + recidivism_bump)\n",
    "        severity = 'Low'\n",
    "        if avg_score >= 0.8:\n",
    "            severity = 'Immediate'\n",
    "        elif avg_score >= 0.5:\n",
    "            severity = 'High'\n",
    "        elif avg_score >= 0.2:\n",
    "            severity = 'Medium'\n",
    "        risk = {'score': avg_score, 'severity': severity}\n",
    "        print(f\"[RiskScorerV2] score={avg_score:.2f} severity={severity}\")\n",
    "        return risk\n",
    "\n",
    "risk_scorer = RiskScorerAgentV2()\n",
    "print(\"Instantiated RiskScorerAgentV2 and assigned to 'risk_scorer'\")\n",
    "\n",
    "# Reattach components to pipeline if available\n",
    "try:\n",
    "    pipeline.pattern_detector = pattern_detector\n",
    "    pipeline.risk_scorer = risk_scorer\n",
    "    pipeline.classifier = classifier\n",
    "    print(\"Reattached pattern_detector, risk_scorer, classifier to pipeline.\")\n",
    "except Exception:\n",
    "    print(\"Pipeline not present; components ready to attach when pipeline is re-created.\")\n",
    "\n",
    "# 4) MessageBus A2A pub/sub\n",
    "class MessageBus:\n",
    "    def __init__(self):\n",
    "        self.handlers = {}\n",
    "    def register(self, topic, fn):\n",
    "        self.handlers.setdefault(topic, []).append(fn)\n",
    "    def publish(self, topic, payload):\n",
    "        print(f\"[MessageBus] publish: {topic}\")\n",
    "        for h in self.handlers.get(topic, []):\n",
    "            try:\n",
    "                h(payload)\n",
    "            except Exception as e:\n",
    "                print(f\"[MessageBus] handler error: {e}\")\n",
    "\n",
    "bus = MessageBus()\n",
    "print(\"MessageBus initialized.\")\n",
    "\n",
    "# Example handler: on classified messages, run async pattern detection (demo)\n",
    "def _pattern_handler(payload):\n",
    "    try:\n",
    "        conv = payload.get('conv')\n",
    "        classified = payload.get('classified')\n",
    "        pd = pattern_detector.detect_patterns(conv, classified)\n",
    "        print(\"[MessageBus pattern_handler] detected patterns:\", pd)\n",
    "    except Exception as e:\n",
    "        print(\"[MessageBus pattern_handler] error:\", e)\n",
    "\n",
    "# register handler (safe if pattern_detector exists)\n",
    "if 'pattern_detector' in globals():\n",
    "    bus.register('classified_messages', _pattern_handler)\n",
    "    print(\"Registered pattern_handler on topic 'classified_messages'\")\n",
    "\n",
    "# 5) FastAPI stub\n",
    "try:\n",
    "    from fastapi import FastAPI\n",
    "    from pydantic import BaseModel\n",
    "    app = FastAPI()\n",
    "    class IngestPayload(BaseModel):\n",
    "        messages: list\n",
    "    @app.post('/ingest')\n",
    "    def ingest_endpoint(payload: IngestPayload):\n",
    "        stream = payload.messages\n",
    "        incident = pipeline.run_once(stream)\n",
    "        return {'incident_id': incident.incident_id, 'severity': incident.severity}\n",
    "    print(\"FastAPI stub defined. (Not running server in notebook.)\")\n",
    "except Exception:\n",
    "    print(\"FastAPI not available in this environment (optional).\")\n",
    "\n",
    "# 6) Monkeypatch pipeline.run_once to update MemoryAgent after incident creation\n",
    "try:\n",
    "    if 'pipeline' in globals():\n",
    "        old_run = pipeline.run_once\n",
    "        def _run_and_update_memory(raw_stream):\n",
    "            # call existing pipeline logic (which returns an Incident)\n",
    "            incident = old_run(raw_stream)\n",
    "            # update memory agent for involved users if available\n",
    "            try:\n",
    "                if 'memory_agent' in globals():\n",
    "                    for u in incident.involved_user_ids:\n",
    "                        try:\n",
    "                            memory_agent.append_incident(u, incident.incident_id)\n",
    "                        except Exception as e:\n",
    "                            print(\"[pipeline memory update] append_incident error:\", e)\n",
    "                    print(\"[pipeline memory update] updated memory_agent for involved users.\")\n",
    "            except Exception as e:\n",
    "                print(\"[pipeline memory update] unexpected error:\", e)\n",
    "            return incident\n",
    "        pipeline.run_once = _run_and_update_memory\n",
    "        print(\"Pipeline.run_once monkeypatched: will now update memory_agent after creating incidents.\")\n",
    "    else:\n",
    "        print(\"No pipeline object found; cannot monkeypatch run_once. Create pipeline then re-run this cell.\")\n",
    "except Exception as e:\n",
    "    print(\"Error patching pipeline.run_once:\", e)\n",
    "\n",
    "print_header(\"COMBINED PATCH APPLIED - Test suggestion\")\n",
    "print(\"Suggested test: run one abusive stream multiple times (3+) to see recidivism bump in RiskScorerV2.\")\n",
    "print(\"To flip classifier to LLM-mode (demo), run: mcp.set('classifier', {'type':'llm','version':'v1'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b250acc",
   "metadata": {
    "papermill": {
     "duration": 0.010896,
     "end_time": "2025-11-30T07:31:48.830651",
     "exception": false,
     "start_time": "2025-11-30T07:31:48.819755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üß© Section 6 : Pipeline Setup and Initialization (#initialization)\n",
    " This section ensures pipeline components (planner, classifier, pattern detector, etc.)\n",
    "are created and attached in a safe order, provide repair hooks, and avoid NameError/TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81ae1754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:48.855845Z",
     "iopub.status.busy": "2025-11-30T07:31:48.854999Z",
     "iopub.status.idle": "2025-11-30T07:31:48.859249Z",
     "shell.execute_reply": "2025-11-30T07:31:48.858362Z"
    },
    "papermill": {
     "duration": 0.018826,
     "end_time": "2025-11-30T07:31:48.860591",
     "exception": false,
     "start_time": "2025-11-30T07:31:48.841765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- FIX: Ensure planner exists before pipeline creation ---\n",
    "# Purpose: guard against NameError when pipeline is instantiated before certain agents.\n",
    "# Behavior:\n",
    "#  - Check if 'planner', 'ethics', 'notifier', etc. are in globals()\n",
    "#  - If missing, create minimal safe stub objects (no-op or logging-only)\n",
    "#  - This lets pipeline be instantiated reliably while dev iterates on agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d0e1ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:48.884254Z",
     "iopub.status.busy": "2025-11-30T07:31:48.883969Z",
     "iopub.status.idle": "2025-11-30T07:31:48.890678Z",
     "shell.execute_reply": "2025-11-30T07:31:48.889771Z"
    },
    "papermill": {
     "duration": 0.020092,
     "end_time": "2025-11-30T07:31:48.891954",
     "exception": false,
     "start_time": "2025-11-30T07:31:48.871862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planner is ready: <__main__.InterventionPlannerAgent object at 0x7da494cb0910>\n"
     ]
    }
   ],
   "source": [
    "# --- FIX: Ensure planner exists before pipeline creation ---\n",
    "if 'planner' not in globals():\n",
    "    print(\"planner not found ‚Äî creating a default InterventionPlannerAgent()\")\n",
    "\n",
    "    class InterventionPlannerAgent:\n",
    "        def __init__(self):\n",
    "            print(\"[InterventionPlanner] init\")\n",
    "\n",
    "        def plan(self, conv, classified_msgs, risk, patterns):\n",
    "            severity = risk['severity']\n",
    "            actions = []\n",
    "            if severity == 'Low':\n",
    "                actions.append({\n",
    "                    'action_type':'suggest_support_message',\n",
    "                    'rationale':'Low severity; offer support to target'\n",
    "                })\n",
    "            elif severity == 'Medium':\n",
    "                actions.append({\n",
    "                    'action_type':'notify_moderator',\n",
    "                    'rationale':'Medium severity; moderator review recommended'\n",
    "                })\n",
    "            else:\n",
    "                actions.append({\n",
    "                    'action_type':'create_incident_and_notify_hr',\n",
    "                    'rationale':'High/Immediate severity; escalate to HR'\n",
    "                })\n",
    "            return actions\n",
    "\n",
    "    planner = InterventionPlannerAgent()\n",
    "\n",
    "print(\"planner is ready:\", planner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c31ff5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:48.915633Z",
     "iopub.status.busy": "2025-11-30T07:31:48.915320Z",
     "iopub.status.idle": "2025-11-30T07:31:48.919165Z",
     "shell.execute_reply": "2025-11-30T07:31:48.918372Z"
    },
    "papermill": {
     "duration": 0.017474,
     "end_time": "2025-11-30T07:31:48.920739",
     "exception": false,
     "start_time": "2025-11-30T07:31:48.903265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Safe Bootstrap Cell ---\n",
    "# Purpose: create deterministic minimal runtime baseline.\n",
    "# Behavior:\n",
    "#  - sets up ModelControlPlane (mcp) and tool_registry\n",
    "#  - creates or connects to memory DB/connection placeholder\n",
    "#  - defines lightweight MemoryAgent stub if not defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b85177c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:48.945936Z",
     "iopub.status.busy": "2025-11-30T07:31:48.945625Z",
     "iopub.status.idle": "2025-11-30T07:31:48.995253Z",
     "shell.execute_reply": "2025-11-30T07:31:48.994135Z"
    },
    "papermill": {
     "duration": 0.064164,
     "end_time": "2025-11-30T07:31:48.996552",
     "exception": false,
     "start_time": "2025-11-30T07:31:48.932388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== SAFE BOOTSTRAP: ensuring required agents & pipeline ====\n",
      "‚úî memory_agent present\n",
      "‚úî ethics already present\n",
      "‚úî notifier already present\n",
      "‚úî observability already present\n",
      "‚úî planner already present\n",
      "‚úî pattern_detector already present\n",
      "‚úî risk_scorer already present\n",
      "‚úî classifier already present\n",
      "‚úî ingestor already present\n",
      "‚úî extractor already present\n",
      "‚úî evidence_builder already present\n",
      "\n",
      "Constructing SilentGuardianPipeline (robust)...\n",
      "[PipelineRobust] created with components: ingestor True classifier True pattern_detector True\n",
      "\n",
      "‚úî pipeline (robust) is ready and assigned to variable 'pipeline'\n",
      "You can now call: incident, conv, classified, patterns, risk = pipeline.run_once(stream)\n",
      "==== SAFE BOOTSTRAP complete ====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# SAFE BOOTSTRAP CELL ‚Äî create missing agents & instantiate pipeline\n",
    "# -----------------------------\n",
    "import types, inspect\n",
    "\n",
    "print(\"\\n==== SAFE BOOTSTRAP: ensuring required agents & pipeline ====\")\n",
    "\n",
    "# Helper: create a minimal default implementation only if missing\n",
    "def ensure(name, creator_fn):\n",
    "    if name in globals() and globals()[name] is not None:\n",
    "        print(f\"‚úî {name} already present\")\n",
    "        return globals()[name]\n",
    "    else:\n",
    "        obj = creator_fn()\n",
    "        globals()[name] = obj\n",
    "        print(f\"‚úî Created default {name}\")\n",
    "        return obj\n",
    "\n",
    "# Default simple classes (only created if the user hasn't defined them)\n",
    "def make_ethics():\n",
    "    class EthicsAgent:\n",
    "        def __init__(self, policy=None):\n",
    "            self.policy = policy or {'allow_auto_messages': True}\n",
    "            print(\"[Ethics] default created\")\n",
    "        def check(self, action):\n",
    "            if action.get('action_type') in ['ban_user','fire_employee','legal_escalation']:\n",
    "                return {'allowed': False, 'reason': 'Human approval required'}\n",
    "            if action.get('action_type') == 'auto_message' and not self.policy.get('allow_auto_messages', False):\n",
    "                return {'allowed': False, 'reason': 'Auto messages disabled'}\n",
    "            return {'allowed': True}\n",
    "    return EthicsAgent({'allow_auto_messages': True})\n",
    "\n",
    "def make_notifier():\n",
    "    class NotifierAgent:\n",
    "        def notify_moderator(self, incident, actions):\n",
    "            try:\n",
    "                iid = incident.incident_id\n",
    "            except Exception:\n",
    "                # incident may be a tuple ‚Äî be resilient\n",
    "                try:\n",
    "                    iid = incident[0].incident_id\n",
    "                except Exception:\n",
    "                    iid = getattr(incident, 'incident_id', '<unknown>')\n",
    "            print(f\"[Notifier] Incident {iid} notify (simulated). Actions: {[a['action_type'] for a in actions]}\")\n",
    "        def send_supportive_message(self, user_id, msg):\n",
    "            print(f\"[Notifier] Supportive message to {user_id}: {msg}\")\n",
    "    return NotifierAgent()\n",
    "\n",
    "def make_observability():\n",
    "    class ObservabilityAgent:\n",
    "        def __init__(self):\n",
    "            self.logs = []\n",
    "            print(\"[Observability] default created\")\n",
    "        def log(self, entry):\n",
    "            entry = dict(entry)\n",
    "            entry['ts'] = datetime.utcnow().isoformat() + \"Z\"\n",
    "            self.logs.append(entry)\n",
    "            print(f\"[Observability] {entry.get('event','unknown')}\")\n",
    "        def dump(self):\n",
    "            return list(self.logs)\n",
    "    return ObservabilityAgent()\n",
    "\n",
    "def make_planner():\n",
    "    class InterventionPlannerAgent:\n",
    "        def __init__(self):\n",
    "            print(\"[InterventionPlanner] default created\")\n",
    "        def plan(self, conv, classified_msgs, risk, patterns):\n",
    "            severity = risk.get('severity') if isinstance(risk, dict) else 'Low'\n",
    "            actions = []\n",
    "            if severity == 'Low':\n",
    "                actions.append({'action_type':'suggest_support_message','rationale':'Offer support'})\n",
    "            elif severity == 'Medium':\n",
    "                actions.append({'action_type':'notify_moderator','rationale':'Moderator review recommended'})\n",
    "            else:\n",
    "                actions.append({'action_type':'create_incident_and_notify_hr','rationale':'Escalate to HR'})\n",
    "                actions.append({'action_type':'generate_evidence_text','rationale':'Create evidence text'})\n",
    "            return actions\n",
    "    return InterventionPlannerAgent()\n",
    "\n",
    "def make_pattern_detector():\n",
    "    class PatternDetectorAgent:\n",
    "        def __init__(self, memory_agent=None):\n",
    "            self.memory = memory_agent\n",
    "            print(\"[PatternDetector] default created\")\n",
    "        def detect_patterns(self, conv, classified_msgs):\n",
    "            patterns = {'repeat_targeting': [], 'recidivism': {}}\n",
    "            for cm in classified_msgs:\n",
    "                labels = [l['label'] for l in cm.get('labels',[]) if l.get('label')!='none']\n",
    "                if labels:\n",
    "                    sender = cm.get('sender_id')\n",
    "                    text = cm.get('text','') or ''\n",
    "                    for t in re.findall(r\"@\\w+\", text):\n",
    "                        patterns['repeat_targeting'].append({'sender': sender, 'target': t, 'msg_id': cm.get('msg_id')})\n",
    "                    if self.memory:\n",
    "                        try:\n",
    "                            prev = self.memory.get_incidents(sender)\n",
    "                            patterns['recidivism'][sender] = len(prev)\n",
    "                        except Exception:\n",
    "                            patterns['recidivism'][sender] = 0\n",
    "            return patterns\n",
    "    return PatternDetectorAgent(memory_agent if 'memory_agent' in globals() else None)\n",
    "\n",
    "def make_risk_scorer():\n",
    "    class RiskScorerAgent:\n",
    "        def __init__(self):\n",
    "            print(\"[RiskScorer] default created\")\n",
    "        def compute_risk(self, classified_msgs, patterns):\n",
    "            base_scores = []\n",
    "            for cm in classified_msgs:\n",
    "                s = max((l.get('score',0.0) for l in cm.get('labels',[])), default=0.0)\n",
    "                base_scores.append(s)\n",
    "            avg = sum(base_scores)/len(base_scores) if base_scores else 0.0\n",
    "            repeat_count = len(patterns.get('repeat_targeting',[])) if isinstance(patterns, dict) else 0\n",
    "            if repeat_count >= 3:\n",
    "                avg = min(1.0, avg + 0.2)\n",
    "            # recidivism bump (safe)\n",
    "            bump = 0.0\n",
    "            for cnt in (patterns.get('recidivism',{}).values() if isinstance(patterns, dict) else []):\n",
    "                if cnt>0:\n",
    "                    bump = max(bump, min(0.3, 0.05*cnt))\n",
    "            avg = min(1.0, avg + bump)\n",
    "            severity = 'Low'\n",
    "            if avg >= 0.8: severity='Immediate'\n",
    "            elif avg >= 0.5: severity='High'\n",
    "            elif avg >= 0.2: severity='Medium'\n",
    "            return {'score': avg, 'severity': severity}\n",
    "    return RiskScorerAgent()\n",
    "\n",
    "def make_classifier():\n",
    "    class HarassmentClassifierAgent:\n",
    "        def __init__(self):\n",
    "            self.insult_keywords = set([\"stupid\",\"idiot\",\"worthless\",\"loser\",\"dumb\",\"hate you\",\"shut up\"])\n",
    "            self.threat_keywords = set([\"kill you\",\"hurt you\",\"i'll kill\",\"i will kill\",\"die\",\"end you\"])\n",
    "            self.doxxing_keywords = set([\"address\",\"phone\",\"where do you live\",\"i know where you live\",\"share her number\"])\n",
    "            print(\"[Classifier] default created\")\n",
    "        def _find_span(self, text, lex):\n",
    "            for k in lex:\n",
    "                if k in text: return k\n",
    "            return ''\n",
    "        def classify_messages(self, messages):\n",
    "            outputs=[]\n",
    "            mode = (mcp.get('classifier') or {}).get('type','rule') if 'mcp' in globals() else 'rule'\n",
    "            for m in messages:\n",
    "                t = (m.get('text') if isinstance(m, dict) else getattr(m,'text', '')) if isinstance(m, dict) or hasattr(m,'text') else ''\n",
    "                text_lower = (t or '').lower()\n",
    "                labels=[]\n",
    "                if any(k in text_lower for k in self.threat_keywords):\n",
    "                    labels.append({'label':'threat','score':0.98,'span':self._find_span(text_lower,self.threat_keywords)})\n",
    "                if any(k in text_lower for k in self.doxxing_keywords):\n",
    "                    labels.append({'label':'doxxing','score':0.8,'span':self._find_span(text_lower,self.doxxing_keywords)})\n",
    "                if any(k in text_lower for k in self.insult_keywords) or re.search(r\"\\bidiot\\b|\\bdumb\\b|\\bworthless\\b\", text_lower):\n",
    "                    labels.append({'label':'insult','score':0.9,'span':self._find_span(text_lower,self.insult_keywords)})\n",
    "                if not labels:\n",
    "                    labels=[{'label':'none','score':0.0,'span':''}]\n",
    "                # support both Message objects and dict-like items\n",
    "                msg_id = (m.get('msg_id') if isinstance(m, dict) else getattr(m, 'msg_id', gen_id('msg')))\n",
    "                sender_id = (m.get('sender_id') if isinstance(m, dict) else getattr(m, 'sender_id', 'unknown'))\n",
    "                outputs.append({'msg_id': msg_id, 'sender_id': sender_id, 'labels': labels, 'text': t})\n",
    "            return outputs\n",
    "    return HarassmentClassifierAgent()\n",
    "\n",
    "def make_ingestor():\n",
    "    class IngestorAgent:\n",
    "        def ingest_stream(self, raw_stream, platform='slack'):\n",
    "            convo_id = gen_id('convo')\n",
    "            messages=[]\n",
    "            for m in raw_stream:\n",
    "                mid = m.get('msg_id') if isinstance(m, dict) else getattr(m,'msg_id', gen_id('msg'))\n",
    "                sender = m.get('sender_id') if isinstance(m, dict) else getattr(m,'sender_id','unknown')\n",
    "                txt = anonymize_text(m.get('text','') if isinstance(m, dict) else getattr(m,'text',''))\n",
    "                ts = m.get('ts') if isinstance(m, dict) else getattr(m,'ts', now_ts())\n",
    "                messages.append({'msg_id': mid, 'sender_id': sender, 'text': txt, 'ts': ts})\n",
    "            # Return a minimal convo-like object with attributes used downstream\n",
    "            return types.SimpleNamespace(convo_id=convo_id, platform=platform, messages=[types.SimpleNamespace(**mm) for mm in messages])\n",
    "    return IngestorAgent()\n",
    "\n",
    "def make_extractor():\n",
    "    class ExtractorAgent:\n",
    "        def extract_window(self, conv, center_msg_idx=0, window_seconds=300):\n",
    "            if not getattr(conv,'messages',[]): return []\n",
    "            center_ts = datetime.fromisoformat(conv.messages[center_msg_idx].ts.replace('Z',''))\n",
    "            lower=(center_ts - timedelta(seconds=window_seconds)).isoformat()+'Z'\n",
    "            upper=(center_ts + timedelta(seconds=window_seconds)).isoformat()+'Z'\n",
    "            window_msgs = [m for m in conv.messages if lower <= getattr(m,'ts',now_ts()) <= upper]\n",
    "            return window_msgs\n",
    "    return ExtractorAgent()\n",
    "\n",
    "def make_evidence_builder():\n",
    "    class EvidenceBuilderAgent:\n",
    "        def build_evidence_text(self, conv, classified_msgs, risk):\n",
    "            lines=[f\"Evidence for convo {getattr(conv,'convo_id','<conv>')}\",\"Generated: \"+now_ts(), f\"Risk: {risk}\", \"Messages:\"]\n",
    "            for cm in classified_msgs:\n",
    "                lines.append(f\"- {cm.get('msg_id')} | {cm.get('sender_id')} | {cm.get('text')} | labels={cm.get('labels')}\")\n",
    "            txt = \"\\n\".join(lines)\n",
    "            print(txt)\n",
    "            return txt\n",
    "    return EvidenceBuilderAgent()\n",
    "\n",
    "# Ensure memory_agent exists (in-memory SQLite expected by user's notebook)\n",
    "if 'memory_agent' not in globals():\n",
    "    # create a tiny MemoryAgent that stores in a dict (non-persistent)\n",
    "    class MemoryAgentSimple:\n",
    "        def __init__(self):\n",
    "            self.mem = {}\n",
    "            print(\"[MemoryAgentSimple] created (in-memory dict)\")\n",
    "        def append_incident(self,user_id, incident_id):\n",
    "            self.mem.setdefault(user_id, []).append(incident_id)\n",
    "        def get_incidents(self, user_id):\n",
    "            return list(self.mem.get(user_id, []))\n",
    "    memory_agent = MemoryAgentSimple()\n",
    "    globals()['memory_agent'] = memory_agent\n",
    "else:\n",
    "    print(\"‚úî memory_agent present\")\n",
    "\n",
    "# Create/ensure other agents (will not overwrite user-defined ones)\n",
    "ensure('ethics', lambda: make_ethics())\n",
    "ensure('notifier', lambda: make_notifier())\n",
    "ensure('observability', lambda: make_observability())\n",
    "ensure('planner', lambda: make_planner())\n",
    "ensure('pattern_detector', lambda: make_pattern_detector())\n",
    "ensure('risk_scorer', lambda: make_risk_scorer())\n",
    "ensure('classifier', lambda: make_classifier())\n",
    "ensure('ingestor', lambda: make_ingestor())\n",
    "ensure('extractor', lambda: make_extractor())\n",
    "ensure('evidence_builder', lambda: make_evidence_builder())\n",
    "\n",
    "# Now define a robust pipeline that tolerates missing/tuple returns\n",
    "print(\"\\nConstructing SilentGuardianPipeline (robust)...\")\n",
    "class SilentGuardianPipelineRobust:\n",
    "    def __init__(self):\n",
    "        self.ingestor = globals().get('ingestor')\n",
    "        self.extractor = globals().get('extractor')\n",
    "        self.classifier = globals().get('classifier')\n",
    "        self.pattern_detector = globals().get('pattern_detector')\n",
    "        self.risk_scorer = globals().get('risk_scorer')\n",
    "        self.planner = globals().get('planner')\n",
    "        self.evidence_builder = globals().get('evidence_builder')\n",
    "        self.ethics = globals().get('ethics')\n",
    "        self.notifier = globals().get('notifier')\n",
    "        self.observability = globals().get('observability')\n",
    "        self.memory = globals().get('memory_agent')\n",
    "        print(\"[PipelineRobust] created with components:\",\n",
    "              \"ingestor\", bool(self.ingestor),\n",
    "              \"classifier\", bool(self.classifier),\n",
    "              \"pattern_detector\", bool(self.pattern_detector))\n",
    "\n",
    "    def run_once(self, raw_stream):\n",
    "        print(\"[PipelineRobust] run_once called\")\n",
    "        conv = self.ingestor.ingest_stream(raw_stream)\n",
    "        # Logging safe\n",
    "        try:\n",
    "            self.observability.log({'event':'ingested_conversation','convo_id': conv.convo_id, 'n_messages': len(conv.messages)})\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Extract window (safe)\n",
    "        try:\n",
    "            window_msgs = self.extractor.extract_window(conv, center_msg_idx=max(0, len(conv.messages)-1))\n",
    "        except Exception:\n",
    "            window_msgs = getattr(conv, 'messages', [])\n",
    "        # Classify (supports both objects and dicts)\n",
    "        classified = self.classifier.classify_messages(window_msgs)\n",
    "        # Detect patterns\n",
    "        patterns = {}\n",
    "        try:\n",
    "            patterns = self.pattern_detector.detect_patterns(conv, classified)\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineRobust] pattern_detector error:\", e); patterns = {}\n",
    "        # Score risk\n",
    "        risk = self.risk_scorer.compute_risk(classified, patterns)\n",
    "        # Plan actions\n",
    "        actions = self.planner.plan(conv, classified, risk, patterns)\n",
    "        # Ethics filter\n",
    "        filtered_actions = []\n",
    "        for a in actions:\n",
    "            try:\n",
    "                check = self.ethics.check(a)\n",
    "            except Exception:\n",
    "                check = {'allowed': True}\n",
    "            try:\n",
    "                self.observability.log({'event':'ethics_check','action': a.get('action_type'), 'result': check})\n",
    "            except Exception:\n",
    "                pass\n",
    "            if check.get('allowed'):\n",
    "                filtered_actions.append(a)\n",
    "        # Evidence text if requested\n",
    "        evidence_text = None\n",
    "        if any(a.get('action_type')=='generate_evidence_text' for a in filtered_actions):\n",
    "            try:\n",
    "                evidence_text = self.evidence_builder.build_evidence_text(conv, classified, risk)\n",
    "            except Exception as e:\n",
    "                print(\"[PipelineRobust] evidence builder error:\", e)\n",
    "                evidence_text = None\n",
    "        # Build incident object (SimpleNamespace) to keep consistent shape\n",
    "        incident = types.SimpleNamespace(\n",
    "            incident_id = gen_id('incident'),\n",
    "            convo_id = getattr(conv,'convo_id', gen_id('convo')),\n",
    "            involved_user_ids = list({getattr(m,'sender_id', None) for m in getattr(conv,'messages',[]) if getattr(m,'sender_id',None)}),\n",
    "            start_ts = getattr(conv.messages[0],'ts', now_ts()) if getattr(conv,'messages',None) else now_ts(),\n",
    "            end_ts = getattr(conv.messages[-1],'ts', now_ts()) if getattr(conv,'messages',None) else now_ts(),\n",
    "            labels = [l for cm in classified for l in cm.get('labels',[])],\n",
    "            severity = risk.get('severity') if isinstance(risk, dict) else 'Low',\n",
    "            evidence = evidence_text,\n",
    "            status = 'new'\n",
    "        )\n",
    "        # store minimal incident in memory_agent if possible\n",
    "        try:\n",
    "            for u in incident.involved_user_ids:\n",
    "                if self.memory:\n",
    "                    self.memory.append_incident(u, incident.incident_id)\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineRobust] memory append error:\", e)\n",
    "        # Notify moderator (resilient)\n",
    "        try:\n",
    "            self.notifier.notify_moderator(incident, filtered_actions)\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineRobust] notifier error:\", e)\n",
    "        try:\n",
    "            self.observability.log({'event':'pipeline_complete', 'incident_id': incident.incident_id, 'severity': incident.severity})\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Return standardized tuple: (incident, conv, classified, patterns, risk)\n",
    "        return incident, conv, classified, patterns, risk\n",
    "\n",
    "# Instantiate robust pipeline and place into globals under the expected name\n",
    "pipeline = SilentGuardianPipelineRobust()\n",
    "globals()['pipeline'] = pipeline\n",
    "print(\"\\n‚úî pipeline (robust) is ready and assigned to variable 'pipeline'\")\n",
    "print(\"You can now call: incident, conv, classified, patterns, risk = pipeline.run_once(stream)\")\n",
    "print(\"==== SAFE BOOTSTRAP complete ====\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf21e0f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.021030Z",
     "iopub.status.busy": "2025-11-30T07:31:49.020726Z",
     "iopub.status.idle": "2025-11-30T07:31:49.025877Z",
     "shell.execute_reply": "2025-11-30T07:31:49.025023Z"
    },
    "papermill": {
     "duration": 0.01914,
     "end_time": "2025-11-30T07:31:49.027199",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.008059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî print_header restored.\n"
     ]
    }
   ],
   "source": [
    "# Restore print_header safely\n",
    "def print_header(title: str):\n",
    "    print(\"\\n\" + \"=\"*8 + f\" {title} \" + \"=\"*8 + \"\\n\")\n",
    "\n",
    "print(\"‚úî print_header restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da7fd319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.051486Z",
     "iopub.status.busy": "2025-11-30T07:31:49.050609Z",
     "iopub.status.idle": "2025-11-30T07:31:49.054633Z",
     "shell.execute_reply": "2025-11-30T07:31:49.053957Z"
    },
    "papermill": {
     "duration": 0.01743,
     "end_time": "2025-11-30T07:31:49.055959",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.038529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Repair Cell (hotfixes / monkeypatches) ---\n",
    "# Purpose: patch broken or partially-applied state after manual edits.\n",
    "# Examples:\n",
    "#  - ensure observability.logs exists (fix AttributeError)\n",
    "#  - replace pipeline.classifier/pipeline.pattern_detector when updated classes are defined\n",
    "#  - make pipeline.run_once wrapper tuple-safe (handles both dataclass and tuple returns)\n",
    "# Use: run when you see NameError/AttributeError after re-editing components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "863a9831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.080591Z",
     "iopub.status.busy": "2025-11-30T07:31:49.079800Z",
     "iopub.status.idle": "2025-11-30T07:31:49.089319Z",
     "shell.execute_reply": "2025-11-30T07:31:49.088241Z"
    },
    "papermill": {
     "duration": 0.023342,
     "end_time": "2025-11-30T07:31:49.090654",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.067312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Repair] pattern_detector already exists.\n",
      "‚úî All required components exist now.\n"
     ]
    }
   ],
   "source": [
    "# --- REPAIR CELL: Ensure all agents exist before Pipeline ---\n",
    "\n",
    "# 1. Pattern Detector\n",
    "try:\n",
    "    pattern_detector\n",
    "    print(\"[Repair] pattern_detector already exists.\")\n",
    "except NameError:\n",
    "    print(\"[Repair] Creating pattern_detector...\")\n",
    "    class PatternDetector_Fix:\n",
    "        def detect_patterns(self, conv, classified):\n",
    "            return {'repeat_targeting': [], 'recidivism': {}}\n",
    "    pattern_detector = PatternDetector_Fix()\n",
    "\n",
    "# 2. Risk Scorer\n",
    "try:\n",
    "    risk_scorer\n",
    "except NameError:\n",
    "    class RiskScorer_Fix:\n",
    "        def compute_risk(self, classified, patterns):\n",
    "            return {'score':0.0, 'severity':'Low'}\n",
    "    risk_scorer = RiskScorer_Fix()\n",
    "\n",
    "# 3. Planner\n",
    "try:\n",
    "    planner\n",
    "except NameError:\n",
    "    class Planner_Fix:\n",
    "        def plan(self, conv, classified, risk, patterns):\n",
    "            return [{'action_type':'suggest_support_message'}]\n",
    "    planner = Planner_Fix()\n",
    "\n",
    "# 4. Ethics Agent\n",
    "try:\n",
    "    ethics\n",
    "except NameError:\n",
    "    class Ethics_Fix:\n",
    "        def check(self, action):\n",
    "            return {'allowed': True}\n",
    "    ethics = Ethics_Fix()\n",
    "\n",
    "# 5. Notifier\n",
    "try:\n",
    "    notifier\n",
    "except NameError:\n",
    "    class Notifier_Fix:\n",
    "        def notify_moderator(self, incident, actions):\n",
    "            print(\"[Notifier_Fix] moderator notified\")\n",
    "    notifier = Notifier_Fix()\n",
    "\n",
    "# 6. Observability\n",
    "try:\n",
    "    observability\n",
    "except NameError:\n",
    "    class Obs_Fix:\n",
    "        def __init__(self): self.logs=[]\n",
    "        def log(self, entry): self.logs.append(entry)\n",
    "    observability = Obs_Fix()\n",
    "\n",
    "# 7. Memory Agent\n",
    "try:\n",
    "    memory_agent\n",
    "except NameError:\n",
    "    class Memory_Fix:\n",
    "        def append_incident(self,u,i): pass\n",
    "    memory_agent = Memory_Fix()\n",
    "\n",
    "print(\"‚úî All required components exist now.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb8f3672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.114540Z",
     "iopub.status.busy": "2025-11-30T07:31:49.114243Z",
     "iopub.status.idle": "2025-11-30T07:31:49.118310Z",
     "shell.execute_reply": "2025-11-30T07:31:49.117413Z"
    },
    "papermill": {
     "duration": 0.017621,
     "end_time": "2025-11-30T07:31:49.119749",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.102128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Safe Pipeline Builder Cell ---\n",
    "# Purpose: instantiate the pipeline in a defensive manner.\n",
    "# Behavior:\n",
    "#  - verify required agent globals exist (ingestor, extractor, classifier, pattern_detector, risk_scorer, planner, ethics, notifier, evidence_builder, observability, memory_agent)\n",
    "#  - if any missing, attach a small safe stub that logs calls (no destructive behavior)\n",
    "#  - print a short summary of attached components (so you can confirm)\n",
    "# Use: run this cell to (re)create a stable pipeline object after edits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb965159",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.147103Z",
     "iopub.status.busy": "2025-11-30T07:31:49.146788Z",
     "iopub.status.idle": "2025-11-30T07:31:49.177592Z",
     "shell.execute_reply": "2025-11-30T07:31:49.176575Z"
    },
    "papermill": {
     "duration": 0.045614,
     "end_time": "2025-11-30T07:31:49.178907",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.133293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Safe Pipeline Builder (auto-fallbacks) ========\n",
      "\n",
      "Using existing ingestor -> IngestorAgent\n",
      "Using existing extractor -> ExtractorAgent\n",
      "Using existing classifier -> HarassmentClassifierAgent_MCP\n",
      "Using existing pattern_detector -> PatternDetectorAgentV2\n",
      "Using existing risk_scorer -> RiskScorerAgentV2\n",
      "Using existing planner -> InterventionPlannerAgent\n",
      "Using existing evidence_builder -> EvidenceBuilderAgent\n",
      "Using existing ethics -> EthicsAgent\n",
      "Using existing notifier -> NotifierAgent\n",
      "Using existing observability -> ObservabilityAgent\n",
      "Using existing memory_agent -> MemoryAgent\n",
      "[PipelineSafe] init\n",
      "\n",
      "Pipeline created. Attached components summary:\n",
      " - ingestor: IngestorAgent\n",
      " - extractor: ExtractorAgent\n",
      " - classifier: HarassmentClassifierAgent_MCP\n",
      " - pattern_detector: PatternDetectorAgentV2\n",
      " - risk_scorer: RiskScorerAgentV2\n",
      " - planner: InterventionPlannerAgent\n",
      " - evidence_builder: EvidenceBuilderAgent\n",
      " - ethics: EthicsAgent\n",
      " - notifier: NotifierAgent\n",
      " - observability: ObservabilityAgent\n",
      " - memory: MemoryAgent\n",
      "\n",
      "‚úÖ Safe pipeline ready. Run pipeline.run_once(stream) to test.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Safe pipeline builder cell (paste this into your notebook)\n",
    "# -----------------------------\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "print_header(\"Safe Pipeline Builder (auto-fallbacks)\")\n",
    "\n",
    "# Helper: create a minimal stub implementation for an agent type if it's missing\n",
    "def make_stub(name):\n",
    "    class Stub:\n",
    "        def __init__(self):\n",
    "            print(f\"[Stub:{name}] created\")\n",
    "        # common minimal methods used by pipeline\n",
    "        def ingest_stream(self, raw_stream, platform='slack'):\n",
    "            return None\n",
    "        def extract_window(self, conv, center_msg_idx=0, window_seconds=300):\n",
    "            return []\n",
    "        def classify_messages(self, messages):\n",
    "            return []\n",
    "        def detect_patterns(self, conv, classified_msgs):\n",
    "            return {'repeat_targeting': [], 'recidivism': {}}\n",
    "        def compute_risk(self, classified_msgs, patterns):\n",
    "            return {'score': 0.0, 'severity': 'Low'}\n",
    "        def plan(self, conv, classified_msgs, risk, patterns):\n",
    "            return []\n",
    "        def build_evidence_text(self, conv, classified_msgs, risk):\n",
    "            return \"NO EVIDENCE (stub)\"\n",
    "        def check(self, action):\n",
    "            return {'allowed': True}\n",
    "        def notify_moderator(self, incident, actions):\n",
    "            print(f\"[Stub-notifier] Incident {getattr(incident,'incident_id', '<no-id>')} actions: {actions}\")\n",
    "        def log(self, entry):\n",
    "            print(f\"[Stub-observability] {entry}\")\n",
    "        def append_incident(self, user_id, incident_id):\n",
    "            pass\n",
    "        def get_incidents(self, user_id):\n",
    "            return []\n",
    "    Stub.__name__ = f\"Stub_{name}\"\n",
    "    return Stub()\n",
    "\n",
    "# List of expected component names and the attribute to attach in pipeline\n",
    "expected_components = {\n",
    "    'ingestor': ('ingestor', 'IngestorAgent'),\n",
    "    'extractor': ('extractor', 'ExtractorAgent'),\n",
    "    'classifier': ('classifier', 'HarassmentClassifierAgent'),\n",
    "    'pattern_detector': ('pattern_detector', 'PatternDetectorAgent'),\n",
    "    'risk_scorer': ('risk_scorer', 'RiskScorerAgent'),\n",
    "    'planner': ('planner', 'InterventionPlannerAgent'),\n",
    "    'evidence_builder': ('evidence_builder', 'EvidenceBuilderAgent'),\n",
    "    'ethics': ('ethics', 'EthicsAgent'),\n",
    "    'notifier': ('notifier', 'NotifierAgent'),\n",
    "    'observability': ('observability', 'ObservabilityAgent'),\n",
    "    'memory': ('memory_agent', 'MemoryAgent'),\n",
    "}\n",
    "\n",
    "# Prepare attachments: use existing globals() objects if present; otherwise create stubs\n",
    "attached = {}\n",
    "for attr, (global_name, cls_name) in expected_components.items():\n",
    "    if global_name in globals() and globals()[global_name] is not None:\n",
    "        attached[attr] = globals()[global_name]\n",
    "        print(f\"Using existing {global_name} -> {type(attached[attr]).__name__}\")\n",
    "    else:\n",
    "        # create a stub and attach\n",
    "        stub = make_stub(attr)\n",
    "        attached[attr] = stub\n",
    "        globals()[global_name] = stub  # create a global reference so later cells find it\n",
    "        print(f\"Created stub for missing {global_name} -> {type(stub).__name__}\")\n",
    "\n",
    "# Minimal Incident dataclass fallback (if missing)\n",
    "try:\n",
    "    Incident  # noqa: F821\n",
    "except NameError:\n",
    "    from dataclasses import dataclass, field\n",
    "    @dataclass\n",
    "    class Incident:\n",
    "        incident_id: str\n",
    "        convo_id: str\n",
    "        involved_user_ids: List[str]\n",
    "        start_ts: str\n",
    "        end_ts: str\n",
    "        labels: List[Dict[str,Any]]\n",
    "        severity: str\n",
    "        evidence: Any = None\n",
    "        status: str = 'new'\n",
    "    globals()['Incident'] = Incident\n",
    "    print(\"Defined fallback Incident dataclass\")\n",
    "\n",
    "# Now define a safe pipeline class that uses the attached components\n",
    "class SilentGuardianPipelineSafe:\n",
    "    def __init__(self, components: Dict[str, Any]):\n",
    "        print(\"[PipelineSafe] init\")\n",
    "        # attach everything (either real or stub)\n",
    "        self.ingestor = components['ingestor']\n",
    "        self.extractor = components['extractor']\n",
    "        self.classifier = components['classifier']\n",
    "        self.pattern_detector = components['pattern_detector']\n",
    "        self.risk_scorer = components['risk_scorer']\n",
    "        self.planner = components['planner']\n",
    "        self.evidence_builder = components['evidence_builder']\n",
    "        self.ethics = components['ethics']\n",
    "        self.notifier = components['notifier']\n",
    "        self.observability = components['observability']\n",
    "        self.memory = components['memory']\n",
    "\n",
    "    def run_once(self, raw_stream: List[Dict[str,Any]]):\n",
    "        print(\"[PipelineSafe] run_once called\")\n",
    "        # Ingest\n",
    "        conv = None\n",
    "        try:\n",
    "            conv = self.ingestor.ingest_stream(raw_stream)\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineSafe] ingest_stream error:\", e)\n",
    "            # create a minimal conversation object if necessary\n",
    "            conv = type(\"Conv\", (), {\"convo_id\": gen_id(\"convo\"), \"platform\": \"unknown\", \"messages\": []})()\n",
    "\n",
    "        # observability\n",
    "        try:\n",
    "            self.observability.log({'event':'ingested_conversation','convo_id': getattr(conv,'convo_id', None), 'n_messages': len(getattr(conv,'messages',[]))})\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineSafe] observability.log error:\", e)\n",
    "\n",
    "        # Extract window\n",
    "        try:\n",
    "            window_msgs = self.extractor.extract_window(conv, center_msg_idx=max(0, len(getattr(conv,'messages',[]))-1))\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineSafe] extract_window error:\", e)\n",
    "            window_msgs = getattr(conv,'messages',[])\n",
    "\n",
    "        # Classify\n",
    "        try:\n",
    "            classified = self.classifier.classify_messages(window_msgs)\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineSafe] classify_messages error:\", e)\n",
    "            classified = []\n",
    "\n",
    "        # Pattern detection\n",
    "        try:\n",
    "            patterns = self.pattern_detector.detect_patterns(conv, classified)\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineSafe] detect_patterns error:\", e)\n",
    "            patterns = {'repeat_targeting': [], 'recidivism': {}}\n",
    "\n",
    "        # Risk scoring\n",
    "        try:\n",
    "            risk = self.risk_scorer.compute_risk(classified, patterns)\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineSafe] compute_risk error:\", e)\n",
    "            risk = {'score':0.0, 'severity':'Low'}\n",
    "\n",
    "        # Plan interventions\n",
    "        try:\n",
    "            actions = self.planner.plan(conv, classified, risk, patterns)\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineSafe] planner.plan error:\", e)\n",
    "            actions = []\n",
    "\n",
    "        # Ethics vetting\n",
    "        filtered_actions = []\n",
    "        for a in actions:\n",
    "            try:\n",
    "                check = self.ethics.check(a)\n",
    "            except Exception as e:\n",
    "                print(\"[PipelineSafe] ethics.check error:\", e)\n",
    "                check = {'allowed': True}\n",
    "            try:\n",
    "                self.observability.log({'event':'ethics_check','action': a.get('action_type','unknown'), 'result': check})\n",
    "            except Exception:\n",
    "                pass\n",
    "            if check.get('allowed'):\n",
    "                filtered_actions.append(a)\n",
    "\n",
    "        # Evidence (text) generation if requested\n",
    "        evidence_text = None\n",
    "        if any(a.get('action_type') in ('generate_evidence_text','generate_evidence_packet') for a in filtered_actions):\n",
    "            try:\n",
    "                evidence_text = self.evidence_builder.build_evidence_text(conv, classified, risk)\n",
    "            except Exception as e:\n",
    "                print(\"[PipelineSafe] evidence_builder error:\", e)\n",
    "                evidence_text = \"EVIDENCE ERROR\"\n",
    "\n",
    "        # Build Incident (robust)\n",
    "        incident_id = gen_id('incident')\n",
    "        involved = list({m.sender_id for m in getattr(conv,'messages',[])}) if getattr(conv,'messages',None) else []\n",
    "        incident = Incident(\n",
    "            incident_id=incident_id,\n",
    "            convo_id=getattr(conv,'convo_id', gen_id('convo')),\n",
    "            involved_user_ids=involved,\n",
    "            start_ts=getattr(conv,'messages',[{'ts': now_ts()}])[0]['ts'] if getattr(conv,'messages',None) else now_ts(),\n",
    "            end_ts=getattr(conv,'messages',[-1])['ts'] if getattr(conv,'messages',None) else now_ts(),\n",
    "            labels=[l for cm in classified for l in cm.get('labels',[])],\n",
    "            severity=risk.get('severity','Low'),\n",
    "            evidence=evidence_text,\n",
    "            status='new'\n",
    "        )\n",
    "\n",
    "        # store incident if DB cursor exists (safe)\n",
    "        try:\n",
    "            if 'cur' in globals() and 'conn' in globals():\n",
    "                cur.execute('INSERT INTO incidents (incident_id, convo_id, involved_users, start_ts, end_ts, labels, severity, evidence, status) VALUES (?,?,?,?,?,?,?,?,?)',\n",
    "                            (incident.incident_id, incident.convo_id, json.dumps(incident.involved_user_ids), incident.start_ts, incident.end_ts, json.dumps(incident.labels), incident.severity, json.dumps(incident.evidence) if incident.evidence else None, incident.status))\n",
    "                conn.commit()\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineSafe] DB insert error:\", e)\n",
    "\n",
    "        # Update memory for involved users\n",
    "        try:\n",
    "            for u in incident.involved_user_ids:\n",
    "                try:\n",
    "                    self.memory.append_incident(u, incident.incident_id)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Notify moderator (prints with fallback)\n",
    "        try:\n",
    "            self.notifier.notify_moderator(incident, filtered_actions)\n",
    "        except Exception as e:\n",
    "            print(\"[PipelineSafe] notifier.notify_moderator error:\", e)\n",
    "\n",
    "        try:\n",
    "            self.observability.log({'event':'pipeline_complete','incident_id': incident.incident_id, 'severity': incident.severity})\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Return the robust tuple\n",
    "        return incident, conv, classified, patterns, risk\n",
    "\n",
    "# instantiate pipeline with attached components\n",
    "pipeline = SilentGuardianPipelineSafe(attached)\n",
    "print(\"\\nPipeline created. Attached components summary:\")\n",
    "for k, v in attached.items():\n",
    "    print(f\" - {k}: {type(v).__name__}\")\n",
    "\n",
    "print(\"\\n‚úÖ Safe pipeline ready. Run pipeline.run_once(stream) to test.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "859d5439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.203759Z",
     "iopub.status.busy": "2025-11-30T07:31:49.203451Z",
     "iopub.status.idle": "2025-11-30T07:31:49.207280Z",
     "shell.execute_reply": "2025-11-30T07:31:49.206567Z"
    },
    "papermill": {
     "duration": 0.017909,
     "end_time": "2025-11-30T07:31:49.208644",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.190735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Pipeline Cell ---\n",
    "# Purpose: define SilentGuardianPipeline and its run_once() method (main processing flow).\n",
    "# Behavior:\n",
    "#  - ingest -> extract -> classify -> pattern detect -> score -> plan -> ethics -> evidence -> incident save -> notify\n",
    "#  - uses the objects attached in the Safe Pipeline Builder cell\n",
    "# Safety:\n",
    "#  - should not directly perform destructive actions (ban/fire); those are flagged for human approval by EthicsAgent\n",
    "#  - returns a consistent Incident dataclass (or guarded tuple) so downstream code can handle both shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6d6237b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.233439Z",
     "iopub.status.busy": "2025-11-30T07:31:49.233167Z",
     "iopub.status.idle": "2025-11-30T07:31:49.246997Z",
     "shell.execute_reply": "2025-11-30T07:31:49.246077Z"
    },
    "papermill": {
     "duration": 0.027954,
     "end_time": "2025-11-30T07:31:49.248485",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.220531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Pipeline ========\n",
      "\n",
      "[Pipeline] init\n",
      "Pipeline ready.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Pipeline\n",
    "# -----------------------------\n",
    "from typing import List, Dict, Any  \n",
    "print_header(\"Pipeline\")\n",
    "class SilentGuardianPipeline:\n",
    "    def __init__(self):\n",
    "        print(\"[Pipeline] init\")\n",
    "        self.ingestor = ingestor\n",
    "        self.extractor = extractor\n",
    "        self.classifier = classifier\n",
    "        self.pattern_detector = pattern_detector\n",
    "        self.risk_scorer = risk_scorer\n",
    "        self.planner = planner\n",
    "        self.evidence_builder = evidence_builder\n",
    "        self.ethics = ethics\n",
    "        self.notifier = notifier\n",
    "        self.observability = observability\n",
    "        self.memory = memory_agent\n",
    "\n",
    "    def run_once(self, raw_stream: List[Dict[str,Any]]):\n",
    "        print(\"[Pipeline] run_once called\")\n",
    "        conv = self.ingestor.ingest_stream(raw_stream)\n",
    "        self.observability.log({'event':'ingested_conversation','convo_id': conv.convo_id, 'n_messages': len(conv.messages)})\n",
    "        window_msgs = self.extractor.extract_window(conv, center_msg_idx=max(0, len(conv.messages)-1))\n",
    "        classified = self.classifier.classify_messages(window_msgs)\n",
    "        # publish: here we just call pattern detector\n",
    "        patterns = self.pattern_detector.detect_patterns(conv, classified)\n",
    "        risk = self.risk_scorer.compute_risk(classified, patterns)\n",
    "        actions = self.planner.plan(conv, classified, risk, patterns)\n",
    "        filtered_actions = []\n",
    "        for a in actions:\n",
    "            check = self.ethics.check(a)\n",
    "            self.observability.log({'event':'ethics_check','action': a['action_type'], 'result': check})\n",
    "            if check.get('allowed'):\n",
    "                filtered_actions.append(a)\n",
    "            else:\n",
    "                print(f\"[Pipeline] Action {a['action_type']} blocked by ethics: {check.get('reason')}\")\n",
    "        evidence_text = None\n",
    "        if any(a['action_type']=='generate_evidence_text' for a in filtered_actions):\n",
    "            evidence_text = self.evidence_builder.build_evidence_text(conv, classified, risk)\n",
    "        # Create incident object and store in-memory DB\n",
    "        incident_id = gen_id('incident')\n",
    "        incident = Incident(incident_id=incident_id, convo_id=conv.convo_id,\n",
    "                            involved_user_ids=list({m.sender_id for m in conv.messages}),\n",
    "                            start_ts=conv.messages[0].ts if conv.messages else now_ts(),\n",
    "                            end_ts=conv.messages[-1].ts if conv.messages else now_ts(),\n",
    "                            labels=[l for cm in classified for l in cm['labels']],\n",
    "                            severity=risk['severity'], evidence=evidence_text, status='new')\n",
    "        cur.execute('INSERT INTO incidents (incident_id, convo_id, involved_users, start_ts, end_ts, labels, severity, evidence, status) VALUES (?,?,?,?,?,?,?,?,?)',\n",
    "                    (incident.incident_id, incident.convo_id, json.dumps(incident.involved_user_ids), incident.start_ts, incident.end_ts, json.dumps(incident.labels), incident.severity, json.dumps(incident.evidence) if incident.evidence else None, incident.status))\n",
    "        conn.commit()\n",
    "        print(f\"[Pipeline] Created incident {incident.incident_id} severity={incident.severity}\")\n",
    "        # update memory for involved users\n",
    "        for u in incident.involved_user_ids:\n",
    "            self.memory.append_incident(u, incident.incident_id)\n",
    "        # Notify moderator (prints)\n",
    "        self.notifier.notify_moderator(incident, filtered_actions)\n",
    "        self.observability.log({'event':'pipeline_complete','incident_id': incident.incident_id, 'severity': incident.severity})\n",
    "        return incident, conv, classified, patterns, risk\n",
    "\n",
    "pipeline = SilentGuardianPipeline()\n",
    "print(\"Pipeline ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c782b873",
   "metadata": {
    "papermill": {
     "duration": 0.012066,
     "end_time": "2025-11-30T07:31:49.274718",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.262652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üß† Section 7 : Session and Memory Management (#session)\n",
    "Maintains per-user memory across sessions by logging past incidents in SQLite.\n",
    "Enables recidivism detection and history-aware risk scoring for repeated offenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b755bb7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.300588Z",
     "iopub.status.busy": "2025-11-30T07:31:49.300317Z",
     "iopub.status.idle": "2025-11-30T07:31:49.307702Z",
     "shell.execute_reply": "2025-11-30T07:31:49.306742Z"
    },
    "papermill": {
     "duration": 0.021883,
     "end_time": "2025-11-30T07:31:49.309339",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.287456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Memory Agent ========\n",
      "\n",
      "MemoryAgent ready.\n"
     ]
    }
   ],
   "source": [
    "print_header(\"Memory Agent\")\n",
    "class MemoryAgent:\n",
    "    def __init__(self, conn):\n",
    "        self.conn = conn\n",
    "    def append_incident(self, user_id, incident_id):\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(\"SELECT incidents FROM user_profiles WHERE user_id=?\", (user_id,))\n",
    "        r = cur.fetchone()\n",
    "        if not r:\n",
    "            cur.execute(\"INSERT INTO user_profiles (user_id, anon_id, safety_score, incidents) VALUES (?,?,?,?)\",\n",
    "                        (user_id, gen_id('anon'), 0.5, json.dumps([incident_id])))\n",
    "        else:\n",
    "            incs = json.loads(r[0] or '[]')\n",
    "            incs.append(incident_id)\n",
    "            cur.execute(\"UPDATE user_profiles SET incidents=? WHERE user_id= ?\", (json.dumps(incs), user_id))\n",
    "        self.conn.commit()\n",
    "    def get_incidents(self, user_id):\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(\"SELECT incidents FROM user_profiles WHERE user_id=?\", (user_id,))\n",
    "        r = cur.fetchone()\n",
    "        return json.loads(r[0]) if r and r[0] else []\n",
    "\n",
    "memory_agent = MemoryAgent(conn)\n",
    "print(\"MemoryAgent ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28559343",
   "metadata": {
    "papermill": {
     "duration": 0.011706,
     "end_time": "2025-11-30T07:31:49.332885",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.321179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìä Section 8 : Observability and Logging (#observability)\n",
    "Captures every pipeline event with timestamps for full traceability and debugging.\n",
    "Provides transparent logs that support evaluation, auditing, and agent introspection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4670f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.357246Z",
     "iopub.status.busy": "2025-11-30T07:31:49.356979Z",
     "iopub.status.idle": "2025-11-30T07:31:49.362993Z",
     "shell.execute_reply": "2025-11-30T07:31:49.362125Z"
    },
    "papermill": {
     "duration": 0.020145,
     "end_time": "2025-11-30T07:31:49.364566",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.344421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Observability ========\n",
      "\n",
      "Observability and Logging done successfully.\n"
     ]
    }
   ],
   "source": [
    "print_header(\"Observability\")\n",
    "class ObservabilityAgent:\n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "    def log(self, entry: Dict[str,Any]):\n",
    "        entry['ts'] = now_ts()\n",
    "        self.logs.append(entry)\n",
    "        print(f\"[Observability] {entry.get('event','unknown')}\")\n",
    "    def dump(self):\n",
    "        # return logs for display in notebook\n",
    "        return list(self.logs)\n",
    "\n",
    "observability = ObservabilityAgent()\n",
    "print(\"Observability and Logging done successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00296fe8",
   "metadata": {
    "papermill": {
     "duration": 0.01163,
     "end_time": "2025-11-30T07:31:49.388117",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.376487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üé¨ Section 9 : Demo Run and Usage (#demo)\n",
    "In this section we can now run the demo streams, check safety pipeline and observability validation, fix the missing logs and also execute the main actual runner streams of the System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55ee7469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.413146Z",
     "iopub.status.busy": "2025-11-30T07:31:49.412357Z",
     "iopub.status.idle": "2025-11-30T07:31:49.419105Z",
     "shell.execute_reply": "2025-11-30T07:31:49.418256Z"
    },
    "papermill": {
     "duration": 0.021013,
     "end_time": "2025-11-30T07:31:49.420661",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.399648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Demo streams ========\n",
      "\n",
      "Prepared 6 demo streams (runtime-generated).\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Demo streams (runtime)\n",
    "# Generates realistic chat conversations dynamically for live testing of the pipeline.\n",
    "# Includes benign, low-risk, and repeated high-risk harassment scenarios.\n",
    "# -----------------------------\n",
    "print_header(\"Demo streams\")\n",
    "SIM_STREAMS = []\n",
    "SIM_STREAMS.append([\n",
    "    {'sender_id':'@alice','text':'Hey team, please review my PR','ts': now_ts()},\n",
    "    {'sender_id':'@bob','text':'Looks good to me, thanks!','ts': now_ts()}\n",
    "])\n",
    "SIM_STREAMS.append([\n",
    "    {'sender_id':'@alex','text':'You are so dumb','ts': now_ts()},\n",
    "    {'sender_id':'@mira','text':'Please do not talk to me like that','ts': now_ts()}\n",
    "])\n",
    "for i in range(4):\n",
    "    SIM_STREAMS.append([\n",
    "        {'sender_id':'@alex','text': f\"@mira you are worthless and a loser {i}\", 'ts': now_ts()}\n",
    "    ])\n",
    "print(f\"Prepared {len(SIM_STREAMS)} demo streams (runtime-generated).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf7ac342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.446502Z",
     "iopub.status.busy": "2025-11-30T07:31:49.445671Z",
     "iopub.status.idle": "2025-11-30T07:31:49.451564Z",
     "shell.execute_reply": "2025-11-30T07:31:49.450689Z"
    },
    "papermill": {
     "duration": 0.020163,
     "end_time": "2025-11-30T07:31:49.452920",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.432757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî pipeline.observability.logs already exists (len = 0)\n"
     ]
    }
   ],
   "source": [
    "# Verifies that the pipeline and observability system are properly initialized before execution.\n",
    "# Prevents runtime crashes by stopping execution if critical components are missing.\n",
    "\n",
    "if 'pipeline' not in globals():\n",
    "    print(\"‚ùå pipeline does NOT exist yet. Run the pipeline creation cell first.\")\n",
    "else:\n",
    "    if not hasattr(pipeline, 'observability'):\n",
    "        print(\"‚ùå pipeline.observability missing ‚Äî create Observability before pipeline.\")\n",
    "    else:\n",
    "        if not hasattr(pipeline.observability, 'logs'):\n",
    "            pipeline.observability.logs = []\n",
    "            print(\"‚úÖ Fixed: created pipeline.observability.logs = []\")\n",
    "        else:\n",
    "            print(f\"‚úî pipeline.observability.logs already exists (len = {len(pipeline.observability.logs)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95d3775e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.478554Z",
     "iopub.status.busy": "2025-11-30T07:31:49.478256Z",
     "iopub.status.idle": "2025-11-30T07:31:49.484272Z",
     "shell.execute_reply": "2025-11-30T07:31:49.483370Z"
    },
    "papermill": {
     "duration": 0.020283,
     "end_time": "2025-11-30T07:31:49.485599",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.465316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline.observability.logs already exists (len = 0)\n"
     ]
    }
   ],
   "source": [
    "# Automatically repairs missing observability log storage if it was not initialized correctly.\n",
    "# Ensures uninterrupted logging without restarting the full notebook.\n",
    "\n",
    "try:\n",
    "    if hasattr(pipeline, 'observability'):\n",
    "        if not hasattr(pipeline.observability, 'logs'):\n",
    "            pipeline.observability.logs = []\n",
    "            print(\"Created pipeline.observability.logs = [] (quick fix)\")\n",
    "        else:\n",
    "            print(\"pipeline.observability.logs already exists (len = {})\".format(len(pipeline.observability.logs)))\n",
    "    else:\n",
    "        print(\"pipeline or pipeline.observability not found in globals()\")\n",
    "except Exception as e:\n",
    "    print(\"Error applying quick fix:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31b71b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.511746Z",
     "iopub.status.busy": "2025-11-30T07:31:49.511133Z",
     "iopub.status.idle": "2025-11-30T07:31:49.515446Z",
     "shell.execute_reply": "2025-11-30T07:31:49.514729Z"
    },
    "papermill": {
     "duration": 0.018957,
     "end_time": "2025-11-30T07:31:49.516664",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.497707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN EXECUTION PIPELINE ‚Äî END-TO-END DEMO RUNNER\n",
    "# ============================================================================\n",
    "# This is the primary execution cell of the Silent Guardian system.\n",
    "# It runs the complete multi-agent pipeline on all demo chat streams,\n",
    "# generates structured incident summaries, and prints human-readable outputs.\n",
    "#\n",
    "# HOW TO USE THIS SECTION:\n",
    "# 1. Ensure all agents (Ingestor, Classifier, Pattern Detector, Risk Scorer,\n",
    "#    Planner, MemoryAgent, Observability, and Pipeline) are already created.\n",
    "# 2. Ensure SIM_STREAMS (demo chat conversations) are defined.\n",
    "# 3. Run this cell once to execute the full detection ‚Üí analysis ‚Üí risk scoring\n",
    "#    ‚Üí intervention ‚Üí memory update ‚Üí reporting workflow.\n",
    "#\n",
    "# WHAT THIS SECTION DOES:\n",
    "# ‚Ä¢ Executes each chat stream through the unified multi-agent pipeline.\n",
    "# ‚Ä¢ Automatically normalizes different pipeline return formats (safe handling).\n",
    "# ‚Ä¢ Identifies offender and target using analytical heuristics.\n",
    "# ‚Ä¢ Prints a standardized Incident Summary Dashboard for every conversation.\n",
    "# ‚Ä¢ Displays full conversation, classifier outputs, detected patterns, and risk.\n",
    "# ‚Ä¢ Collects all results into the `results` list for evaluation or export.\n",
    "#\n",
    "# This section demonstrates the complete real-time behavior of the system\n",
    "# exactly as it would operate in a production moderation environment.\n",
    "# ============================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d8885ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.542450Z",
     "iopub.status.busy": "2025-11-30T07:31:49.542137Z",
     "iopub.status.idle": "2025-11-30T07:31:49.572549Z",
     "shell.execute_reply": "2025-11-30T07:31:49.570921Z"
    },
    "papermill": {
     "duration": 0.045422,
     "end_time": "2025-11-30T07:31:49.574139",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.528717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Run demo ========\n",
      "\n",
      "\n",
      "--- Running stream #0 ---\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_afe5155c with 2 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 2 (ts range 2025-11-30T07:26:49.415799Z - 2025-11-30T07:36:49.415799Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_8a96 labels:['none']\n",
      "[HarassmentClassifier_MCP] msg:msg_f30f labels:['none']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] score=0.00 severity=Low\n",
      "[InterventionPlanner] planned actions: ['suggest_support_message']\n",
      "[Observability] ethics_check\n",
      "[Pipeline] Created incident incident_625ed895 severity=Low\n",
      "--- Moderator Notification: Incident incident_625ed895 (severity=Low) ---\n",
      "[0] Action: suggest_support_message - Offer support\n",
      "[Observability] pipeline_complete\n",
      "[InterventionPlanner] planned actions: ['suggest_support_message']\n",
      "\n",
      "=== Incident Summary Dashboard ===\n",
      "Incident ID: incident_625ed895\n",
      "Severity: Low\n",
      "Offender: @alice\n",
      "Target: (none detected)\n",
      "Recommended Actions:\n",
      " - suggest_support_message: Offer support\n",
      "========================================\n",
      "\n",
      "Session: convo_afe5155c\n",
      "User messages (2):\n",
      " - @alice @ 2025-11-30T07:31:49.415791Z: Hey team, please review my PR\n",
      " - @bob @ 2025-11-30T07:31:49.415799Z: Looks good to me, thanks!\n",
      "\n",
      "Classifier results:\n",
      " - msg_8a96945a by @alice: labels=['none'] \n",
      " - msg_f30fe42b by @bob: labels=['none'] \n",
      "\n",
      "Patterns detected:\n",
      "{'repeat_targeting': [], 'recidivism': {}}\n",
      "\n",
      "Risk:  {'score': 0.0, 'severity': 'Low'}\n",
      "\n",
      "Recommended actions:\n",
      "[InterventionPlanner] planned actions: ['suggest_support_message']\n",
      " - suggest_support_message : Offer support\n",
      "\n",
      "--- Running stream #1 ---\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_11b8613f with 2 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 2 (ts range 2025-11-30T07:26:49.415864Z - 2025-11-30T07:36:49.415864Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_987b labels:['insult']\n",
      "[HarassmentClassifier_MCP] msg:msg_9cc2 labels:['none']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {'@alex': 0}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] score=0.45 severity=Medium\n",
      "[InterventionPlanner] planned actions: ['notify_moderator']\n",
      "[Observability] ethics_check\n",
      "[Pipeline] Created incident incident_2e9a75b3 severity=Medium\n",
      "--- Moderator Notification: Incident incident_2e9a75b3 (severity=Medium) ---\n",
      "[0] Action: notify_moderator - Moderator review recommended\n",
      "[Observability] pipeline_complete\n",
      "[InterventionPlanner] planned actions: ['notify_moderator']\n",
      "\n",
      "=== Incident Summary Dashboard ===\n",
      "Incident ID: incident_2e9a75b3\n",
      "Severity: Medium\n",
      "Offender: @alex\n",
      "Target: (none detected)\n",
      "Recommended Actions:\n",
      " - notify_moderator: Moderator review recommended\n",
      "========================================\n",
      "\n",
      "Session: convo_11b8613f\n",
      "User messages (2):\n",
      " - @alex @ 2025-11-30T07:31:49.415861Z: You are so dumb\n",
      " - @mira @ 2025-11-30T07:31:49.415864Z: Please do not talk to me like that\n",
      "\n",
      "Classifier results:\n",
      " - msg_987be5f3 by @alex: labels=['insult'] \n",
      " - msg_9cc27f65 by @mira: labels=['none'] \n",
      "\n",
      "Patterns detected:\n",
      "{'repeat_targeting': [], 'recidivism': {'@alex': 0}}\n",
      "\n",
      "Risk:  {'score': 0.45, 'severity': 'Medium'}\n",
      "\n",
      "Recommended actions:\n",
      "[InterventionPlanner] planned actions: ['notify_moderator']\n",
      " - notify_moderator : Moderator review recommended\n",
      "\n",
      "--- Running stream #2 ---\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_3fd82558 with 1 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 1 (ts range 2025-11-30T07:26:49.415935Z - 2025-11-30T07:36:49.415935Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_5f01 labels:['insult']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_5f010c7b'}], 'recidivism': {'@alex': 1}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] applying recidivism bump: 0.05\n",
      "[RiskScorerV2] score=0.95 severity=Immediate\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "[Observability] ethics_check\n",
      "[Observability] ethics_check\n",
      "\n",
      "Evidence for conversation convo_3fd82558 (platform=slack)\n",
      "Generated: 2025-11-30T07:31:49.566666Z\n",
      "Risk: {'score': 0.9500000000000001, 'severity': 'Immediate'}\n",
      "\n",
      "Messages:\n",
      "- msg_5f010c7b | @alex | @mira you are worthless and a loser 0 | labels=[{'label': 'insult', 'score': 0.9, 'span': 'loser'}]\n",
      "\n",
      "[Pipeline] Created incident incident_40425401 severity=Immediate\n",
      "--- Moderator Notification: Incident incident_40425401 (severity=Immediate) ---\n",
      "[0] Action: create_incident_and_notify_hr - Escalate to HR\n",
      "[1] Action: generate_evidence_text - Create evidence text\n",
      "[Observability] pipeline_complete\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "\n",
      "=== Incident Summary Dashboard ===\n",
      "Incident ID: incident_40425401\n",
      "Severity: Immediate\n",
      "Offender: @alex\n",
      "Target: @mira\n",
      "Recommended Actions:\n",
      " - create_incident_and_notify_hr: Escalate to HR\n",
      " - generate_evidence_text: Create evidence text\n",
      "========================================\n",
      "\n",
      "Session: convo_3fd82558\n",
      "User messages (1):\n",
      " - @alex @ 2025-11-30T07:31:49.415935Z: @mira you are worthless and a loser 0\n",
      "\n",
      "Classifier results:\n",
      " - msg_5f010c7b by @alex: labels=['insult'] \n",
      "\n",
      "Patterns detected:\n",
      "{'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_5f010c7b'}], 'recidivism': {'@alex': 1}}\n",
      "\n",
      "Risk:  {'score': 0.9500000000000001, 'severity': 'Immediate'}\n",
      "\n",
      "Recommended actions:\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      " - create_incident_and_notify_hr : Escalate to HR\n",
      " - generate_evidence_text : Create evidence text\n",
      "\n",
      "--- Running stream #3 ---\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_2e8e021f with 1 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 1 (ts range 2025-11-30T07:26:49.415938Z - 2025-11-30T07:36:49.415938Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_a6c7 labels:['insult']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_a6c7e2a8'}], 'recidivism': {'@alex': 2}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] applying recidivism bump: 0.1\n",
      "[RiskScorerV2] score=1.00 severity=Immediate\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "[Observability] ethics_check\n",
      "[Observability] ethics_check\n",
      "\n",
      "Evidence for conversation convo_2e8e021f (platform=slack)\n",
      "Generated: 2025-11-30T07:31:49.567390Z\n",
      "Risk: {'score': 1.0, 'severity': 'Immediate'}\n",
      "\n",
      "Messages:\n",
      "- msg_a6c7e2a8 | @alex | @mira you are worthless and a loser 1 | labels=[{'label': 'insult', 'score': 0.9, 'span': 'loser'}]\n",
      "\n",
      "[Pipeline] Created incident incident_904f5b97 severity=Immediate\n",
      "--- Moderator Notification: Incident incident_904f5b97 (severity=Immediate) ---\n",
      "[0] Action: create_incident_and_notify_hr - Escalate to HR\n",
      "[1] Action: generate_evidence_text - Create evidence text\n",
      "[Observability] pipeline_complete\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "\n",
      "=== Incident Summary Dashboard ===\n",
      "Incident ID: incident_904f5b97\n",
      "Severity: Immediate\n",
      "Offender: @alex\n",
      "Target: @mira\n",
      "Recommended Actions:\n",
      " - create_incident_and_notify_hr: Escalate to HR\n",
      " - generate_evidence_text: Create evidence text\n",
      "========================================\n",
      "\n",
      "Session: convo_2e8e021f\n",
      "User messages (1):\n",
      " - @alex @ 2025-11-30T07:31:49.415938Z: @mira you are worthless and a loser 1\n",
      "\n",
      "Classifier results:\n",
      " - msg_a6c7e2a8 by @alex: labels=['insult'] \n",
      "\n",
      "Patterns detected:\n",
      "{'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_a6c7e2a8'}], 'recidivism': {'@alex': 2}}\n",
      "\n",
      "Risk:  {'score': 1.0, 'severity': 'Immediate'}\n",
      "\n",
      "Recommended actions:\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      " - create_incident_and_notify_hr : Escalate to HR\n",
      " - generate_evidence_text : Create evidence text\n",
      "\n",
      "--- Running stream #4 ---\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_d53182ed with 1 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 1 (ts range 2025-11-30T07:26:49.415940Z - 2025-11-30T07:36:49.415940Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_82d5 labels:['insult']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_82d53282'}], 'recidivism': {'@alex': 3}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] applying recidivism bump: 0.15000000000000002\n",
      "[RiskScorerV2] score=1.00 severity=Immediate\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "[Observability] ethics_check\n",
      "[Observability] ethics_check\n",
      "\n",
      "Evidence for conversation convo_d53182ed (platform=slack)\n",
      "Generated: 2025-11-30T07:31:49.567901Z\n",
      "Risk: {'score': 1.0, 'severity': 'Immediate'}\n",
      "\n",
      "Messages:\n",
      "- msg_82d53282 | @alex | @mira you are worthless and a loser 2 | labels=[{'label': 'insult', 'score': 0.9, 'span': 'loser'}]\n",
      "\n",
      "[Pipeline] Created incident incident_5eee0d43 severity=Immediate\n",
      "--- Moderator Notification: Incident incident_5eee0d43 (severity=Immediate) ---\n",
      "[0] Action: create_incident_and_notify_hr - Escalate to HR\n",
      "[1] Action: generate_evidence_text - Create evidence text\n",
      "[Observability] pipeline_complete\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "\n",
      "=== Incident Summary Dashboard ===\n",
      "Incident ID: incident_5eee0d43\n",
      "Severity: Immediate\n",
      "Offender: @alex\n",
      "Target: @mira\n",
      "Recommended Actions:\n",
      " - create_incident_and_notify_hr: Escalate to HR\n",
      " - generate_evidence_text: Create evidence text\n",
      "========================================\n",
      "\n",
      "Session: convo_d53182ed\n",
      "User messages (1):\n",
      " - @alex @ 2025-11-30T07:31:49.415940Z: @mira you are worthless and a loser 2\n",
      "\n",
      "Classifier results:\n",
      " - msg_82d53282 by @alex: labels=['insult'] \n",
      "\n",
      "Patterns detected:\n",
      "{'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_82d53282'}], 'recidivism': {'@alex': 3}}\n",
      "\n",
      "Risk:  {'score': 1.0, 'severity': 'Immediate'}\n",
      "\n",
      "Recommended actions:\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      " - create_incident_and_notify_hr : Escalate to HR\n",
      " - generate_evidence_text : Create evidence text\n",
      "\n",
      "--- Running stream #5 ---\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_2b9ffd43 with 1 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 1 (ts range 2025-11-30T07:26:49.415943Z - 2025-11-30T07:36:49.415943Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_9f75 labels:['insult']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_9f759e12'}], 'recidivism': {'@alex': 4}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] applying recidivism bump: 0.2\n",
      "[RiskScorerV2] score=1.00 severity=Immediate\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "[Observability] ethics_check\n",
      "[Observability] ethics_check\n",
      "\n",
      "Evidence for conversation convo_2b9ffd43 (platform=slack)\n",
      "Generated: 2025-11-30T07:31:49.568350Z\n",
      "Risk: {'score': 1.0, 'severity': 'Immediate'}\n",
      "\n",
      "Messages:\n",
      "- msg_9f759e12 | @alex | @mira you are worthless and a loser 3 | labels=[{'label': 'insult', 'score': 0.9, 'span': 'loser'}]\n",
      "\n",
      "[Pipeline] Created incident incident_af3861fd severity=Immediate\n",
      "--- Moderator Notification: Incident incident_af3861fd (severity=Immediate) ---\n",
      "[0] Action: create_incident_and_notify_hr - Escalate to HR\n",
      "[1] Action: generate_evidence_text - Create evidence text\n",
      "[Observability] pipeline_complete\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "\n",
      "=== Incident Summary Dashboard ===\n",
      "Incident ID: incident_af3861fd\n",
      "Severity: Immediate\n",
      "Offender: @alex\n",
      "Target: @mira\n",
      "Recommended Actions:\n",
      " - create_incident_and_notify_hr: Escalate to HR\n",
      " - generate_evidence_text: Create evidence text\n",
      "========================================\n",
      "\n",
      "Session: convo_2b9ffd43\n",
      "User messages (1):\n",
      " - @alex @ 2025-11-30T07:31:49.415943Z: @mira you are worthless and a loser 3\n",
      "\n",
      "Classifier results:\n",
      " - msg_9f759e12 by @alex: labels=['insult'] \n",
      "\n",
      "Patterns detected:\n",
      "{'repeat_targeting': [{'sender': '@alex', 'target': '@mira', 'msg_id': 'msg_9f759e12'}], 'recidivism': {'@alex': 4}}\n",
      "\n",
      "Risk:  {'score': 1.0, 'severity': 'Immediate'}\n",
      "\n",
      "Recommended actions:\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      " - create_incident_and_notify_hr : Escalate to HR\n",
      " - generate_evidence_text : Create evidence text\n",
      "\n",
      "======== Run demo complete (patched) ========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Executes the full Silent Guardian multi-agent pipeline on all runtime demo streams and prints standardized incident reports.\n",
    "# -----------------------------\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def summarize_offender_target(classified: List[Dict[str,Any]], patterns: Dict[str,Any]):\n",
    "    \"\"\"\n",
    "    Pick an offender (sender with highest total label score) and a target (most frequent @-mention).\n",
    "    Returns tuple (offender, target).\n",
    "    Defensive: works with labelled messages where each cm has 'sender_id' and 'labels'.\n",
    "    \"\"\"\n",
    "    # Sum label scores per sender\n",
    "    scores_by_sender = {}\n",
    "    for cm in classified:\n",
    "        s = cm.get('sender_id', '(unknown)')\n",
    "        total = sum(l.get('score', 0.0) for l in cm.get('labels', []))\n",
    "        scores_by_sender[s] = scores_by_sender.get(s, 0.0) + total\n",
    "    if scores_by_sender:\n",
    "        sorted_items = sorted(scores_by_sender.items(), key=lambda kv: (-kv[1], kv[0]))\n",
    "        offender = sorted_items[0][0]\n",
    "    else:\n",
    "        offender = '(none)'\n",
    "\n",
    "    # Collect targets from pattern detector and direct message mentions\n",
    "    targets = [t.get('target') for t in patterns.get('repeat_targeting', []) if t.get('target')]\n",
    "    # Also scan classified messages for mentions if patterns empty\n",
    "    if not targets:\n",
    "        for cm in classified:\n",
    "            text = cm.get('text') or ''\n",
    "            # safe string check\n",
    "            if isinstance(text, str):\n",
    "                targets.extend(re.findall(r\"@\\w+\", text))\n",
    "    if targets:\n",
    "        counts = Counter(targets)\n",
    "        # pick most frequent, break ties lexicographically\n",
    "        sorted_targets = sorted(counts.items(), key=lambda kv: (-kv[1], kv[0]))\n",
    "        target = sorted_targets[0][0]\n",
    "    else:\n",
    "        target = '(none detected)'\n",
    "\n",
    "    return offender, target\n",
    "\n",
    "\n",
    "def print_incident_dashboard(incident_obj, conv, classified: List[Dict[str,Any]],\n",
    "                             patterns: Dict[str,Any], risk: Dict[str,Any],\n",
    "                             planner_obj=None, ethics_obj=None):\n",
    "    \"\"\"\n",
    "    Robust incident dashboard printer.\n",
    "    Supports:\n",
    "     - incident_obj as dataclass-like with .incident_id/.severity\n",
    "     - incident_obj as tuple (returns from older pipeline) -- tries reasonable positions\n",
    "    \"\"\"\n",
    "    planner_obj = planner_obj or globals().get('planner')\n",
    "    ethics_obj = ethics_obj or globals().get('ethics')\n",
    "\n",
    "    offender, target = summarize_offender_target(classified, patterns)\n",
    "\n",
    "    # Resolve incident id + severity safely\n",
    "    if hasattr(incident_obj, 'incident_id'):\n",
    "        incident_id = getattr(incident_obj, 'incident_id', '(unknown)')\n",
    "    elif isinstance(incident_obj, tuple):\n",
    "        # try common tuple shapes: (incident, conv, classified, patterns, risk)\n",
    "        # if incident_obj actually is the \"incident\" element in older wrapper, handle both.\n",
    "        try:\n",
    "            # if the user passed a 5-tuple from old pipeline, second element may be conv etc.\n",
    "            # Search tuple for an object with attribute 'incident_id'\n",
    "            incident_id = next((x.incident_id for x in incident_obj if hasattr(x, 'incident_id')), None)\n",
    "            if not incident_id:\n",
    "                incident_id = incident_obj[0] if len(incident_obj) > 0 else '(unknown)'\n",
    "        except Exception:\n",
    "            incident_id = str(incident_obj)\n",
    "    else:\n",
    "        incident_id = str(incident_obj)\n",
    "\n",
    "    if hasattr(incident_obj, 'severity'):\n",
    "        severity = getattr(incident_obj, 'severity', '(unknown)')\n",
    "    elif isinstance(incident_obj, tuple):\n",
    "        # try to find risk-like element in tuple (a dict with 'severity') or fallback\n",
    "        sev = None\n",
    "        for x in incident_obj:\n",
    "            if isinstance(x, dict) and 'severity' in x:\n",
    "                sev = x.get('severity')\n",
    "                break\n",
    "        severity = sev or (incident_obj[0].severity if hasattr(incident_obj[0], 'severity') else '(unknown)')\n",
    "    else:\n",
    "        severity = risk.get('severity') if isinstance(risk, dict) else '(unknown)'\n",
    "\n",
    "    # Build recommended actions using planner if available and if it accepts inputs\n",
    "    actions = []\n",
    "    if planner_obj:\n",
    "        try:\n",
    "            # planner.plan may expect conv, classified, risk, patterns\n",
    "            # ensure risk is a dict with severity\n",
    "            r = risk if isinstance(risk, dict) else {'severity': severity}\n",
    "            actions = planner_obj.plan(conv, classified, r, patterns) or []\n",
    "        except Exception as e:\n",
    "            # fallback: leave actions empty but do not raise\n",
    "            # print debug line to help developer\n",
    "            print(f\"[print_incident_dashboard] planner.plan call failed: {e}\")\n",
    "            actions = []\n",
    "\n",
    "    # Print dashboard\n",
    "    print(\"\\n=== Incident Summary Dashboard ===\")\n",
    "    print(f\"Incident ID: {incident_id}\")\n",
    "    print(f\"Severity: {severity}\")\n",
    "    print(f\"Offender: {offender}\")\n",
    "    print(f\"Target: {target}\")\n",
    "    print(\"Recommended Actions:\")\n",
    "    if actions:\n",
    "        for a in actions:\n",
    "            print(f\" - {a.get('action_type', '(unknown)')}\" + (f\": {a.get('rationale')}\" if a.get('rationale') else \"\"))\n",
    "    else:\n",
    "        print(\" - (none)\")\n",
    "    print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Re-run demo loop using new dashboard function\n",
    "# (This replaces the old ad-hoc printing block; paste this cell and run)\n",
    "# -----------------------------\n",
    "print_header(\"Run demo\")\n",
    "results = []\n",
    "\n",
    "# Defensive checks for required globals\n",
    "if 'SIM_STREAMS' not in globals():\n",
    "    raise RuntimeError(\"SIM_STREAMS not found in globals. Ensure you defined demo streams before running this cell.\")\n",
    "if 'pipeline' not in globals():\n",
    "    raise RuntimeError(\"pipeline not found in globals. Define pipeline (SilentGuardianPipeline) before running this cell.\")\n",
    "\n",
    "for i, s in enumerate(SIM_STREAMS):\n",
    "    print(f\"\\n--- Running stream #{i} ---\")\n",
    "    # pipeline.run_once may return either: Incident (dataclass) or tuple (incident, conv, classified, patterns, risk)\n",
    "    out = pipeline.run_once(s)\n",
    "    # Normalize return shapes:\n",
    "    if isinstance(out, tuple) and len(out) == 5:\n",
    "        incident, conv, classified, patterns, risk = out\n",
    "    elif hasattr(out, 'incident_id') or isinstance(out, dict):\n",
    "        # older pipeline variant returned incident only; try to reconstruct other outputs where possible\n",
    "        incident = out\n",
    "        # attempt to reconstruct conv/classified/patterns/risk via a second classification pass (safe)\n",
    "        try:\n",
    "            # we have the raw stream s -> ingest to get conv\n",
    "            conv = ingestor.ingest_stream(s)\n",
    "            window_msgs = extractor.extract_window(conv, center_msg_idx=max(0, len(conv.messages)-1))\n",
    "            classified = classifier.classify_messages(window_msgs)\n",
    "            patterns = pattern_detector.detect_patterns(conv, classified) if 'pattern_detector' in globals() else {}\n",
    "            risk = risk_scorer.compute_risk(classified, patterns) if 'risk_scorer' in globals() else {'severity': getattr(incident, 'severity', 'Unknown')}\n",
    "        except Exception as e:\n",
    "            # last resort: set placeholders\n",
    "            conv = None\n",
    "            classified = []\n",
    "            patterns = {}\n",
    "            risk = {'severity': getattr(incident, 'severity', 'Unknown')}\n",
    "    else:\n",
    "        # Unexpected shape ‚Äî try to treat it as incident-like\n",
    "        incident = out\n",
    "        conv = None\n",
    "        classified = []\n",
    "        patterns = {}\n",
    "        risk = {'severity': getattr(incident, 'severity', 'Unknown')}\n",
    "\n",
    "    # Print standardized dashboard\n",
    "    try:\n",
    "        print_incident_dashboard(incident, conv, classified, patterns, risk, planner_obj=globals().get('planner'))\n",
    "    except Exception as e:\n",
    "        print(\"[demo loop] print_incident_dashboard failed:\", e)\n",
    "\n",
    "    # The rest of the structured output (messages, classifier results, etc.)\n",
    "    if conv:\n",
    "        print(f\"Session: {getattr(conv, 'convo_id', '(unknown)')}\")\n",
    "        try:\n",
    "            n_messages = len(conv.messages)\n",
    "        except Exception:\n",
    "            n_messages = 0\n",
    "        print(f\"User messages ({n_messages}):\")\n",
    "        for m in getattr(conv, 'messages', []):\n",
    "            # m may be Message object or dict\n",
    "            if hasattr(m, 'sender_id'):\n",
    "                sid = m.sender_id\n",
    "                txt = m.text\n",
    "                ts = m.ts\n",
    "            else:\n",
    "                sid = m.get('sender_id','(unknown)')\n",
    "                txt = m.get('text','')\n",
    "                ts = m.get('ts', now_ts())\n",
    "            print(f\" - {sid} @ {ts}: {txt}\")\n",
    "    else:\n",
    "        print(\"Session: (conversation object not available)\")\n",
    "\n",
    "    # Classifier results\n",
    "    print('\\nClassifier results:')\n",
    "    for cm in classified:\n",
    "        expl = cm.get('explanation') or ''\n",
    "        print(f\" - {cm.get('msg_id','(no-id)')} by {cm.get('sender_id','(unknown)')}: labels={[l['label'] for l in cm.get('labels',[])]} {expl}\")\n",
    "\n",
    "    # Patterns, risk, recommended actions (repeat)\n",
    "    print('\\nPatterns detected:')\n",
    "    print(patterns)\n",
    "    print('\\nRisk: ', risk)\n",
    "    print('\\nRecommended actions:')\n",
    "    try:\n",
    "        rec_actions = globals().get('planner').plan(conv, classified, risk, patterns)\n",
    "    except Exception as e:\n",
    "        rec_actions = []\n",
    "    for a in rec_actions:\n",
    "        print(' -', a.get('action_type'), ':', a.get('rationale',''))\n",
    "    results.append({'incident':incident, 'conv':conv, 'classified':classified, 'patterns':patterns, 'risk':risk})\n",
    "\n",
    "print_header(\"Run demo complete (patched)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "796957eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.600608Z",
     "iopub.status.busy": "2025-11-30T07:31:49.600295Z",
     "iopub.status.idle": "2025-11-30T07:31:49.605952Z",
     "shell.execute_reply": "2025-11-30T07:31:49.605200Z"
    },
    "papermill": {
     "duration": 0.020317,
     "end_time": "2025-11-30T07:31:49.607348",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.587031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@alice', '[\"incident_625ed895\"]'), ('@bob', '[\"incident_625ed895\"]'), ('@mira', '[\"incident_2e9a75b3\"]'), ('@alex', '[\"incident_2e9a75b3\", \"incident_40425401\", \"incident_904f5b97\", \"incident_5eee0d43\", \"incident_af3861fd\"]')]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Inspect MemoryAgent persistent user incident history\n",
    "# -----------------------------\n",
    "cur.execute(\"SELECT user_id, incidents FROM user_profiles WHERE incidents IS NOT NULL\")\n",
    "print(cur.fetchall()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a0491aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.633732Z",
     "iopub.status.busy": "2025-11-30T07:31:49.633419Z",
     "iopub.status.idle": "2025-11-30T07:31:49.638103Z",
     "shell.execute_reply": "2025-11-30T07:31:49.637205Z"
    },
    "papermill": {
     "duration": 0.019284,
     "end_time": "2025-11-30T07:31:49.639358",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.620074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Observability logs (last 10) ========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# Observability & Execution Trace Viewer\n",
    "# ---------------------------------------------\n",
    "# Displays the last 10 internal pipeline events captured during the demo run.\n",
    "# This provides full transparency into system behavior for debugging, auditing,\n",
    "# and validating multi-agent decision flow.\n",
    "     \n",
    "print_header('Observability logs (last 10)')\n",
    "logs = observability.dump()\n",
    "for e in logs[-10:]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e826a",
   "metadata": {
    "papermill": {
     "duration": 0.012411,
     "end_time": "2025-11-30T07:31:49.664508",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.652097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üîç Section 10 :  Evaluation of the System (#evaluation)\n",
    "This section validates the end-to-end Silent Guardian pipeline using a small, controlled test set.  \n",
    "Each test case contains a short message stream with a known ground-truth severity label** (Gold) and compares it with the system-predicted severity.\n",
    "\n",
    "The evaluation is executed in three stages:\n",
    "1. Initial baseline evaluation\n",
    "2. Robust output normalization for safe metric extraction\n",
    "3. Final stabilized evaluation with guaranteed tuple unpacking\n",
    "\n",
    "This design ensures the system behaves correctly even when internal pipeline return formats change during experimentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b67e39e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.691449Z",
     "iopub.status.busy": "2025-11-30T07:31:49.691112Z",
     "iopub.status.idle": "2025-11-30T07:31:49.699593Z",
     "shell.execute_reply": "2025-11-30T07:31:49.698371Z"
    },
    "papermill": {
     "duration": 0.0236,
     "end_time": "2025-11-30T07:31:49.700968",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.677368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Evaluation ========\n",
      "\n",
      "Running eval set (prints Gold vs Pred)\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_8f6d66c8 with 1 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 1 (ts range 2025-11-30T07:26:49.693820Z - 2025-11-30T07:36:49.693820Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_f2de labels:['none']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] score=0.00 severity=Low\n",
      "[InterventionPlanner] planned actions: ['suggest_support_message']\n",
      "[Observability] ethics_check\n",
      "[Pipeline] Created incident incident_4c9f687a severity=Low\n",
      "--- Moderator Notification: Incident incident_4c9f687a (severity=Low) ---\n",
      "[0] Action: suggest_support_message - Offer support\n",
      "[Observability] pipeline_complete\n",
      "Gold=Low Pred=Low\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_a173e132 with 1 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 1 (ts range 2025-11-30T07:26:49.693828Z - 2025-11-30T07:36:49.693828Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_33aa labels:['insult']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {'@u2': 0}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] score=0.90 severity=Immediate\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "[Observability] ethics_check\n",
      "[Observability] ethics_check\n",
      "\n",
      "Evidence for conversation convo_a173e132 (platform=slack)\n",
      "Generated: 2025-11-30T07:31:49.695942Z\n",
      "Risk: {'score': 0.9, 'severity': 'Immediate'}\n",
      "\n",
      "Messages:\n",
      "- msg_33aab5f1 | @u2 | You are worthless | labels=[{'label': 'insult', 'score': 0.9, 'span': 'worthless'}]\n",
      "\n",
      "[Pipeline] Created incident incident_d20dc168 severity=Immediate\n",
      "--- Moderator Notification: Incident incident_d20dc168 (severity=Immediate) ---\n",
      "[0] Action: create_incident_and_notify_hr - Escalate to HR\n",
      "[1] Action: generate_evidence_text - Create evidence text\n",
      "[Observability] pipeline_complete\n",
      "Gold=High Pred=Immediate\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_9f2f6050 with 1 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 1 (ts range 2025-11-30T07:26:49.693829Z - 2025-11-30T07:36:49.693829Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_cd46 labels:['threat']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {'@u3': 0}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] score=0.95 severity=Immediate\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "[Observability] ethics_check\n",
      "[Observability] ethics_check\n",
      "\n",
      "Evidence for conversation convo_9f2f6050 (platform=slack)\n",
      "Generated: 2025-11-30T07:31:49.696473Z\n",
      "Risk: {'score': 0.95, 'severity': 'Immediate'}\n",
      "\n",
      "Messages:\n",
      "- msg_cd460f3d | @u3 | I will kill you | labels=[{'label': 'threat', 'score': 0.95, 'span': 'i will kill'}]\n",
      "\n",
      "[Pipeline] Created incident incident_48986896 severity=Immediate\n",
      "--- Moderator Notification: Incident incident_48986896 (severity=Immediate) ---\n",
      "[0] Action: create_incident_and_notify_hr - Escalate to HR\n",
      "[1] Action: generate_evidence_text - Create evidence text\n",
      "[Observability] pipeline_complete\n",
      "Gold=Immediate Pred=Immediate\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# Evaluation Cell 1: Baseline Functional Check\n",
    "# ---------------------------------------------\n",
    "# Runs a labeled test set through the pipeline and prints\n",
    "# Gold (expected) vs Pred (predicted) severity levels.\n",
    "# This verifies that the end-to-end detection and scoring logic is working.\n",
    "\n",
    "print_header('Evaluation')\n",
    "EVAL_SET = [\n",
    "    ([{'sender_id':'@u1','text':'Hi all, hello','ts': now_ts()}], 'Low'),\n",
    "    ([{'sender_id':'@u2','text':'You are worthless','ts': now_ts()}], 'High'),\n",
    "    ([{'sender_id':'@u3','text':'I will kill you','ts': now_ts()}], 'Immediate'),\n",
    "]\n",
    "print('Running eval set (prints Gold vs Pred)')\n",
    "for stream, gold in EVAL_SET:\n",
    "    inc, conv, classified, patterns, risk = pipeline.run_once(stream)\n",
    "    print(f\"Gold={gold} Pred={risk['severity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "713c9a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.728229Z",
     "iopub.status.busy": "2025-11-30T07:31:49.727937Z",
     "iopub.status.idle": "2025-11-30T07:31:49.737390Z",
     "shell.execute_reply": "2025-11-30T07:31:49.736407Z"
    },
    "papermill": {
     "duration": 0.024902,
     "end_time": "2025-11-30T07:31:49.738844",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.713942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying robust pipeline.run_once normalizer...\n",
      "pipeline.run_once normalized: callers will receive a tuple (incident, conv, classified, patterns, risk).\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# Evaluation Cell 2: Pipeline Output Normalizer\n",
    "# ---------------------------------------------\n",
    "# Wraps pipeline.run_once with a robust normalizer to guarantee\n",
    "# a consistent return format: (incident, conv, classified, patterns, risk).\n",
    "# Also performs safe MemoryAgent updates without risking runtime crashes.\n",
    "# This ensures all evaluation logic works reliably across pipeline versions.\n",
    "\n",
    "from types import MethodType\n",
    "print(\"Applying robust pipeline.run_once normalizer...\")\n",
    "\n",
    "# get the current 'raw' run function if saved previously (avoid losing the original)\n",
    "original = getattr(pipeline, '__orig_run__', None)\n",
    "if original is None:\n",
    "    # if not saved, assume current pipeline.run_once is the original\n",
    "    original = pipeline.run_once\n",
    "\n",
    "def _normalized_run(raw_stream):\n",
    "    # call original\n",
    "    res = original(raw_stream)\n",
    "    # normalize to tuple (incident, conv, classified, patterns, risk)\n",
    "    if isinstance(res, tuple):\n",
    "        # assume the original already returns desired tuple\n",
    "        normalized = res\n",
    "    else:\n",
    "        # single incident returned -> try to reconstruct minimal tuple\n",
    "        incident = res\n",
    "        conv = None\n",
    "        classified = None\n",
    "        patterns = None\n",
    "        risk = None\n",
    "        # try to extract some fields if incident-like\n",
    "        if hasattr(incident, 'convo_id'):\n",
    "            conv = Conversation(convo_id=getattr(incident, 'convo_id'), platform='unknown', messages=[])\n",
    "        if hasattr(incident, 'severity'):\n",
    "            risk = {'severity': getattr(incident, 'severity')}\n",
    "        normalized = (incident, conv, classified, patterns, risk)\n",
    "\n",
    "    # Update memory safely (no attribute errors)\n",
    "    try:\n",
    "        incident_obj = normalized[0]\n",
    "        involved = getattr(incident_obj, 'involved_user_ids', None) or getattr(incident_obj, 'involved_users', None)\n",
    "        if involved and 'memory_agent' in globals():\n",
    "            for u in involved:\n",
    "                try:\n",
    "                    memory_agent.append_incident(u, getattr(incident_obj, 'incident_id', None))\n",
    "                except Exception as e:\n",
    "                    print(\"[pipeline memory update] append_incident error:\", e)\n",
    "            # informational\n",
    "            print(\"[pipeline memory update] updated memory_agent for involved users.\")\n",
    "    except Exception as e:\n",
    "        print(\"[pipeline memory update] unexpected error while updating memory:\", e)\n",
    "\n",
    "    return normalized\n",
    "\n",
    "# attach wrapper and remember original\n",
    "pipeline.__orig_run__ = original\n",
    "pipeline.run_once = MethodType(lambda self, raw_stream: _normalized_run(raw_stream), pipeline)\n",
    "print(\"pipeline.run_once normalized: callers will receive a tuple (incident, conv, classified, patterns, risk).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69ae2130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.765962Z",
     "iopub.status.busy": "2025-11-30T07:31:49.765642Z",
     "iopub.status.idle": "2025-11-30T07:31:49.777082Z",
     "shell.execute_reply": "2025-11-30T07:31:49.776139Z"
    },
    "papermill": {
     "duration": 0.026764,
     "end_time": "2025-11-30T07:31:49.778326",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.751562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Evaluation  - fixed unpacking ========\n",
      "\n",
      "Running small eval set (prints Gold vs Pred)\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_1dc4ca2b with 1 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 1 (ts range 2025-11-30T07:26:49.770624Z - 2025-11-30T07:36:49.770624Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_df75 labels:['none']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] score=0.00 severity=Low\n",
      "[InterventionPlanner] planned actions: ['suggest_support_message']\n",
      "[Observability] ethics_check\n",
      "[Pipeline] Created incident incident_dd8c6970 severity=Low\n",
      "--- Moderator Notification: Incident incident_dd8c6970 (severity=Low) ---\n",
      "[0] Action: suggest_support_message - Offer support\n",
      "[Observability] pipeline_complete\n",
      "[pipeline memory update] updated memory_agent for involved users.\n",
      "Gold=Low Pred=Low\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_168695a7 with 1 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 1 (ts range 2025-11-30T07:26:49.770632Z - 2025-11-30T07:36:49.770632Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_e5ee labels:['insult']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {'@u2': 1}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] applying recidivism bump: 0.05\n",
      "[RiskScorerV2] score=0.95 severity=Immediate\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "[Observability] ethics_check\n",
      "[Observability] ethics_check\n",
      "\n",
      "Evidence for conversation convo_168695a7 (platform=slack)\n",
      "Generated: 2025-11-30T07:31:49.773586Z\n",
      "Risk: {'score': 0.9500000000000001, 'severity': 'Immediate'}\n",
      "\n",
      "Messages:\n",
      "- msg_e5ee55fc | @u2 | You are worthless | labels=[{'label': 'insult', 'score': 0.9, 'span': 'worthless'}]\n",
      "\n",
      "[Pipeline] Created incident incident_1cacf093 severity=Immediate\n",
      "--- Moderator Notification: Incident incident_1cacf093 (severity=Immediate) ---\n",
      "[0] Action: create_incident_and_notify_hr - Escalate to HR\n",
      "[1] Action: generate_evidence_text - Create evidence text\n",
      "[Observability] pipeline_complete\n",
      "[pipeline memory update] updated memory_agent for involved users.\n",
      "Gold=High Pred=Immediate\n",
      "[Pipeline] run_once called\n",
      "[Ingestor] ingest_stream called\n",
      "[Ingestor] Produced conversation convo_c40d3452 with 1 messages\n",
      "[Observability] ingested_conversation\n",
      "[Extractor] extract_window called\n",
      "[Extractor] Window size: 1 (ts range 2025-11-30T07:26:49.770634Z - 2025-11-30T07:36:49.770634Z)\n",
      "[HarassmentClassifier_MCP] classify_messages called\n",
      "[HarassmentClassifier_MCP] msg:msg_39f6 labels:['threat']\n",
      "[PatternDetectorV2] detect_patterns called\n",
      "[PatternDetectorV2] found patterns: {'repeat_targeting': [], 'recidivism': {'@u3': 1}}\n",
      "[RiskScorerV2] compute_risk called\n",
      "[RiskScorerV2] applying recidivism bump: 0.05\n",
      "[RiskScorerV2] score=1.00 severity=Immediate\n",
      "[InterventionPlanner] planned actions: ['create_incident_and_notify_hr', 'generate_evidence_text']\n",
      "[Observability] ethics_check\n",
      "[Observability] ethics_check\n",
      "\n",
      "Evidence for conversation convo_c40d3452 (platform=slack)\n",
      "Generated: 2025-11-30T07:31:49.774032Z\n",
      "Risk: {'score': 1.0, 'severity': 'Immediate'}\n",
      "\n",
      "Messages:\n",
      "- msg_39f63bcc | @u3 | I will kill you | labels=[{'label': 'threat', 'score': 0.95, 'span': 'i will kill'}]\n",
      "\n",
      "[Pipeline] Created incident incident_c5ec9bd2 severity=Immediate\n",
      "--- Moderator Notification: Incident incident_c5ec9bd2 (severity=Immediate) ---\n",
      "[0] Action: create_incident_and_notify_hr - Escalate to HR\n",
      "[1] Action: generate_evidence_text - Create evidence text\n",
      "[Observability] pipeline_complete\n",
      "[pipeline memory update] updated memory_agent for involved users.\n",
      "Gold=Immediate Pred=Immediate\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# Evaluation Cell 3: Final Stabilized Validation\n",
    "# ---------------------------------------------\n",
    "# Executes the evaluation using the normalized pipeline output.\n",
    "# Safely extracts predicted severity and compares it with gold labels.\n",
    "# This cell represents the final verification step for detection accuracy\n",
    "# and can be extended for formal ML metrics in future versions.\n",
    "\n",
    "print_header('Evaluation  - fixed unpacking')\n",
    "EVAL_SET = [\n",
    "    ([{'sender_id':'@u1','text':'Hi all, hello','ts': now_ts()}], 'Low'),\n",
    "    ([{'sender_id':'@u2','text':'You are worthless','ts': now_ts()}], 'High'),\n",
    "    ([{'sender_id':'@u3','text':'I will kill you','ts': now_ts()}], 'Immediate'),\n",
    "]\n",
    "print('Running small eval set (prints Gold vs Pred)')\n",
    "\n",
    "for stream, gold in EVAL_SET:\n",
    "    # call pipeline.run_once - accept either tuple return or single Incident\n",
    "    result = pipeline.run_once(stream)\n",
    "    if isinstance(result, tuple):\n",
    "        # expected tuple shape: (incident, conv, classified, patterns, risk)\n",
    "        incident = result[0] if len(result) > 0 else None\n",
    "        conv = result[1] if len(result) > 1 else None\n",
    "        classified = result[2] if len(result) > 2 else None\n",
    "        patterns = result[3] if len(result) > 3 else None\n",
    "        risk = result[4] if len(result) > 4 else (None if not incident else {'severity': incident.severity if hasattr(incident, 'severity') else None})\n",
    "    else:\n",
    "        # single object returned (incident-like)\n",
    "        incident = result\n",
    "        conv = classified = patterns = None\n",
    "        # try to derive risk if available on incident; else fallback\n",
    "        risk = {'severity': getattr(incident, 'severity', None)} if incident is not None else {'severity': None}\n",
    "\n",
    "    pred = risk.get('severity') if isinstance(risk, dict) else getattr(risk, 'severity', None)\n",
    "    print(f\"Gold={gold} Pred={pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91b96746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T07:31:49.806269Z",
     "iopub.status.busy": "2025-11-30T07:31:49.805998Z",
     "iopub.status.idle": "2025-11-30T07:31:49.811951Z",
     "shell.execute_reply": "2025-11-30T07:31:49.810960Z"
    },
    "papermill": {
     "duration": 0.021481,
     "end_time": "2025-11-30T07:31:49.813194",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.791713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== In-memory incidents summary ========\n",
      "\n",
      "('incident_625ed895', 'convo_afe5155c', 'Low')\n",
      "('incident_2e9a75b3', 'convo_11b8613f', 'Medium')\n",
      "('incident_40425401', 'convo_3fd82558', 'Immediate')\n",
      "('incident_904f5b97', 'convo_2e8e021f', 'Immediate')\n",
      "('incident_5eee0d43', 'convo_d53182ed', 'Immediate')\n",
      "('incident_af3861fd', 'convo_2b9ffd43', 'Immediate')\n",
      "('incident_4c9f687a', 'convo_8f6d66c8', 'Low')\n",
      "('incident_d20dc168', 'convo_a173e132', 'Immediate')\n",
      "('incident_48986896', 'convo_9f2f6050', 'Immediate')\n",
      "('incident_dd8c6970', 'convo_1dc4ca2b', 'Low')\n",
      "('incident_1cacf093', 'convo_168695a7', 'Immediate')\n",
      "('incident_c5ec9bd2', 'convo_c40d3452', 'Immediate')\n",
      "\n",
      "‚úÖ Demo complete ‚Äî all outputs are printed above (no files).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Inspect in-memory DB (print summary)\n",
    "# -----------------------------\n",
    "print_header('In-memory incidents summary')\n",
    "cur.execute('SELECT incident_id, convo_id, severity FROM incidents')\n",
    "for r in cur.fetchall():\n",
    "    print(r)\n",
    "\n",
    "print('\\n‚úÖ Demo complete ‚Äî all outputs are printed above (no files).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70984b9e",
   "metadata": {
    "papermill": {
     "duration": 0.012899,
     "end_time": "2025-11-30T07:31:49.838919",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.826020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìù Section 11 : Conclusion & Summary {#conclusion}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5424fc",
   "metadata": {
    "papermill": {
     "duration": 0.014948,
     "end_time": "2025-11-30T07:31:49.867292",
     "exception": false,
     "start_time": "2025-11-30T07:31:49.852344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Key Concepts Demonstrated\n",
    "\n",
    "This capstone project successfully demonstrates the following advanced AI system concepts :\n",
    "\n",
    "1. ‚úÖ **Multi-Agent System**\n",
    "\n",
    "    - Multiple specialized agents such as Ingestor, Classifier, Pattern Detector, Risk    Scorer, Planner, Ethics, Evidence Builder, Notifier, Memory, and Observability\n",
    "\n",
    "    - A centralized pipeline orchestrator coordinating all agents\n",
    "\n",
    "     - Sequential and event-driven agent execution\n",
    "\n",
    "    - Agent collaboration for real-time detection and response\n",
    "\n",
    "2. ‚úÖ **Custom Tools & MCP (Model Control Plane)**\n",
    "\n",
    "    - Google Search Tool (simulated) integrated as a safe external tool\n",
    "\n",
    "    - MCP-based classifier switching between rule-based and LLM-sim modes\n",
    "\n",
    "    - Tool registry enabling safe experimentation and modular upgrades\n",
    "\n",
    "3. ‚úÖ **Sessions & Memory**\n",
    "\n",
    "    - Persistent user behavior tracking using SQLite / in-memory database\n",
    "\n",
    "    - Incident history (recidivism tracking) for repeat offenders\n",
    "\n",
    "    - Stateful context preserved across multiple interactions\n",
    "\n",
    "4. ‚úÖ **Observability**\n",
    "\n",
    "    - End-to-end event logging for every pipeline stage\n",
    "\n",
    "    - Tracks ingestion, classification, ethics checks, escalations, and completion\n",
    "\n",
    "    - Enables debugging, auditing, and system transparency\n",
    "\n",
    "5. ‚úÖ **Agent-to-Agent Communication**\n",
    "\n",
    "    - Agents communicate via the pipeline and Message Bus (A2A Pub/Sub)\n",
    "\n",
    "    - Real-time sharing between Classifier ‚Üí Pattern Detector ‚Üí Risk Scorer ‚Üí Planner\n",
    "\n",
    "    - Modular design allows agents to act as tools for other agents\n",
    "\n",
    "6. ‚úÖ **Agent Evaluation**\n",
    "\n",
    "    - Built evaluation framework for checking predictions\n",
    "\n",
    "    - Gold vs Predicted severity comparison\n",
    "\n",
    "    - Functional validation of full pipeline behavior\n",
    "\n",
    "## üèóÔ∏è Architecture Highlights\n",
    "\n",
    " - Modular Design: Each agent is independently replaceable\n",
    "\n",
    " - Scalable: New tools, models, or agents can be added easily\n",
    "\n",
    " - Observable: Complete visibility into system behavior\n",
    "\n",
    " - Stateful: Uses memory and session context for intelligent decisions\n",
    "\n",
    " - Ethics-Aware: All automated actions pass through policy checks\n",
    "\n",
    " - Human-in-the-Loop Ready: HR/moderator escalation is built-in\n",
    "\n",
    "## üéØ Value Proposition\n",
    "\n",
    "- This system helps organizations:\n",
    "\n",
    "- ‚úÖ Detect harassment automatically in real time\n",
    "\n",
    "- ‚úÖ Prevent repeated abuse using behavior history (recidivism tracking)\n",
    "\n",
    "- ‚úÖ Reduce manual moderation workload through automation\n",
    "\n",
    "- ‚úÖ Ensure ethical compliance before any enforcement\n",
    "\n",
    "- ‚úÖ Preserve legal evidence for HR and compliance teams\n",
    "\n",
    "- ‚úÖ Improve workplace safety and trust\n",
    "\n",
    "## üöÄ Future Enhancements\n",
    "\n",
    "- Integration with real chat platforms (Slack, MS Teams, Emails)\n",
    "\n",
    "- Automated sentiment trend analysis\n",
    "\n",
    "- Admin dashboard for live monitoring\n",
    "\n",
    "- Role-based access control (RBAC)\n",
    "\n",
    "- Multilingual harassment detection\n",
    "\n",
    "- Mobile and web UI for moderators\n",
    "\n",
    "## ‚úÖ Final Summary Statement\n",
    "\n",
    "The Silent Guardian AI Safety Agent demonstrates how a multi-agent, memory-aware, observable, and ethics-driven AI system can be designed to automatically detect, assess, and intervene in harassment incidents at scale. This project showcases enterprise-"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14484960,
     "sourceId": 121144,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.677967,
   "end_time": "2025-11-30T07:31:50.398849",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-30T07:31:40.720882",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
